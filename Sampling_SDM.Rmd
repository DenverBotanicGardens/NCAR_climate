---
title: "Sampling impacts on SDM"
author: "Michelle DePrenger-Levin"
date: "2/15/2020"
output: html_document
---

```{r}
# install.packages("installr")
# require(installr)
# updateR()

rm(list=ls())


# Sys.setenv(JAVA_HOME="C:/Program Files (x86)/Java/jre1.8.0_241/lib/") # for 64-bit version
# install.packages("rJava")
# library(rJava)

library(diagram)
library(ggplot2)

require(DiagrammeR)

# simmulations
library(virtualspecies)

# SDM
library(rJava)

library(dismo)

# Mapping
library(rgeos)
library(raster)
library(maptools)
library(dismo)
library(RNRCS)
library(rgdal)


# Parallelization
library(foreach)
library(parallel)
library(doParallel)
library(magrittr) # pipe %>%


thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}
```

Systematic should either be removed or treated as spatially unbiased while simple random is both spatially and environmentally unbiased because environemtnal variables are spatially autocorrelated. 

DiagrammeR 
```{r}
grViz("digraph flowchart {

      graph [rankdir = TB, fontsize = 14]
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = box]        
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']
      tab4 [label = '@@4']
      tab5 [label = '@@5']
      tab6 [label = '@@6']
      tab7 [label = '@@7']
      tab8 [label = '@@8-1']
      tab9 [label = '@@8-2']
      tab10 [label = '@@8-3']
      tab11 [label = '@@8-4']
      tab12 [label = <Bio<SUB>1</SUB>>]
      tab13 [label = <Bio<SUB>11</SUB>>]
      tab14 [label = <Bio<SUB>12</SUB>>]
      tab15 [label = <Bio<SUB>19</SUB>>]
     
      # edge definitions with the node IDs
      tab1 -> tab3;
      tab4 -> tab5;
      tab2 -> tab3;
      tab5 -> tab6;
      tab3 -> tab8;
      tab8 -> tab3; 
      tab3 -> tab9;
      tab3 -> tab10;
      tab3 -> tab11;
      tab7 -> tab2;
      tab12 -> tab2;
      tab13 -> tab2;
      tab14 -> tab2;
      tab15 -> tab2;
      tab9 -> tab4;
      tab10 -> tab4;
      tab11 -> tab4;
      {rank = same ; tab8; tab3;}
      }

      [1]: 'Model organism (Claytonia rubra)'
      [2]: 'Climate Drivers'
      [3]: 'Build true distribution (SDM)'
      [4]: 'sample'
      [5]: 'Build SDM'
      [6]: 'Compare with true'
      [7]: 'Elevation'
      [8]: c('Systematic (true sample)','Adaptive cluster','Convenience','Simple random')
      ")


```


Bayesian model to treat amount of the niche sampled as a latent vairable  
```{r}

grViz("digraph flowchart {

        
      graph [layout = dot, overlap = FALSE]
        
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = plain, rankdir = LR]        
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab4 [label = '@@4-1']
      tab5 [label = '@@4-2']
      tab6 [label = '@@4-3']
      tab7 [label = '@@4-4']
      tab8 [label = '@@4-5']
       node [label = '&alpha;&#x2080;&beta;&#x2080;']
      tab9 
       node [label = '&alpha;&#x2081;&beta;&#x2081;']
      tab10
       node [label = '&alpha;&#x2084;&beta;&#x2082;']
      tab11 
       node [label = '&alpha;&#x2082;&beta;&#x2083;']
      tab12 
       node [label = '&alpha;&#x2083;&beta;&#x2084;']
      tab13
       node [label = '&sigma;&#x00B2;']
      tab14
      tab3 [label = '@@3']
      tab15 [label = '@@5']
      
      # edge
      edge[ dir = forw];
      tab3 -> tab9 [style=dotted]; {rank = same tab1 tab3};
      tab3 -> tab10 [style=dotted];
      tab3 -> tab12 [style=dotted];
      tab3 -> tab13 [style=dotted];
      tab3 -> tab11 [style=dotted];
      

      
      # edge definitions with the node IDs
      edge[ dir = back];
      tab1 -> tab2; 
      tab2 -> tab15;
      tab15 -> tab4;
      tab15 -> tab5;
      tab15 -> tab6;
      tab15 -> tab7;
      tab15 -> tab8;
      tab4 -> tab9;
      tab5 -> tab10;
      tab6 -> tab12;
      tab7 -> tab13;
      tab8 -> tab11;
      tab2 -> tab14;{rank = same tab11 tab14};
      }

      [1]: '(Data) &gamma;&#x2081;'
      [2]: 'SDM (Pattern) &eta;'
      [3]: 'Sampling design'
      [4]: c('Annual Precipition','Annual Temperature','Precip of coldest quarter','Mean temp of coldest quarter','Elevation')
      [5]: 'Variable contribution (Process)'
      ")
```



```{r}
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")

colocounties <- spTransform(colocounties.UTM,CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")
bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif")
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)
```


### Skip ###
Use maxent, and then refine the relatonships of environment and points  
```{r}
clru <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Claytonia rubra_SEINet/occurrences.csv")

plot(colocounties)
points(clru$decimalLongitude, clru$decimalLatitude, col="blue")
# points(clar$decimalLongitude, clar$decimalLatitude)


clru <- clru[complete.cases(clru$decimalLatitude),]
clruspdf <- SpatialPointsDataFrame(coords = clru[,c("decimalLongitude","decimalLatitude")],
                                     data = clru,
                                     proj4string = CRS("+proj=longlat +datum=WGS84"))

```
SDMtune
```{r}
# install.packages("SDMtune")
library(SDMtune)
```


# Virtual species 
<http://borisleroy.com/files/virtualspecies-tutorial.html>
virtual species based on Claytonia rubra   
```{r}
# or use all worldclim data
# bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)
# save(bioclim.colorado, file = "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/bioclim.colorado.Rda")
load("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/bioclim.colorado.Rda")
bioclim.colorado

rasterstack1 <- stack(bioclim.colorado[[c(1,11,12,19)]]) 
coloElev_resam <- resample(coElev_res, bioclim.colorado[[1]], method = 'bilinear')
coloElev <- crop(coloElev_resam, extent(colocounties), snap="out")
bioclim.stack <- crop(rasterstack1,extent(colocounties), snap="out")
rasterstack2 <- stack(coloElev,bioclim.stack)


# dummy variable
sim_layer <- coloElev
sim_layer <- setValues(sim_layer, runif(length(coloElev), min = 0, max = 100))
names(sim_layer) <- "dummy"
plot(sim_layer)
rasterstack3 <- stack(coloElev,bioclim.stack, sim_layer)

# scale will center (subtract the layer mean) and scale by dividing the centered layer by SD
rasterstack3_z <- scale(rasterstack3)
plot(rasterstack3_z)

# Normalize raster layers to 0-1; linear transformations so do not change the shape of the data
# normalize
# X - min(X) /  max(X) - min(X)
# z-score; Standardized
# X - mean(X) / sd(X)

rasterstack_norm <- rasterstack3
# Normalize to 0-1; worked before and now doesn't
for(i in 1:6){
  rasterstack_norm[[i]] <- calc(rasterstack_norm[[i]], function(x){
    (x-min(getValues(rasterstack_norm[[i]])))/(max(getValues(rasterstack_norm[[i]]))-min(getValues(rasterstack_norm[[i]])))
  })
}

plot(rasterstack_norm[[1]], main="noramlized")
plot(rasterstack3[[1]], main="elevation as is")
plot(rasterstack3_z[[1]], main="scaled minus mean/sd")
plot(scale(rasterstack_norm[[1]]), main="scaled normalized")

# scale in raster::scale just give the z-score
names(rasterstack_norm) <- c("Elevation","Bio1","Bio11","Bio12","Bio19","dummy")

# for(i in 1:6){
#     writeRaster(rasterstack_norm[[i]], paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/rasterstack_normalized,",i,".tif",sep=""), overwrite=TRUE)
# }


```


e^Xlinearmodel/1+e^linear model so that it's [0-1] of the probability of y|x 
Create my own glm for comparison with maxent
```{r}

predic_raster <- rasterstack_norm[[1]]

lm1 <- as.formula(~ getValues(rasterstack_norm[[1]])*1 + getValues(rasterstack_norm[[2]])*2.5 - getValues(rasterstack_norm[[3]])*6 +
                    getValues(rasterstack_norm[[4]])*4 - getValues(rasterstack_norm[[5]])*5 + getValues(rasterstack_norm[[6]])*.005)


identical(length(predic_raster),length(exp(as.formula(lm1[[2]]))/(1+exp(as.formula(lm1[[2]])))))

# predic_raster[] <- exp(as.formula(lm1[[2]]))/(1+exp(as.formula(lm1[[2]])))
predic_raster <- setValues(predic_raster, as.vector(exp(as.formula(lm1[[2]]))/(1+exp(as.formula(lm1[[2]])))))

plot(predic_raster)

# normalize response
predic_raster <- calc(predic_raster, function(x){
    (x-min(getValues(predic_raster)))/(max(getValues(predic_raster))-min(getValues(predic_raster)))
})
```

```{r}
jpeg("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig1a_abioticvars.jpg",
     width=173, height=105,units='mm', res=300)
        par(mar=c(2.1,2.1,1.1,2.1))
        plot(predic_raster)
        mtext("a)", side=3, line=0, adj=0)
 
dev.off()

jpeg("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig1b_abioticvars.jpg",
     width=225, height=105,units='mm', res=300)

        plot(rasterstack_norm)
        mtext("b)", side=3, line=3, adj=-.10)

dev.off()
        

# jpeg("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig1_abioticvars.jpg",
#      width=170, height=100,units='mm', res=300)
#   
# par(mfrow=c(1,2))      
# # layout(matrix(c(1,2), 1,2, byrow = TRUE), widths = c(3,3), heights = c(1,1))
# # layout.show(2)
# # plot 1
# par(mar=c(2.1,2.1,1.1,2.1))
# plot(predic_raster)
# mtext("a)", side=3, line=0, adj=0)
# 
# # plot 2
# plot(rasterstack_norm)
# mtext("b)", side=3, line=3, adj= -0.1)
# 
# dev.off()
        



```


Pattern and process figures
```{r}


jpeg("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Pattern_compare.jpg",
     width=175, height=175,units='mm', res=300)

plot(1:10, 1:10, type="l", lwd=2, yaxt="n", xaxt="n", ylab="Biased Sampling", xlab="True sampling (systematic)")
mtext("Pixel-based distance from true", side=1, line=0.5)
mtext("Pixel-based distance from true", side=2, line=0.5)
# polygon(c(1,1,8.9), c(2.1,9.9,9.9), col=rgb(.15,0,.5,.25))
arrows(4.9,5.1,3.5,6.5,lwd=1, col='red')
arrows(5.1,4.9,6.5,3.5, col='red')
text("sampling method outperformed systematic", x = 2, y=7.5, adj = 0, cex= 0.95)
text("sampling method underperformed systematic", x = 9, y = 2, adj = 1, cex=0.95)
# across sample size? colored dots by sample size? yes maybe

dev.off()
```



# Sampling functions
Sampling methods
```{r}
# test
# suitability.raster <- predic_raster
# samplesize <- 20

### systematic 
systematic_sampling <- function(suitability.raster,  samplesize){
  # systematic sampling to allow for Bernoulli process to reject some cells with high suitability and sometimes take cells with low suitability
  # evenstep <- ceiling(length(suitability.raster)/(samplesize*mean(suitability.raster[]))) 
  evenstep <- ceiling(length(suitability.raster)/(samplesize*100))
  i <- evenstep
  
  sampleout <- c()
  while(i < length(suitability.raster)){
      if(rbinom(1, 1, getValues(suitability.raster)[i]) == 1){
        sampleout <- rbind(sampleout,xyFromCell(suitability.raster, i))
      }
      i <- i + evenstep
    }
  
  sampleout <- thin.max(sampleout, c("x","y"), samplesize) # spatial thinning
  sampleout
}


# suitability.raster <- clru1[[3]]
# rm(suitability.raster)
### random
random_sampling <- function(suitability.raster, samplesize){
  sampleout <- c()
  i <- 1
  while(i <= samplesize){
    randcell <- ceiling(runif(1, min = 1, max = length(suitability.raster)))
    
    if(rbinom(1, 1, getValues(suitability.raster)[randcell]) == 1){
      sampleout <- rbind(sampleout,xyFromCell(suitability.raster, randcell))
      i <- i+1
    } 
  }
  sampleout
}



### adaptive cluster sampling  
# function to find the surrounding cells
# check if on edge is it 1 or max row or col then select the remaining ones
surroundingcells <- function(cellRowCol, suitability.raster){
  out <- data.frame(Cells = c(cellFromRowCol(suitability.raster, cellRowCol[1], cellRowCol[2]), # center cell; 1
                          cellFromRowCol(suitability.raster, cellRowCol[1]-1, cellRowCol[2]-1),
                          cellFromRowCol(suitability.raster, cellRowCol[1]-1, cellRowCol[2]),
                          cellFromRowCol(suitability.raster, cellRowCol[1]-1, cellRowCol[2]+1), # row above; 4
                          cellFromRowCol(suitability.raster, cellRowCol[1], cellRowCol[2]-1),
                          cellFromRowCol(suitability.raster, cellRowCol[1], cellRowCol[2]+1), # either side, same row; 6
                          cellFromRowCol(suitability.raster, cellRowCol[1]+1, cellRowCol[2]-1),
                          cellFromRowCol(suitability.raster, cellRowCol[1]+1, cellRowCol[2]),
                          cellFromRowCol(suitability.raster, cellRowCol[1]+1, cellRowCol[2]+1)), # next row; 9
                    Rows = c(cellRowCol[1], # center row
                          cellRowCol[1]-1,
                          cellRowCol[1]-1,
                          cellRowCol[1]-1, # row above
                          cellRowCol[1], 
                          cellRowCol[1],  # either side, same row
                          cellRowCol[1]+1, 
                          cellRowCol[1]+1, 
                          cellRowCol[1]+1),
                    Cols = c(cellRowCol[2], # center col
                          cellRowCol[2]-1,
                          cellRowCol[2],
                          cellRowCol[2]+1, # row above
                          cellRowCol[2]-1,
                          cellRowCol[2]+1, # either side, same row
                          cellRowCol[2]-1,
                          cellRowCol[2],
                          cellRowCol[2]+1))
  if(cellRowCol[1]==1){
    out <- out[c(1,5:9),]
  }
  if(cellRowCol[2]==1){
    out <- out[c(1,3:4,6,8:9),]
  }
  if(cellRowCol[1]==nrow(suitability.raster)){
    out <- out[c(1,1:6),]
  }
  if(cellRowCol[2]==ncol(suitability.raster)){
    out <- out[c(1:3,5,7:8),]
  }
  out
}

# Test
# suitability.raster <- predic_raster
# samplesize <- 20
# rm(suitability.raster);rm(samplesize)

adaptive_cluster <- function(suitability.raster, samplesize){
  n <- 0
  samples <- c()
  while(n <= samplesize){
    if(n == samplesize) break
    # Select a random cell (name row, col, and cell number)
    randcellRowCol <- c(ceiling(runif(1, min = 1, max = nrow(suitability.raster))),
                    ceiling(runif(1, min = 1, max = ncol(suitability.raster)))) # Row Col
    randcell <- cellFromRowCol(suitability.raster,randcellRowCol[1],randcellRowCol[2]) # cell number that matches
    # start a cluster
    # Bernoulli trial for setting a presence at the cell with probabiliity of suitability score to start a cluster
    if(rbinom(1,1,getValues(suitability.raster)[randcell]) == 1){
      n <- n+1
      samples <- rbind(samples, xyFromCell(suitability.raster, randcell))
      if(n == samplesize) break
      surrcells <- surroundingcells(randcellRowCol, suitability.raster)
      
      # check surrounding cells of a 'presence' and start this cluster
      j <- 2 # move down the table of cells, adding non-duplicated if cell occupied, first row is center of cluster, included to check for dupliates
      # Could hit sample size in the middle of checking all the surrounding cells
      while(j < nrow(surrcells)){
        if(rbinom(1,1,getValues(suitability.raster)[surrcells$Cells[j]]) == 1){
          samples <- rbind(samples, xyFromCell(suitability.raster, surrcells$Cells[j]))
          surrcells <- rbind(surrcells, surroundingcells(as.numeric(paste(surrcells[j,c(2:3)])),suitability.raster) )
          surrcells <- surrcells[!duplicated(surrcells$Cells),] # only add the surrounding cells not already included
          j <- j+1 # move down surrounding cells of original cluster 
          n <- n+1 # added to sample
          if(n == samplesize) break
          if(j == samplesize) break
        } else {# surrounding the surrounding cells, clusters
          j <- j+1 # last one not added, check the next row
          }
      }  # end while statement j is number of surrounding cells to be checked
    } # end if cell selected, when not occupied, select a new random cell
    
  } # end while sample size n <= samplesize so don't start a new cluster
  samples
}


### Convenience sampling, weighted by sampled areas
# 1. set each convenience raster cell to the proportion of SEINet herb collections per cell as convenience

# convenience_raster <- predic_raster
# # All samples from 1990, 2000, 2010 to represent samples over time over 21 years
# xy_1990 <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Colorado_1990/occurrences.csv")
# xy_2000 <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Colorado_2000/occurrences.csv")
# xy_2010 <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Colorado_2010/occurrences.csv")
# xys <- do.call(rbind,lapply(list(xy_1990,xy_2000,xy_2010), function(xys){
#   i <- sapply(xys, is.factor)
#   xys[i] <- lapply(xys[i], as.character)
#   xys    
# }))
# 
# xys$decimalLatitude <- as.numeric(xys$decimalLatitude)
# xys$decimalLongitude <- as.numeric(xys$decimalLongitude)
# xys <- xys[!is.na(xys$decimalLongitude),c("decimalLongitude","decimalLatitude")]
# convenience_raster <- rasterize(xys, convenience_raster, fun='count')

## Interpolate <https://www.rdocumentation.org/packages/raster/versions/3.0-12/topics/interpolate> 
# library(fields)
# tps <- Tps(xyFromCell(convenience_raster, 1:ncell(convenience_raster)), getValues(convenience_raster))
# p <- raster(convenience_raster)
# p <- interpolate(p, tps)
# writeRaster(p, "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/convenience_raster_interpolated.tif", overwrite=TRUE)
p <- raster("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/convenience_raster_interpolated.tif")

p_norm <- calc(p, function(x){
    (x-min(getValues(p)))/(max(getValues(p))-min(getValues(p)))
})
# plot(p)
plot(p_norm)

# # contour lines for the convenience map
# cont <- rasterToContour(p_norm)
# plot(cont)
# plot(predic_raster)
# plot(cont, add=TRUE)


# 2. have rbinom selection of that cell probability based on convenience weights
# 3. follow the random selection 
convenience_sampling <- function(suitability.raster, convenience.raster, samplesize){
  sampleout <- c()
  i <- 1
  while(i <= samplesize){
    randcell <- ceiling(runif(1, min = 1, max = length(suitability.raster)))
      if(rbinom(1,1,getValues(convenience.raster)[randcell]) == 1){
        
        if(rbinom(1, 1, getValues(suitability.raster)[randcell]) == 1){
          sampleout <- rbind(sampleout,xyFromCell(suitability.raster, randcell))
          i <- i+1
        }
      }
    
  }
  sampleout
  
}

 

```

Sampling images
```{r}

########### Systematic (true sample) ############
 
for(x in 1:10){
  samplesys1 <- systematic_sampling(predic_raster, 100)
      
  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig2_SystematicTrue",x,".jpg", sep=""),
       width=145, height=100,units='mm', res=300)
  par(mar=c(2.1,2.1,2.1,1.1))
  plot(predic_raster, main = ""); points(samplesys1, pch=16, cex=0.25)
  mtext("d)", side=3, line=0.5, adj=-0.1)
  mtext("Systematic sampling (n = 100)", side=3, line=0, adj=0.5, cex=1.15)
  
  dev.off()
  }


############ Simple random ###############

for(x in 1:10){
  random1 <- random_sampling(predic_raster, 100)
  
  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig2_simplerandom",x,".jpg", sep=""),
       width=145, height=100,units='mm', res=300)
  par(mar=c(2.1,2.1,2.1,1.1))
  plot(predic_raster, main = ""); points(random1, pch=16, cex=0.25)
  mtext("a)", side=3, line=0.5, adj=-0.1)
  mtext("Simple random sampling (n = 100)", side=3, line=0, adj=0.5, cex=1.15)
  
  dev.off()
  }

############ Adaptive Cluster ###############
for(x in 1:10){
  cluster1 <- adaptive_cluster(predic_raster, 100)
  print(nrow(cluster1))
    
  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig2_AdaptiveCluster",x,".jpg", sep=""),
       width=145, height=100,units='mm', res=300)
  par(mar=c(2.1,2.1,2.1,1.1))
  plot(predic_raster, main = ""); points(cluster1, pch=16, cex=0.25)
    mtext("b)", side=3, line=0.5, adj=-0.1)
  mtext("Adaptive cluster sampling (n = 100)", side=3, line=0, adj=0.5, cex=1.15)
  
  dev.off()
}   

############ Convenience (based on samples from 1990, 2000, and 2010) ##########
for(x in 1:10){
  conve1 <- convenience_sampling(predic_raster, p_norm, 100)
  print(nrow(conve1))
    
  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/Fig2_Convenience",x,".jpg", sep=""),
       width=145, height=100,units='mm', res=300)
  par(mar=c(2.1,2.1,2.1,1.1))
  plot(predic_raster, main = ""); points(conve1, pch=16, cex=0.25)
  contour(p_norm, levels = c(0,0.25,0.5,0.75,1), add=TRUE)
  mtext("c)", side=3, line=0.5, adj=-0.1)

  mtext("Convenience sampling (n = 100)", side=3, line=0, adj=0.5, cex=1.15)
  
  dev.off()
}  
```


Maxent compared to the 'true' distribution
# Maxent function  
  Background points are sampled randomly from the cells that are not NA in the first predictor variable, unless background points are specified with argument a.
```{r}
#test 
rasterstack <- rasterstack_norm
# sampling_type <- "system"
# pathstart <- "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/maxent_simulations/"
true.dist <- predic_raster
# reps <- 2
# sampling_type <- "ra"
# rm(rasterstack); rm(true.dist); rm(sampling_type)

# rasterstack = predictor variables; true.dist = true distribution of suitability; conveience.raster = the raster of density of all herbarium collections sampled from three different years, could be roads or trails

maxent_sampling <- function(rasterstack, true.dist, sampling_type = c("random","systematic","convenience","cluster"),
                            convenience.raster = p_norm,
                            reps = 100, samplesize, pathstart = pathstart){
  if(grepl(sampling_type, "random")){
    sample_xy <- random_sampling(suitability.raster = true.dist,samplesize = samplesize)
  } 
  if(grepl(sampling_type, "systematic")){
    sample_xy <- systematic_sampling(suitability.raster = true.dist, samplesize = samplesize)
  }
  if(grepl(sampling_type, "convenience")){
    sample_xy <- convenience_sampling(suitability.raster = true.dist, convenience.raster, samplesize = samplesize)
  }
  if(grepl(sampling_type, "cluster")){
    sample_xy <- adaptive_cluster(suitability.raster = true.dist, samplesize = samplesize)
  }
  
  for(r in 1:reps){
    # fold <- kfold(sample_xy, k=5) # withold 20% of the sample for testing; or just use whole sample and test with random background?
    # occtest <- sample_xy[fold == 1,]
    # occtrain <- sample_xy[fold != 1,]
    # xm <- maxent(x = rasterstack, p = occtrain,  args=c(
    xm <- maxent(x = rasterstack, p = sample_xy, args=c(
  # 'maximumbackground=10000',
  'defaultprevalence=1.00',
  # 'betamultiplier=0.5',
  # 'pictures=true',
  # 'randomtestpoints=30',
  'linear=true',
  'quadratic=false',
  'product=false',
  'threshold=false',
  'hinge=false',
  # 'threads=2',
  'responsecurves=true',
  'jackknife=true',
  'askoverwrite=false'
))
    # write.csv(data.frame(sample_xy, fold), paste(pathstart,"maxentOcc",sampling_type,"rep",r,".csv",sep=""))    
    write.csv(sample_xy, paste(pathstart,"maxentOcc",sampling_type,"rep",r,"SampleSize",samplesize,".csv",sep=""))
    save(xm, file = paste(pathstart, "maxent",sampling_type,"rep",r,"SampleSize",samplesize,".Rda",sep=""))
    
    gc()
    ncores <- detectCores()-1
    cl = parallel::makeCluster(ncores)
    doParallel::registerDoParallel(cl,ncores)
    
    # compute indices for data splitting
    rows <- 1:nrow(rasterstack)
    split <- sort(rows%%ncores)+1
    outname <- paste(pathstart,"Predictmaxent",sampling_type,"rep",r,sep="")
    
    #predict with subsets of predictor dataset
    foreach(i = unique(split), .combine = c) %dopar% {
      rows_sub <- rows[split==i]
      sub <- raster::crop(rasterstack, raster::extent(rasterstack, min(rows_sub), max(rows_sub),
                                                      1, ncol(rasterstack)))
      raster::predict(sub, xm, filename = paste(outname, i, sep="_"), overwrite = TRUE)
    }
    
    # Do I care? Do I need to get the AUC? I don't think I care
    # random background data
    # bg <- randomPoints(rasterstack, 300)
    # e <- evaluate(xm, p=occtest, a=bg, x=rasterstack)
    # save(e, file = paste(pathstart, "evaluate", sampling_type,"rep",r,".Rda",sep=""))
    # 
    rm(xm)
    gc()
    stopCluster(cl)
  }
  
   lapply(1:reps, function(k){
    resultpath <- list.files(path = pathstart, 
                             pattern = paste("Predictmaxent",sampling_type,"rep",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste(pathstart,"ProbTiff",sampling_type,"Rep",k,"SampleSize",samplesize,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
  })
}

# 
# plot(xm)
# r <- response(xm, var="bio19_12")
# plot(r, type = "l")
# response(xm)

```

<https://www.youtube.com/watch?v=42rSg60Rk-k&feature=youtu.be&fbclid=IwAR3AvdVB3U7YVI0aVrfm-KYGQm0Vnfo_W3udZL2YoH0h5vQjxQjp6_Kde7A>
<https://www.youtube.com/watch?v=2vgX7QoyPJo&feature=youtu.be&fbclid=IwAR2mvP8p9LDdz1LefrCwjcMMXi1l_uLI1m-1-sIiydHqHyIpMwcooSoz6lc> 

```{r}

# pathstart <- "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/maxent_simulations/"
# pathstart <- "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/maxent_simulations_20200313/"

pathstart <- "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/maxent_simulations_20200314/"

# 3:10, 
lapply(c(20, 30, 50, 100), function(sampsize){
    maxent_sampling(rasterstack = rasterstack_norm, true.dist = predic_raster, sampling_type = "random", reps = 100, samplesize = sampsize, pathstart = pathstart)
    
    # maxent_sampling(rasterstack = rasterstack_norm, true.dist = predic_raster, sampling_type = "system", reps = 10, samplesize = 100, pathstart = pathstart)
    
    maxent_sampling(rasterstack = rasterstack_norm, true.dist = predic_raster, sampling_type = "convenience", reps = 100, samplesize = sampsize, pathstart = pathstart)
    
    maxent_sampling(rasterstack = rasterstack_norm, true.dist = predic_raster, sampling_type = "cluster", reps = 100, samplesize = sampsize, pathstart = pathstart)
})


# errors unknown, NA by coercion??
lapply(c(6:10, 20,30,50,100), function(sampsize){
  maxent_sampling(rasterstack = rasterstack_norm, true.dist = predic_raster, sampling_type = "systematic", reps = 100, samplesize = sampsize, pathstart = pathstart)
})

# failed at cluster sample size 20 rep 85...

for(ss in c(3:10, 20, 30, 50, 100)){
  cluster1 <- adaptive_cluster(predic_raster, ss)
  plot(cluster1)
}
    
```


 

# Pattern: correlation to the true distribution  
```{r}

# c(3:10, 20,30,50,100)
for(ss in c(3:10, 20,30,50,100)){
  
  r_random <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffrandomRep", sample(1:100,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/random2true_samplesize",ss,".jpg", sep=""),
       width=173, height=105,units='mm', res=300)
  
  plot(getValues(predic_raster), getValues(r_random), 
       xlim = c(0,1), ylim = c(0,1), pch=16, cex=0.25, xlab="True Distribution", ylab="Random sampling",main=paste("Suitability by Pixel, Sample Size",ss))
for(i in 1:5){
  r_random <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffrandomRep", sample(1:100,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  points(getValues(predic_raster), getValues(r_random), pch=16, cex=0.5, col = rgb(i/(i+1),0,i/(i+5),0.05))
}
  dev.off()
}

# systematic
for(ss in c(3:10, 20,30,50,100)){
  
  r_systematic <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffsystematicRep", sample(1:100,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/systematic2true_samplesize",ss,".jpg", sep=""),
       width=173, height=105,units='mm', res=300)
  
  plot(getValues(predic_raster), getValues(r_systematic), 
       xlim = c(0,1), ylim = c(0,1), pch=16, cex=0.25, xlab="True Distribution", ylab="Systematic sampling",main=paste("Suitability by Pixel, Sample Size",ss))
for(i in 1:5){
  r_systematic <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffsystematicRep", sample(1:100,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  points(getValues(predic_raster), getValues(r_systematic), pch=16, cex=0.5, col = rgb(i/(i+1),0,i/(i+5),0.05))
}
  dev.off()
}


# adaptive cluster
for(ss in c(3:10,20,30,50,100)){
    r_clust <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffclusterRep", sample(1:80,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))

  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/cluster2true_samplesize",ss,".jpg", sep=""),
       width=153, height=105,units='mm', res=300)
  
  plot(getValues(predic_raster), getValues(r_clust), 
       xlim = c(0,1), ylim = c(0,1), pch=16, cex=0.25, xlab="True Distribution", ylab="Adaptive Cluster sampling",main=paste("Suitability by Pixel, Sample Size",ss))
for(i in 1:5){
  r_clust <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffclusterRep",sample(1:80,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  points(getValues(predic_raster), getValues(r_clust), pch=16, cex=0.25, col = rgb(i/(i+1),i/(i+i),i/(i+5),0.05))
}
  dev.off()
}

# Convenience
for(ss in c(3:10,20,30,50,100)){
    r_clust <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffconvenienceRep", sample(1:80,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))

  jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/convenience2true_samplesize",ss,".jpg", sep=""),
       width=153, height=105,units='mm', res=300)
  
  plot(getValues(predic_raster), getValues(r_clust), 
       xlim = c(0,1), ylim = c(0,1), pch=16, cex=0.25, xlab="True Distribution", ylab="Convenience sampling",main=paste("Suitability by Pixel, Sample Size",ss))
for(i in 1:5){
  r_clust <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffconvenienceRep",sample(1:80,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  points(getValues(predic_raster), getValues(r_clust), pch=16, cex=0.25, col = rgb(i/(i+1),i/(i+i),i/(i+5),0.05))
}
  dev.off()
}

```


```{r}

library(MASS)
library("RColorBrewer")
library(dplyr)
library(gtable)

random2true <- lapply(c(10, 20,30,50,100), function(ss){
  
  r_random <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffrandomRep", sample(1:100,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  # jpeg(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/random2true_samplesize",ss,".jpg", sep=""),
       # width=173, height=105,units='mm', res=300)

  random2true <- data.frame(true = getValues(predic_raster), random = getValues(r_random), samplesize = ss)

  
  plot <- ggplot(random2true, aes(true, random, colour = as.factor(samplesize)))+
    stat_density2d(aes(fill = ..level..), alpha = 0.3, geom = "polygon")+
    scale_fill_continuous(low = "grey", high = colors()[ss], space = "Lab",
                          name = paste("samplesize =", ss))+
    scale_color_discrete(guide = FALSE)+
    expand_limits(x = c(0,1), y = c(0,1))+
    theme_bw()
  
  out <- list(sample_n(random2true, size = 100000), plot)
  out
})
```

```{r}


for(i in 1:5){
  print(random2true[[i]][[2]])
}

```

```{r}

for(ss in c(3:10, 20,30,50,100)){ #
  for(sampd in c("random", "cluster", "systematic", "convenience")){
    
    r_design <- do.call(rbind,lapply(sample(1:100, 10), function(s){
      r1 <- raster(list.files(path = pathstart, 
                                        pattern = paste("ProbTiff", sampd, "Rep", s,"SampleSize",ss, ".tif", sep=""),
                                        full.names = TRUE))
    
      design2true <- data.frame(true = getValues(predic_raster), V1 = getValues(r1), samplesize = ss)
      design2true[sample(1:nrow(design2true), 100000),]
    }))

    p <- ggplot(r_design, aes(true, V1, colour = as.factor(samplesize)))+
      geom_point(alpha=0.05, size=0.1)+
      stat_density2d(aes(fill = ..level..), alpha = 0.3, geom = "polygon", n = 500)+
      scale_fill_continuous(low = "grey", high = colors()[30], space = "Lab",
                            name = paste("samplesize =", ss))+
      scale_color_discrete(guide = FALSE)+
      expand_limits(x = c(0,1), y = c(0,1))+
      theme_bw()+ 
      ylab(paste(sampd))+
      geom_abline(intercept = 0, slope = 1)
    
    # ggsave(paste("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/", 
    ggsave(paste("Q:/Research/MEDL_folder/Dissertation/SDM_SamplingDesign/Figures/",
                 sampd, "2true_density_samplesize",ss,".jpg", sep=""),
           plot = p,
           width=173, height=105,units='mm')
  }
}

```


```{r}  
  ggplot(random2true, aes(true, random, colour = as.factor(samplesize)))+
    geom_point(pch=16, alpha = 0.25)+
    expand_limits(x = c(0,1), y = c(0,1))+
    xlab("True Distribution")+
    ylab("Random sampling")+
    stat_density2d(aes(fill = ..level..), alpha = 0.5, geom = "polygon", data = random2true)+
    scale_fill_viridis_c()+
    theme_bw()
    
    
for(i in 1:5){
  r_random <- raster(list.files(path = pathstart, 
                                    pattern = paste("ProbTiffrandomRep", sample(1:100,1),"SampleSize",ss, ".tif", sep=""),
                                    full.names = TRUE))
  points(getValues(predic_raster), getValues(r_random), pch=16, cex=0.5, col = rgb(i/(i+1),0,i/(i+5),0.05))
}
  # dev.off()
# }
```



```{r}


# c("system","random","convenience","cluster")

# Sample from the replicates with replacement; ProbTiffsystematicRep100SampleSize3
repsXsamplesize <- lapply(c(3:10, 20, 30, 50, 100), function(x){
  reps <- lapply(1:100, function(rep){
      system <- raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffsystematicRep", sample(1:10,1), "SampleSize", x,".tif", sep=""),
                                  full.names = TRUE))
      random <-  raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffrandomRep", sample(1:10,1), "SampleSize", x,".tif", sep=""),
                                  full.names = TRUE))
      convenience <-  raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffconvenienceRep", sample(1:10,1), "SampleSize", x,".tif", sep=""),
                                  full.names = TRUE))
      cluster <-  raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffclusterRep", sample(1:10,1), "SampleSize", x,".tif", sep=""),
                                  full.names = TRUE))
      out<- list(system, random, convenience, cluster)
      out
      })
  reps
})

# Histogram of each alone as correlation to true
Cor2True <- do.call(rbind, lapply(1:(length(c(3:10, 20,30,50,100))), function(ss){
  systemcor <- do.call(rbind,lapply(1:100, function(i){
    corout <- cor(getValues(repsXsamplesize[[ss]][[i]][[1]]), getValues(predic_raster), method = "pearson")
    corout
  }))
  randomcor <- do.call(rbind,lapply(1:100, function(i){
    corout <- cor(getValues(repsXsamplesize[[ss]][[i]][[2]]), getValues(predic_raster), method = "pearson")
    corout
  }))
  conveniencecor <- do.call(rbind,lapply(1:100, function(i){
    corout <- cor(getValues(repsXsamplesize[[ss]][[i]][[3]]), getValues(predic_raster), method = "pearson")
    corout
  }))
  clustercor <- do.call(rbind,lapply(1:100, function(i){
    corout <- cor(getValues(repsXsamplesize[[ss]][[i]][[4]]), getValues(predic_raster), method = "pearson")
    corout
  }))
  data.frame(systemcor, randomcor, conveniencecor, clustercor, SampleSize = ss)
})
)
  
# ggplot(Cor2True, aes(systemcor, color = as.factor(SampleSize)))+
#   geom_freqpoly(position = "dodge", na.rm = TRUE)+
#   scale_color_manual(values=colors()[sample(1:600, 12)],
#                     name="Systematic sampling\nSample Size",
#                     breaks=c(1:12),
#                     labels=c(3:10,20,30,50,100))+
#   theme_bw()



ggplot(Cor2True, aes(systemcor, fill = as.factor(SampleSize)))+
  geom_histogram(position = "dodge", na.rm = TRUE, binwidth = 0.15)+
  expand_limits(x = c(-1,1))+
  scale_fill_manual(values=rainbow(12),
                    name="Systematic sampling\nSample Size",
                    breaks=c(1:12),
                    labels=c(3:10,20,30,50,100))+
  theme_bw()


ggplot(Cor2True, aes(randomcor, fill = as.factor(SampleSize)))+
  geom_histogram(position = "dodge", na.rm = TRUE, binwidth = 0.15)+ #
  expand_limits(x = c(-1,1))+
  scale_fill_manual(values=rainbow(12),
                    name="Systematic sampling\nSample Size",
                    breaks=c(1:12),
                    labels=c(3:10,20,30,50,100))+
  theme_bw()
``` 





```{r}
true_random <- lapply(1:100, function(x){
      
          ## Correlation to true
          rtrue <- raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffsystemRep", sample(1:10,1), ".tif", sep=""),
                                  full.names = TRUE))
          rsimprand <- raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffrandomRep", sample(1:10,1), ".tif", sep=""),
                                  full.names = TRUE))
          cor_True_System <- layerStats(stack(rtrue, predic_raster), 'pearson', na.rm=TRUE)  # non-parameteric, not normally distributied and relationship not linear
          cor_True_System$`pearson correlation coefficient`
          
          cor_True_Random <- layerStats(stack(rsimprand, predic_raster), 'pearson', na.rm=TRUE)  # non-parameteric, not normally distributied and relationship not linear
          cor_True_Random$`pearson correlation coefficient`
          
          out <- data.frame(True = cor_True_System$`pearson correlation coefficient`[2], Random = cor_True_Random$`pearson correlation coefficient`[2])
          out
})

true_random <- do.call(rbind, true_random)

ggplot(true_random, aes(True, Random))+
  geom_point()+
  theme_bw()+
  geom_abline(slope = 1, intercept = 0)+
  scale_x_continuous(limits = c(0,1))+
  scale_y_continuous(limits = c(0,1))


cluster_random <- do.call(rbind,lapply(1:100, function(x){
      
          ## Correlation to true
          rclust <- raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffclusterRep", sample(1:10,1), ".tif", sep=""),
                                  full.names = TRUE))
          rsimprand <- raster(list.files(path = pathstart, 
                                  pattern = paste("ProbTiffrandomRep", sample(1:10,1), ".tif", sep=""),
                                  full.names = TRUE))
          cor_True_System <- layerStats(stack(rclust, predic_raster), 'pearson', na.rm=TRUE)  # non-parameteric, not normally distributied and relationship not linear
          cor_True_System$`pearson correlation coefficient`
          
          cor_True_Random <- layerStats(stack(rsimprand, predic_raster), 'pearson', na.rm=TRUE)  # non-parameteric, not normally distributied and relationship not linear
          cor_True_Random$`pearson correlation coefficient`
          
          out <- data.frame(Cluster = cor_True_System$`pearson correlation coefficient`[2], Random = cor_True_Random$`pearson correlation coefficient`[2])
          out
}))


ggplot(cluster_random, aes(Cluster, Random))+
  geom_point()+
  theme_bw()+
  geom_abline(slope = 1, intercept = 0)+
  scale_x_continuous(limits = c(0,1))+
  scale_y_continuous(limits = c(0,1))
```




# Process: variable importance
```{r}

modelstoload <- unlist(lapply(c("random","system"), function(x){
  resultpath <- list.files(path = pathstart,
                           pattern = paste("^","maxent",x,"rep",sep=""),
                           full.names = TRUE)
  }))


load(modelstoload[1])

maxModels <- lapply(modelstoload, function(x) load(x))
response(xm) # response curve shapes
plot(xm) # variable contriubtion
var.importance <- data.frame(Var = row.names(xm@results), xm@results)[7:12,]

# evaluate models
evalstoload <- list.files(path = pathstart,
                           pattern = "evaluate",
                           full.names = TRUE)
evalModels <- lapply(evalstoload, function(x) load(x))

load(evalstoload[1])
threshold(e)  # can get prevalence and other measures for thresholds
plot(e, 'ROC')
```



# Nicheoverlap function    
```{r}

```


# JAGS or make a gibbs sampler?   
Just raster stack glm with the enviornmental variable relationships. 
```{r}
# The distribution of suitable values by layer
ana_rast <- stack(rasterstack3_z, clru1_z[[3]])
# x <- calc(ana_rast, function(x) if(ana_rast[[7]]>0.3) lm(x~time))

# Distribution in suitable 
for(i in names(ana_rast)[-7]){
  hist(ana_rast[[i]][ana_rast[[7]]>0.3], main=paste(i))
}
for(i in names(ana_rast)[-7]){
  hist(ana_rast[[i]][ana_rast[[7]]>0.5], main=paste(i))
}
# Take the central tendancy as alpha and the SD as var? those are the first step to estimate those parameters from the random sample? Then take the output from those as the input 

# if beta then dbeta(ElevationResampled_bioclim, $alpha, $beta, ncp = based on derivation as a Poisson mixture of betas Johnson et al 1995)
model1 <- ElevationResampled_bioclim[]*x

r_suitability <- stackApply(rasterstack3_z, indices = 1:6, function(x) )

```





Cite Abdi, Abdulhakim M., et al. "The El Niño–La Niña cycle and recent trends in supply 
 and demand of net primary productivity in African drylands." Climatic Change 138.1-2 (2016): 111-125. 
 https://link.springer.com/article/10.1007/s10584-016-1730-1  
Don't know if I need this 
<https://www.hakimabdi.com/blog/test-pixelwise-correlation-between-two-time-series-of-gridded-satellite-data-in-r?fbclid=IwAR0aWWWwKX6IQUhEpzT1saT2yXtHPpwFmesC6eKXRbtMaGoGSdffZc35kWw>
```{r}
gridcorts <- function(rasterstack, method, type=c("corel","pval","both")){
  # Values for (layers, ncell, ncol, nrow, method, crs, extent) come straight from the input raster stack
  # e.g. nlayers(rasterstack), ncell(rasterstack)... etc.
  print(paste("Start Gridcorts:",Sys.time()))
  print("Loading parameters")
  layers=nlayers(rasterstack);ncell=ncell(rasterstack);
  ncol=ncol(rasterstack);nrow=nrow(rasterstack);crs=crs(rasterstack);
  extent=extent(rasterstack);pb = txtProgressBar(min = 0, max = ncell, initial = 0)
  print("Done loading parameters")
  mtrx <- as.matrix(rasterstack,ncol=layers)
  empt <- matrix(nrow=ncell, ncol=2)
  print("Initiating loop operation")
  if (type == "corel"){
    for (i in 1:ncell){
      setTxtProgressBar(pb,i)
      if (all(is.na(mtrx[i,1:(layers/2)])) | all(is.na(mtrx[i,((layers/2)+1):layers]))){ 
        empt[i,1] <- NA 
      } else 
        if (sum(!is.na(mtrx[i,1:(layers/2)]/mtrx[i,((layers/2)+1):layers])) < 4 ){
          empt[i,1] <- NA 
        } else 
          empt[i,1] <- as.numeric(cor.test(mtrx[i,1:(layers/2)], mtrx[i,((layers/2)+1):layers],method=method)$estimate)
    }
    print("Creating empty raster")
    corel <- raster(nrows=nrow,ncols=ncol,crs=crs)
    extent(corel) <- extent
    print("Populating correlation raster")
    values(corel) <- empt[,1]
    print(paste("Ending Gridcorts on",Sys.time()))
    corel
  } 
  else
    if (type == "pval"){
      for (i in 1:ncell){
        setTxtProgressBar(pb,i)
        if (all(is.na(mtrx[i,1:(layers/2)])) | all(is.na(mtrx[i,((layers/2)+1):layers]))){ 
          empt[i,2] <- NA 
        } else 
          if (sum(!is.na(mtrx[i,1:(layers/2)]/mtrx[i,((layers/2)+1):layers])) < 4 ){
            empt[i,2] <- NA 
          } else 
            empt[i,2] <- as.numeric(cor.test(mtrx[i,1:(layers/2)], mtrx[i,((layers/2)+1):layers],method=method)$p.value)
      }
      pval <- raster(nrows=nrow,ncols=ncol,crs=crs)
      extent(pval) <- extent
      print("Populating significance raster")
      values(pval) <- empt[,2]
      print(paste("Ending Gridcorts on",Sys.time()))
      pval
    }
  else
    if (type == "both"){
      for (i in 1:ncell){
        setTxtProgressBar(pb,i)
        if (all(is.na(mtrx[i,1:(layers/2)])) | all(is.na(mtrx[i,((layers/2)+1):layers]))){ 
          empt[i,] <- NA 
        } else 
          if (sum(!is.na(mtrx[i,1:(layers/2)]/mtrx[i,((layers/2)+1):layers])) < 4 ){
            empt[i,] <- NA 
          } else {
            empt[i,1] <- as.numeric(cor.test(mtrx[i,1:(layers/2)], mtrx[i,((layers/2)+1):layers],method=method)$estimate) 
            empt[i,2] <- as.numeric(cor.test(mtrx[i,1:(layers/2)], mtrx[i,((layers/2)+1):layers],method=method)$p.value)
          }
      }
      c <- raster(nrows=nrow,ncols=ncol,crs=crs)
      p <- raster(nrows=nrow,ncols=ncol,crs=crs)
      print("Populating raster brick")
      values(c) <- empt[,1]
      values(p) <- empt[,2]
      brk <- brick(c,p)
      extent(brk) <- extent
      names(brk) <- c("Correlation","Pvalue")
      print(paste("Ending Gridcorts on",Sys.time()))
      brk
    }
}
```


