---
title: "Sampling impacts on SDM"
author: "Michelle DePrenger-Levin"
date: "2/15/2020"
output: html_document
---

```{r}
# install.packages("installr")
# require(installr)
# updateR()

# maybe a mix of R3.5.X and R3.6.X so need to update everything?
# update.packages(ask = FALSE, checkBuilt = TRUE)

# maybe broken and not getting updated or removed, need to find and delete
# find.package("knitr")
# remove.packages("knitr")
# 
# install.packages("dismo")

library(diagram)

require(DiagrammeR)

# simmulations
library(virtualspecies)

# SDM
library(rJava)
library(dismo)

# Mapping
library(rgeos)
library(raster)
library(maptools)
library(dismo)
library(RNRCS)
library(rgdal)


# Parallelization
library(foreach)
library(parallel)
library(doParallel)
library(magrittr) # pipe %>%


thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}
```
diagram
```{r}

m <- matrix(nrow=6, ncol = 6, byrow = TRUE, data = c(
  # P  f  s  g  dd  sz  c  m
   0, 0, 0, 0, 0, 0, 0, 0,0, 
   1, 0, 0, 0, 0, 0, 0, 0,0, 
   0, 2, 0, 0, 0, 0, 0, 0,0, 
   0, 0, 3, 0, 0, 0, 0, 0,0, 
   0, 0, 0, 4, 0, 0, 0, 0,0, 
   0, 5, 6, 5, 0, 0, 0, 0,0, 
   0, 8, 9,10, 0, 0, 0, 0,0, 
   0,11,12,13, 0, 0, 0, 0,0
   )) 
names <- c("Model Organism", "Climate Drivers", "'True' distribution", "sample", "SDMs",
           "Compare to 'True'")

# m[2,1] <- m[3,1] <- m[4,1] <- m[5,1] <- m[6,2] <- m[6,3] <- m[6,4] <- 
#   m[7,2] <- m[7,3] <- m[7,4] <- 
#   m[8,2] <- m[8,3] <- m[8,4] <- "lm" 
plotmat(m, pos = c(1, 1,1,1,1,1), curve = 0, name = names, 
        box.type = "square", cex.txt = 0.45, box.prop = 0.3,
        arr.type = "triangle", arr.pos = 0.5, prefix = "m")


```

DiagrammeR 
```{r}
# Erysimum capitatum or Rhodiola integrifolium or Hymenoxys grandiflora

grViz("digraph flowchart {
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = rectangle]        
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']
      tab4 [label = '@@4']
      tab5 [label = '@@5']
      tab6 [label = '@@6']
      tab7 [label = '@@7']
      tab8 [label = '@@8-1']
      tab9 [label = '@@8-2']
      tab10 [label = '@@8-3']
      tab11 [label = '@@8-4']
      
      # edge definitions with the node IDs
      tab1 -> tab3 -> tab4;
      tab4 -> tab8;
      tab4 -> tab9;
      tab4 -> tab10;
      tab4 -> tab11;
      tab2 -> tab3;
      tab5 -> tab6;
      tab8 -> tab5;
      tab9 -> tab5;
      tab10 -> tab5;
      tab11 -> tab5;
      tab5 -> tab6;
      tab5 -> tab6;
      tab5 -> tab6;
      tab5 -> tab6;
      tab7 -> tab2;
      }

      [1]: 'Model organism (Claytonia rubra)'
      [2]: 'Climate Drivers'
      [3]: 'Build true distribution'
      [4]: 'sample'
      [5]: 'SDM'
      [6]: 'Compare with True'
      [7]: 'snow melt, min and max temp, soil moisture, dummy'
      [8]: c('Ad Hoc','Adaptive cluster sampling','Neutral sampling','Random')
      ")


```

something about the update broke the double digit useage
```{r}

grViz("digraph flowchart {
      # node definitions with substituted label text
      node [fontname = Helvetica, shape = rectangle]        
      a [label = '@@1']
      b [label = '@@2']
      c [label = '@@3']
      d [label = '@@4']
      e [label = '@@5']
      f [label = '@@6']
      g [label = '@@7']
      h [label = '@@8-1']
      i [label = '@@8-2']
      j [label = '@@8-3']
      k [label = '@@8-4']
      
      # edge definitions with the node IDs
      a -> c -> d;
      d -> h;
      d -> i;
      d -> j;
      d -> k;
      b -> c;
      e -> f;
      h -> e;
      i -> e;
      j -> e;
      k -> e;
      e -> f;
      e -> f;
      e -> f;
      e -> f;
      g -> b;
      }

      [1]: 'Model organism (Claytonia rubra)'
      [2]: 'Climate Drivers'
      [3]: 'Build true distribution'
      [4]: 'sample'
      [5]: 'SDM'
      [6]: 'Compare with True'
      [7]: 'snow melt, min and max temp, soil moisture, dummy'
      [8]: c('Systematic','Adaptive cluster sampling','Neutral sampling','Random')
      ")

```


Snow melt, temperature
```{r}
# install.packages("snotelr")
# library("snotelr")
# 
# library(snotelr)
# snotel.explorer()

# install.packages("RNRCS")


grabNRCS.meta()
snow1 <- grabNRCS.data(network = 'SNTL', site_id = 2229, timescale = "monthly", DayBgn = '2019-01-01', DayEnd = '2020-01-01')


load("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/hackathon/Simulations/SNOWHLNDmodelavg_annual.RData") # 1920-2005
load("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/hackathon/Simulations/SNOWHLNDmodelavg.raster.RData")
load("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/hackathon/Simulations/SNOWHLNDmodel17_annual.RData") # 5, 17 year blocks averaged 
load("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/hackathon/Simulations/SNOWHLNDmodel17_raster.RData")


str(SNOWHLNDmodel17.raster[[1]])
plot(SNOWHLNDmodel17.raster[[1]][[1]])
```

```{r}
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")

colocounties <- spTransform(colocounties.UTM,CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")
bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif")
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)
```


Use maxent, and then refine the relatonships of environment and points  
```{r}
hygr <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Hymenoxys grandiflora_SEINet/occurrences.csv")

plot(hygr$decimalLongitude, hygr$decimalLatitude)

clar <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Claytonia arctica_SEINet/occurrences.csv")

clru <- read.csv("C:/Users/DePrengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/Claytonia rubra_SEINet/occurrences.csv")

plot(colocounties)
points(clru$decimalLongitude, clru$decimalLatitude, col="blue")
points(clar$decimalLongitude, clar$decimalLatitude)


```


```{r}
hygr <- hygr[complete.cases(hygr$decimalLatitude),]

pointsspdf <- SpatialPointsDataFrame(coords = hygr[,c("decimalLongitude","decimalLatitude")],
                                     data = hygr,
                                     proj4string = CRS("+proj=longlat +datum=WGS84"))

plot(bio12_res)
# plot(SNOWHLNDmodel17.raster[[1]][[1]], add=TRUE)
points(pointsspdf, pch = 16)
plot(colocounties, add=TRUE)

```

```{r}

clru <- clru[complete.cases(clru$decimalLatitude),]
clruspdf <- SpatialPointsDataFrame(coords = clru[,c("decimalLongitude","decimalLatitude")],
                                     data = clru,
                                     proj4string = CRS("+proj=longlat +datum=WGS84"))


plot(SNOWHLNDmodel17.raster[[1]][[1]])
points(clruspdf, pch = 16)
plot(colocounties, add=TRUE)

snow11 <- rotate(SNOWHLNDmodel17.raster[[1]][[1]])
plot(snow11)
plot(SNOWHLNDmodel17.raster[[1]][[1]])

snowclip11 <- mask(snow11, colocounties)
plot(snowclip11)

snowcrop11 <- crop(snow11, extent(colocounties), snap="out")
plot(snowcrop11)
points(clar$decimalLongitude, clar$decimalLatitude)
points(hygr$decimalLongitude, hygr$decimalLatitude, col="blue")
```
SDMtune
```{r}
install.packages("SDMtune")
library(SDMtune)
```

# Virtual species 
<http://borisleroy.com/files/virtualspecies-tutorial.html>
virtual species based on Claytonia rubra   
```{r}

names(rasterstack)

# or use all worldclim data
# bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)
# save(bioclim.colorado, file = "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/bioclim.colorado.Rda")
load("C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/R/bioclim.colorado.Rda")
bioclim.colorado

coloElev_resam <- resample(coElev_res, bioclim.colorado[[1]], method = 'bilinear')
coloElev <- crop(coloElev_resam, extent(colocounties), snap="out")
bioclim.stack <- crop(rasterstack1,extent(colocounties), snap="out")
rasterstack2 <- stack(coloElev,bioclim.stack)

# Variables bio1 (annual mean temperature in °C * 10) and bio2 (annual precipitation)
plot(bioclim.colorado[[c("bio1_12","bio12_12")]])


```

Define response functions
```{r}

climate_clru <- raster::extract(bioclim.colorado, clru[,c("decimalLongitude","decimalLatitude")])

mu_clru <- colMeans(climate_clru, na.rm = TRUE)
sd_clru <- apply(climate_clru, 2, function(x) sd(x, na.rm = TRUE))

# gaussian distribution functions 
dnorm_clru <- mapply(function(x,y) dnorm(x = 150, mean = x, sd = y), mu_clru, sd_clru)


# using dnorm to generate vitural species
# my.parameters <- mapply(function(bio, x, y) formatFunctions(assign(paste(bio), 
#                                                                    c(fun = 'dnorm', mean = x, sd = y))),
#                         names(bioclim.colorado), mu_clru, sd_clru)
mu_clru[11]
sd_clru[11]

# my.parameters2 <- formatFunctions(bio1_12 = c(fun = 'dnorm', assign('mean', mu_clru[1]), 
#                                              assign('sd', mu_clru[1])),
#                                  bio12_12 = c(fun = 'dnorm', assign('mean', mu_clru[12]), 
#                                               assign('sd', mu_clru[12])))
# 
# my.first.species2 <- generateSpFromFun(raster.stack = bioclim.colorado[[c("bio1_12", "bio12_12")]],
#                                               parameters = my.parameters2,
#                                               plot = TRUE)

# bio19 precip of coldest quarter to represent snow accumulation
# bio11 mean temp of coldest quarter
my.parameters <- formatFunctions(bio1_12 = c(fun = 'dnorm', mean = 81.5, sd = 30.4),
                                 bio12_12 = c(fun = 'dnorm', mean = 505.9, sd = 182),
                                 bio19_12 = c(fun = 'dnorm', mean = 198.1, sd = 117.8),
                                 bio11_12 = c(fun = 'dnorm', mean = -1.38, sd = 37.4))


my.first.species <- generateSpFromFun(raster.stack = 
                                        bioclim.colorado[[c("bio1_12", "bio12_12", "bio19_12", "bio11_12")]],
                                              parameters = my.parameters,
                                              plot = TRUE)

plot(colocounties);plot(my.first.species, add=TRUE);plot(colocounties, add=TRUE); points(clruspdf)
```

Change the functions to use built in linear, quadratic, logistic, normal, and beta or make your own  
logisticFun   (alpha=7.42; beta=272.035035035035) has all 1 suitability until the beta and drops fast to 0
```{r}
rasterstack1 <- stack(bioclim.colorado[[c(1,11,12,19)]]) # Does this need to be rotated? And turned into Z scores? subtract mean and divide by SD? 

hist(climate_clru[,12])

clru.parameters1 <- formatFunctions(bio1_12 = c(fun = 'dnorm', mean = 81.5, sd = 20),
                                 bio12_12 = c(fun = 'custnorm', mean = 505.9, diff = 70, prob = 0.99),
                                 bio19_12 = c(fun = 'betaFun', p1 = 0, p2 = 198.1, alpha = 0.9, gamma = 0.08), # precip coldest quarter
                                 # bio11_12 = c(fun = 'logisticFun', beta = -1.38, alpha = 2)) # mean temp of coldest quarter, should be how fast the snow melts
                                 bio11_12 = c(fun = 'quadraticFun', a = -1, b = 2, c = -1))

clru.species1 <- generateSpFromFun(raster.stack = 
                                        bioclim.colorado[[c("bio1_12", "bio12_12", "bio19_12", "bio11_12")]],
                                              parameters = clru.parameters1,
                                   # species.type = "additive",
                                   formula = "3 * bio19_12 + sqrt(bio11_12) + bio12_12 * bio1_12",
                                              plot = TRUE)

plot(colocounties);plot(clru.species1, add=TRUE);plot(colocounties, add=TRUE); points(clruspdf, pch=16, cex=0.5, col='blue')

```

Plot response curves
```{r}

plotResponse(clru.species1)


```


```{r}
class(clru.species1)

# suitability map
clru.species1[[3]]

colorado.clru <- crop(clru.species1[[3]], extent(colocounties), snap="out")
plot(colorado.clru); points(clruspdf, pch=16, cex=0.5, col='blue')

# convert to presence absence, use beta to set the inflection and alpha to make stronger switch from suitable to unsuitable
pa1 <- convertToPA(clru.species1, plot = TRUE, beta = 0.65, alpha = -0.001)

# Can set the species prevalance and let it get there with testing levels of beta that get to the desired prevalence, alpha fixed at default -0.05
pa2 <- convertToPA(clru.species1, plot = TRUE, species.prevalence = 0.2)  
# - beta = 0.4677734375
# - alpha = -0.05
# - species prevalence =0.200104841931879
```

#########################################################################################
# attempt to get a more specific distribution  
## add a dummy predictor variable

```{r}

xy <- expand.grid( 1:ncol(rasterstack2),1:nrow(rasterstack2))
names(xy) <-  c('x','y')
# where formula defines the dependent variable (z) as a linear model of independent variables. For ordinary and simple kriging we can use the formula z~1; for simple kriging it is necessary to define a beta parameter too (see below); for universal kriging, if z is linearly dependent on x and y use the formula z~x+y. We are using simple kriging here.
# locations define the data coordinates, e.g. ~x+y in our case here. 
# dummy is a logical value, and it needs to be TRUE for unconditional simulation. 
# beta is used only for simple kriging, and is a vector with the trend coefficients (including an intercept); 
# if no independent variables are defined the model only contains an intercept, i.e. the simple kriging mean. model defines the variogram model, as defined by a call to vgm. vgm allows defining the (partial) sill, range and nugget paramaters, as well as the variogram model type (e.g. exponential, gaussian, spherical, etc). Anisotropy can also be used. 
# nmax defines the number of nearest observations that should be used for a kriging prediction or simulation.

g.dummy <- gstat(formula=z~1, locations=~x+y, dummy=T, beta=1, model=vgm(psill=0.025, range=5, model='Exp'), nmax=20)

yy <- predict(g.dummy, newdata=xy, nsim=1)
gridded(yy) = ~x+y
spplot(obj=yy[1])

sim_layer <- raster(yy) 
extent(sim_layer) <- extent(bioclim.stack)
res(sim_layer) <- res(bioclim.stack)
sim_layer@data <- yy@data

# not working
sim_layer <- coloElev
sim_layer <- setValues(sim_layer, runif(length(coloElev), min = 0, max = 100))
names(sim_layer) <- "dummy"
plot(sim_layer)

rasterstack3 <- stack(coloElev,bioclim.stack, sim_layer)

# scale will center (subtract the layer mean) and scale by dividing the centered layer by SD
rasterstack3_z <- scale(rasterstack3)

```

Define response functions
```{r}
climate_clru2 <- raster::extract(rasterstack2, clru[,c("decimalLongitude","decimalLatitude")])

# add in a dummy variable 
rasterstack3

mu_clru2 <- colMeans(climate_clru2, na.rm = TRUE)
sd_clru2 <- apply(climate_clru2, 2, function(x) sd(x, na.rm = TRUE))
hist(climate_clru2[,1])

# bio19 precip of coldest quarter to represent snow accumulation
# bio11 mean temp of coldest quarter
# BIO12 = Annual Precipitation
# BIO1 = Annual Mean Temperature
clru.para <- formatFunctions(bio1_12 = c(fun = 'dnorm', mean = 66, sd = 19),
                             bio12_12 = c(fun = 'custnorm', mean = 454, diff = 70, prob = 0.99),
                             # bio19_12 = c(fun = 'betaFun', p1 = 0, p2 = 49, alpha = 0.9, gamma = 0.08),
                             bio19_12 = c(fun = 'logisticFun', beta = 60, alpha = 8),
                             bio11_12 = c(fun = 'quadraticFun', a = -1, b = 2, c = -1),
                             ElevationResampled_bioclim = c(fun = 'betaFun', p1 = 1600, p2 = 3000, alpha = 0.9, gamma = 0.08))

 # - The response to each variable was rescaled between 0 and 1. To
 #            disable, set argument rescale.each.response = FALSE
 # 
 # - The final environmental suitability was rescaled between 0 and 1.
 #            To disable, set argument rescale = FALSE
clru1 <- generateSpFromFun(raster.stack = rasterstack2, parameters = clru.para, plot = TRUE) 
                             # species.type = "additive") # this makes it much more squishy

plot(clru1);plot(colocounties, add=TRUE); points(clruspdf, pch=16, cex=0.25,col="blue")
```


Plot response curves
```{r}

plotResponse(clru1)


```

# Need to find and correct errors
######################################################################################
######################################################################################
# again with a dummy variable to check model
Define response functions
```{r}

# add in a dummy variable and scale all variables
rasterstack3_z

climate_clru3 <- raster::extract(rasterstack3_z, clru[,c("decimalLongitude","decimalLatitude")])
mu_clru3 <- colMeans(climate_clru3, na.rm = TRUE)
sd_clru3 <- apply(climate_clru3, 2, function(x) sd(x, na.rm = TRUE))
hist(climate_clru3[,1])

# bio19 precip of coldest quarter to represent snow accumulation
# bio11 mean temp of coldest quarter
# BIO12 = Annual Precipitation
# BIO1 = Annual Mean Temperature
clru.para_z <- formatFunctions(bio1_12 = c(fun = 'dnorm', mean = 0.05302507, sd = 0.47035730),
                             bio12_12 = c(fun = 'custnorm', mean = 0.14942025, diff = 0.10, prob = 0.99),
                             bio19_12 = c(fun = 'logisticFun', beta = -0.45, alpha = 0.8),
                             bio11_12 = c(fun = 'quadraticFun', a = -1, b = 0.48112631, c = -1),
                             ElevationResampled_bioclim = c(fun = 'betaFun', p1 = -6, p2 = 6, alpha = 0.9, gamma = 0.08),
                             dummy = c(fun = 'linearFun', a=0, b=0),
                             rescale = FALSE) # but let the suitability be rescaled to 0 - 1

 # - The response to each variable was rescaled between 0 and 1. To
 #            disable, set argument rescale.each.response = FALSE
 # 
 # - The final environmental suitability was rescaled between 0 and 1.
 #            To disable, set argument rescale = FALSE
clru1_z <- generateSpFromFun(raster.stack = rasterstack3_z, parameters = clru.para_z, plot = TRUE) 
                             # species.type = "additive") # this makes it much more squishy

plot(colocounties);plot(clru1, add=TRUE);plot(colocounties, add=TRUE); points(clruspdf, pch=16, cex=0.25,col="blue")
```


Plot response curves
```{r}

plotResponse(clru1)


```


###############################################################################################
###############################################################################################
###############################################################################################


```{r}
class(clru.species1)

# suitability map
clru.species1[[3]]

colorado.clru <- crop(clru.species1[[3]], extent(colocounties), snap="out")
plot(colorado.clru); points(clruspdf, pch=16, cex=0.5, col='blue')

# convert to presence absence, use beta to set the inflection and alpha to make stronger switch from suitable to unsuitable
pa1 <- convertToPA(clru.species1, plot = TRUE, beta = 0.65, alpha = -0.001)

# Can set the species prevalance and let it get there with testing levels of beta that get to the desired prevalence, alpha fixed at default -0.05
pa2 <- convertToPA(clru.species1, plot = TRUE, species.prevalence = 0.2)  
# - beta = 0.4677734375
# - alpha = -0.05
# - species prevalence =0.200104841931879
```





#################################################################################
Sampler testing  
```{r}

length(colorado.clru) 
nrow(colorado.clru) # 482
ncol(colorado.clru) # 844
# use xyFromCell() to get coordinates from row, column, or cell number
xyFromCell(colorado.clru, ceiling(runif(1, min = 1, max = length(colorado.clru))))

# use prob argument in sample?
# select that cell if a runif(1, min = minValue(colorado.clru), max = maxValue(colorado.clru)) is < the cell value; cell number comes from indexing: colorado.clru[cellnumber]
getValues(colorado.clru)[ceiling(runif(1, min = 1, max = length(colorado.clru)))]

 # the first parameter of pbinom must be the number of "successes,", the second parameter is the number of trials, and the third parameter is the chance of success (not of failure). It looks like pbinom(n,m,p) is returning Pr(X≤n) when X has a Binomial(m,p) distribution. Just as a check that ≤ is meant instead of <, compute some small values

plot(pbinom(1:100,100,0.8))
rbinom(1:100, 1, 0.8)

# > runif(1, min = mean(getValue(suitability.raster), max = maxValue(colorado.clru))


# Maybe this is faster? But need to not get below 0.5
# Which are above threshold of 0.5? Oh, maybe change the values from 0.5 to 0 
colorado.clru.threshold <- colorado.clru
colorado.clru.threshold[colorado.clru.threshold<0.5] <- 0
randfaster <- xyFromCell(colorado.clru.threshold,sample(1:length(colorado.clru.threshold), 100, prob = getValues(colorado.clru.threshold)))
plot(colorado.clru); points(randfaster, pch=16, cex=0.5)
# randfaster <- xyFromCell(colorado.clru,sample(colorado.clru[colorado.clru>0.5], 100, prob = getValues(colorado.clru[colorado.clru[colorado.clru>0.5]])))


samplerand1 <- random_sampling(colorado.clru, 100)
plot(colorado.clru); points(samplerand1, pch=16, cex=0.5)
```


# Sampling functions
Sampling methods
```{r}

### systematic and thinning
systematic_sampling_thinning <- function(suitability.raster, stepsize = 1000, samplesize){
  evenstep <- length(suitability.raster)/stepsize
  i <- evenstep
  
  sampleout <- c()
  while(i < length(suitability.raster)){
    if(getValues(suitability.raster)[i] > 0.5 &
       rbinom(1, 1, getValues(suitability.raster)[i]) == 1){
      sampleout <- rbind(sampleout,xyFromCell(suitability.raster, i))
    }
      i <- i + evenstep
  }

  sampleout <- thin.max(sampleout, c("x","y"), samplesize)
  sampleout
}


samplesys1 <- systematic_sampling_thinning(colorado.clru, 1000, 100)
plot(colorado.clru); points(samplesys1, pch=16, cex=0.5)

# suitability.raster <- clru1[[3]]
# rm(suitability.raster)
### random
random_sampling <- function(suitability.raster, samplesize){
  sampleout <- c()
  i <- 1
  while(i <= samplesize){
    randcell <- ceiling(runif(1, min = 1, max = length(suitability.raster)))
    
    if(getValues(suitability.raster)[randcell] > 0.5 & 
       rbinom(1, 1, getValues(suitability.raster)[randcell]) == 1){
      sampleout <- rbind(sampleout,xyFromCell(suitability.raster, randcell))
      i <- i+1
    } 
  }
  sampleout
}


### adaptive cluster sampling 

### neutral to species, weighted by sampled areas
# 1. sort all weights to start with hightest weighted areas
# 2. have random selection of that point or not
```
Maxent compared to the 'true' distribution


# Maxent function  
  Background points are sampled randomly from the cells that are not NA in the first predictor variable, unless background points are specified with argument a.
```{r}
#test 
# rasterstack <- rasterstack2
pathstart <- "C:/Users/deprengm/OneDrive - Denver Botanic Gardens/P drive/My Documents/UCDenver_phd/Dissertation/Chapter1/maxent_simulations/"
# true.dist <- clru1[[3]]
# sampling_type <- "ra"
rm(rasterstack); rm(true.dist); rm(sampling_type)

maxent_sampling <- function(rasterstack, true.dist, sampling_type = c("random","systematic","neutral","cluster"),
                            reps = 100, samplesize, stepsize, pathstart = pathstart){
  if(grepl(sampling_type, "random")){
    sample_xy <- random_sampling(suitability.raster = true.dist,samplesize = samplesize)
  } 
  if(grepl(sampling_type, "systematic")){
    sample_xy <- systematic_sampling_thinning(true.dist, stepsize = stepsize, samplesize)
  }
  if(grepl(sampling_type, "neutral")){
    sample_xy <- neutral()
  }
  if(grepl(sampling_type, "cluster")){
    sample_xy <- cluster()
  }
  
  for(r in 1:reps){
    fold <- kfold(sample_xy, k=5) # withold 20% of the sample for testing
    occtest <- sample_xy[fold == 1,]
    occtrain <- sample_xy[fold != 1,]
    xm <- maxent(x = rasterstack, p = occtrain)
    write.csv(data.frame(sample_xy, fold), paste(pathstart,"maxentOcc",sampling_type,"rep",r,".csv",sep=""))
    save(xm, file = paste(pathstart, "maxent",sampling_type,"rep",r,".Rda",sep=""))
    
    gc()
    ncores <- detectCores()-1
    cl = parallel::makeCluster(ncores)
    doParallel::registerDoParallel(cl,ncores)
    
    # compute indices for data splitting
    rows <- 1:nrow(rasterstack)
    split <- sort(rows%%ncores)+1
    outname <- paste(pathstart,"Predictmaxent",sampling_type,"rep",r,sep="")
    
    #predict with subsets of predictor dataset
    foreach(i = unique(split), .combine = c) %dopar% {
      rows_sub <- rows[split==i]
      sub <- raster::crop(rasterstack, raster::extent(rasterstack, min(rows_sub), max(rows_sub),
                                                      1, ncol(rasterstack)))
      raster::predict(sub, xm, filename = paste(outname, i, sep="_"), overwrite = TRUE)
    }
    
    # random background data
    bg <- randomPoints(rasterstack, 300)
    e <- evaluate(xm, p=occtest, a=bg, x=rasterstack)
    save(e, file = paste(pathstart, "evaluate", sampling_type,"rep",r,".Rda",sep=""))
    
    rm(xm)
    gc()
    stopCluster(cl)
  }
  
   lapply(1:reps, function(k){
    resultpath <- list.files(path = pathstart, 
                             pattern = paste("Predictmaxent",sampling_type,"rep",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste(pathstart,"ProbTiff",r,sampling_type,"Rep",k,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
  })
}


plot(xm)
```

<https://www.youtube.com/watch?v=42rSg60Rk-k&feature=youtu.be&fbclid=IwAR3AvdVB3U7YVI0aVrfm-KYGQm0Vnfo_W3udZL2YoH0h5vQjxQjp6_Kde7A>
<https://www.youtube.com/watch?v=2vgX7QoyPJo&feature=youtu.be&fbclid=IwAR2mvP8p9LDdz1LefrCwjcMMXi1l_uLI1m-1-sIiydHqHyIpMwcooSoz6lc> 

```{r}
maxent_sampling(rasterstack = rasterstack2, true.dist = clru1[[3]], sampling_type = "random", reps = 20, samplesize = 50, pathstart = pathstart)


maxent_sampling(rasterstack = rasterstack2, true.dist = clru1[[3]], sampling_type = "system", reps = 20, samplesize = 50, pathstart = pathstart, stepsize = 1000)

```

# Nicheoverlap function    
```{r}

```


