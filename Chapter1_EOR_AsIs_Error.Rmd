---
title: "Chapter1_EORtoHerbtoHerbwitherror"
author: "Michelle DePrenger-Levin"
date: "June 4, 2019"
output: html_document
---

```{r}
rm(list=ls())

```

Packages
```{r}
# Plotting
library(gridExtra)
library(grid)
library(lattice)
library(ggplot2)
library(grid) # for rectGrob
library(RCurl)

# Models
require(lme4)
require(AICcmodavg)
library(splancs)
library(Rmisc)
library(rgdal)
library(ENMeval)
# devtools::install_github("ropensci/prism")
library(prism)
options(java.parameters = "Xmx26000m")
# library(rJava)

# Mapping
library(rgeos)
library(raster)
library(maptools)
library(dismo)

# Parallelization
library(foreach)
library(parallel)
library(doParallel)
library(magrittr) # pipe %>%

# Taxonomy
library(Taxonstand)

```

Functions
```{r}

ScaleBar <- function(reference_raster_utm, round_to_nearest_km, width_percent, y_percent_from_bottom, x_percent_from_left, y_text_percent_from_bottom, ...) {
    # Round by max to nearest... e.g. 5 km 
    mround <- function(x,base){ 
        base*round(x/base) 
    }   
    # scale bar size adjustment to avoid decimals
        scale_size <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*width_percent)/1000
        scale_size_adj <- mround(scale_size, round_to_nearest_km)
        scale_size_adj_plot <- (scale_size_adj*1000)/2
    # Horizontal percent position (x) for scale bar
        x_position <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*x_percent_from_left)+xmin(reference_raster_utm)
    # Vertical percent position y for scale bar
        y_position <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_percent_from_bottom)+ymin(reference_raster_utm)
        y_position_text <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_text_percent_from_bottom)+ymin(reference_raster_utm)
    # Draw line on plot
        library(sp)
        x_ends <- c((x_position-scale_size_adj_plot), (x_position+scale_size_adj_plot))
        y_ends <- c((y_position), (y_position))
        scale_bar_line <- SpatialLines(list(Lines(Line(cbind(x_ends, y_ends)), ID="length")))
        projection(scale_bar_line) <- projection(reference_raster_utm)
        plot(scale_bar_line, add=TRUE, ...)
        text(x_position, y_position_text, paste0(scale_size_adj, "km"))
}

thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}
```

Raw data
```{r}

colocounties <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties_wgs84")
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")


load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2namesall68.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/coloradosps.g1g2_168.Rda")
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")
l1G1G2and <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2","G1G2"),])
l1G1G2and$PolyID <- do.call(rbind, lapply(split(l1G1G2and,l1G1G2and$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))

# Predictor layers (DEM layers resampled to match at Bioclim 30 arc second scale)
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")
bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif")
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)
rm(bio1_res,bio12_res,coAspect_res,coElev_res,coRugged_res)
gc()
```

Grid cells are around 1km anyway so round to about 1.1 km
```{r}
coloradosps.g1g2_168$decimalLatitude <- as.numeric(as.character(coloradosps.g1g2_168$decimalLatitude))
coloradosps.g1g2_168$decimalLongitude <- as.numeric(as.character(coloradosps.g1g2_168$decimalLongitude))
coloradosps.g1g2_168$year <- as.numeric(as.character(coloradosps.g1g2_168$year))

coloradosps.g1g2_168$lon2 <- round(coloradosps.g1g2_168$decimalLongitude, 2)
coloradosps.g1g2_168$lat2 <- round(coloradosps.g1g2_168$decimalLatitude, 2)

length(table(coloradosps.g1g2_168$lon2)) # 325 
length(table(coloradosps.g1g2_168$decimalLongitude)) # 870
```



Points for SDMs    
       1. EOs sample size matching Herbarium specimens sample size, use thin.max
       2. Herbarium specimens as-is
       3. Herbarium specimens with additional error (to be created from distance distribution)
```{r}
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_EOR.Rda")
```
or make new: 
```{r}
distXsp_EOR <- lapply(1:nrow(g1g2namesall68), function(i){
  gc()
  g1g2now <- coloradosps.g1g2_168[coloradosps.g1g2_168$scientificName %in%
                                c(g1g2namesall68$Taxon[i],g1g2namesall68$AcceptedName[i])&
                                !is.na(coloradosps.g1g2_168$decimalLatitude),]
  g1g2now$year <- as.numeric(as.character(substring(g1g2now$year,1,4)))
   # remove points with errors in the year field
  g1g2now <- g1g2now[g1g2now$year>1800,]
  
  g1g2now$decimalLatitude <- as.numeric(as.character(g1g2now$decimalLatitude))
  g1g2now$decimalLongitude <- as.numeric(as.character(g1g2now$decimalLongitude))
  # remove points not in Colorado
  g1g2now <- g1g2now[g1g2now$decimalLatitude>35,]
  g1g2now <- g1g2now[g1g2now$decimalLongitude>(-113),]
  # discard observations that lack specimens
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c("scientificName","scientificNameAuthorship","institutionCode", 
                        "recordedBy","year","decimalLatitude","decimalLongitude")] # ,"lat2","lon2"
  gc()
  
  
  if(nrow(g1g2now)>0){
  # put grid points across colorado, sample from it for each polygons
    polys <- l1G1G2and[l1G1G2and$GNAME %in% c(g1g2namesall68$AcceptedName[i],
                                        g1g2namesall68$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
    totalarea <- sum(area(disaggregate(polys)))
  # area of each polygon
    # areanow <- sapply(slot(polys,"polygons"), slot, "area")
  

  # Convert polys to match rasterstack; only those mapped after 1980
    polys@data$LASTOBS <- as.numeric(substring(polys@data$LASTOBS,1,4))
    polys <- polys[polys@data$LASTOBS < 2020,] # when keeping all polys, need to remove unknown year
    polys_after1980 <- polys[polys$LASTOBS > 1980 & polys$LASTOBS < 2020,] # and not unknown 9999
    polys_latlon <- spTransform(polys, CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))

    # Get cell number of where the herbarium specimens fall; for records after 1980
      Herbcell <- cellFromXY(rasterstack, g1g2now[g1g2now$year>1980
                                                  ,c("decimalLongitude","decimalLatitude")])

    # Get cell number
      cell <- cellFromPolygon(rasterstack, polys_latlon, weights =TRUE)
      EORpnts <- rasterToPoints(rasterstack[[1]])[unique(as.vector(do.call(rbind,cell)[,1])),c(1:2)]
    # Thin to same number of points available in Herbarium specimens
      EORpnts <- thin.max(EORpnts,c("x","y"),length(unique(Herbcell)))
        
    gc()
    
  #turn into spatialpointsdataframe for individual species
    coordinates(g1g2now) <- ~decimalLongitude+decimalLatitude
    proj4string(g1g2now) <- CRS("+init=epsg:4326")  # CRS("+proj=longlat +datum=WGS84")
    g1g2now <- spTransform(g1g2now, CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
  # The minimum distance from each point to the nearest polygon
    distnow <- apply(gDistance(g1g2now,polys, byid=TRUE),2,min)
    gc()
    
    g1g2distarea <- data.frame(Species = g1g2namesall68$AcceptedName[i], 
                               g1g2now,Dist = distnow, Area = totalarea,
                               EORdate = polys$LASTOBS[apply(gDistance(g1g2now,polys,
                                                                       byid=TRUE),2,which.min)],
                               Yeardiff = g1g2now$year- as.numeric(substring(as.character(polys$LASTOBS[apply(gDistance(g1g2now,polys, byid=TRUE),2,which.min)]),1,4)))
    gc()
    
    out <- list(g1g2distarea, EORpnts)
    gc()
    out
    }
  })
save(distXsp_EOR, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_EOR.Rda") 

```

#Distribution of error in herbarium specimens 
    
    1) Habitat Specificity
        i.  Table 1 of distance, area, year, year differences
        ii. AIC to compare habitt specificity, range, year, difference in years EOR to herbarium on distance from nearest EOR     
        
```{r}
df_dist <- do.call(rbind,Map(cbind, mapply('[[', distXsp_EOR, 1)[notnull], SpNum = notnull))
df_dist$EORYear <- as.numeric(substring(df_dist$EORdate,1,4))

out <- Rmisc::summarySE(df_dist, "Dist", "SpNum", na.rm=TRUE)
tab1 <- do.call(rbind, lapply(split(df_dist, df_dist$SpNum), function(x){
  data.frame(SpNum1 = unique(x$SpNum), Species = x$Species[1], DistAvg = summarySE(x, "Dist"), 
             Area = unique(x$Area), minYearDiff = min(x$Yeardiff), maxYearDiff = max(x$Yeardiff),
             SpNum= unique(x$SpNum), YearDiffAvg = summarySE(x, "Yeardiff"),
             MinEORyear = min(x$EORYear), MaxEORyear = max(x$EORYear), 
             MinYear = min(x$year), MaxYear = max(x$year), AvgLat = summarySE(x, "decimalLatitude"))
})) 
tab1$SDM[tab1$SpNum %in% atleast12] <- "x"

write.csv(tab1, "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/table1_20190804.csv")


```

Habitat Specificity   
```{r}


```



AIC
```{r}


```


#Maxent function
```{r}
maxentrun <- function(whichones, spatialpointsdataframe_herb, 
                      Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
                      numberofReps = 10, 
                      maxentarguments = FALSE, predictorvariables = rasterstack, 
                      pathstart, filenames, kfoldnum = 4, 
                      error = FALSE, distdistribution = NULL, backgroundscale = 5000){
        for(x in whichones){
            pointsspdf <- SpatialPointsDataFrame(coords = spatialpointsdataframe_herb[[x]][,c("decimalLongitude","decimalLatitude")],
                                                 data = spatialpointsdataframe_herb[[x]],
                                                 proj4string = Whichproj4string)
          if(error == TRUE){
               # for each point I will draw a circle of size (drawn from the distribution of error seen distXspall$Dist) and then pick a random point along the circle.
              errorpointsout <- do.call(rbind,lapply(1:nrow(pointsspdf), function(r){
                errordist <- sample(distdistribution, 1)
                if(errordist>0){
                  erroraround <- gBuffer(pointsspdf[r,], width=errordist)
                  newpoint <- erroraround@polygons[[1]]@Polygons[[1]]@coords
                  out <- newpoint[sample(1:nrow(newpoint),1),]
                } else {
                  out <- pointsspdf@coords[r,]
                  }
                out
                }))
                
                df <- SpatialPointsDataFrame(coords = errorpointsout,
                                             data = pointsspdf@data,
                                             proj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
                circlesout <- circles(df, d = backgroundscale) #Should be 5km around
                polygns <- polygons(circlesout)
                bgpnts <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
                
                convertxy <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
                proj4string(bgpnts) <- Whichproj4string
                bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
          } else {
                convertxy <- spTransform(pointsspdf, CRS("+proj=longlat +datum=WGS84"))
                circlesout <- circles(pointsspdf, d = backgroundscale)
                polygns <- polygons(circlesout)
                bgpnts <- spsample(polygns, 300, "stratified")
                proj4string(bgpnts) <- Whichproj4string
                bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
            
          }
            
             for(rep in 1:numberofReps){
                convertxy$kfold <- kfold(convertxy, k=kfoldnum) # to have 75:25%
                if(maxentarguments == TRUE){
                  xm <- maxent(x = predictorvariables,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords,
                           args=c("noautofeature","noproduct","nothreshold"))
                } else {
                  xm <- maxent(x = predictorvariables,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords)
                }
                
                write.csv(data.frame(convertxy@coords,convertxy@data),
                          paste(pathstart,"presenceHerb",filenames,"Sp",x,"kfold",rep,".csv", sep=""))
                # write.csv(data.frame(bgpnts@coords, convertxy@data[1,c("Species","Area")]),
                #           paste(pathstart,"presenceHerb",filenames,"Sp",x,"kfold",rep,".csv", sep=""))
                save(xm, file= paste(pathstart,"maxentHerb",filenames,"Sp",x,"kfold",rep,".Rda", sep=""))        
        
                gc()
                #register parallel computing backend
                ncores <- detectCores()-1
                cl = parallel::makeCluster(ncores)
                doParallel::registerDoParallel(cl,ncores)
                #compute indices for data splitting
                rows = 1:nrow(predictorvariables)
                split = sort(rows%%ncores)+1
                outname = paste(pathstart,"PredictHerb",filenames,"Sp", x,"kfold",rep, sep="")
                #perform the prediction on subsets of the predictor dataset
                foreach(i=unique(split), .combine=c)%dopar%{
                  rows_sub = rows[split==i]
                  sub = raster::crop(predictorvariables,raster::extent(predictorvariables, min(rows_sub), max(rows_sub), 
                                                                1, ncol(predictorvariables)))
                  raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
                }
        
                e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, predictorvariables)
                save(e, file= paste(pathstart,"evaluateHerb",filenames,"Sp",x,"kfold",rep,".Rda", sep=""))
        
                rm(xm)
                gc()
                stopCluster(cl)
             }
                e
        }
}



```

More functions
```{r}
stitchtogether <- function(whichones, pathstart, patternmatch, rasternames){
  lapply(whichones, function(i){
  gc()
  lapply(1:10, function(k){
    resultpath <- list.files(path = pathstart, 
                             pattern = paste(patternmatch,i,"kfold",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste(pathstart,"ProbTiffSp",i,rasternames,k,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
  })
})
}

forhistofaverage <- function(whichones = atleast12, pathstart, patternmatch){
  stacktoaverage <- lapply(whichones, function(i){
    rasterstoavg <- list.files(path = pathstart, 
                               pattern = paste("ProbTiffSp",
                                               i,
                                               patternmatch,sep=""), 
                               full.names=TRUE)
    ras <- stack(lapply(rasterstoavg, function(y){
      raster(y)
    }))
    beginCluster(10)
    ras.mean <- clusterR(ras, calc, args=list(mean, na.rm=T))
    writeRaster(ras.mean, paste(pathstart,
                                "AvgTiffSp",i,patternmatch,g1g2namesall68$AcceptedName[i],
                                ".tif", sep=""),overwrite=TRUE)
    gc()
    endCluster()
    ras.mean
  })
  stacktoaverage
}

forhistofsd <- function(whichones = atleast12, pathstart, patternmatch){
  stacktoaverage <- lapply(whichones, function(i){
    rasterstoavg <- list.files(path = pathstart, 
                               pattern = paste("ProbTiffSp",
                                               i,
                                               patternmatch,sep=""), 
                               full.names=TRUE)
    ras <- stack(lapply(rasterstoavg, function(y){
      raster(y)
    }))
    beginCluster(10)
    ras.mean <- clusterR(ras, calc, args=list(sd, na.rm=T))
    writeRaster(ras.mean, paste(pathstart, "SDTiffSp",i,patternmatch,
                              g1g2namesall68$AcceptedName[i],
                              ".tif", sep=""),overwrite=TRUE)
    gc()
    endCluster()
    ras.mean
  })
  stacktoaverage
}

habitatSpecificity <- function(whichones, pathstart, replicates = 10, filenames, rasterstack){
  
  # collect all the presence points used in the SDM
  habsp <- do.call(rbind,lapply(whichones, function(x){
    out <- do.call(rbind,lapply(filenames, function(nams){
      outno <- do.call(rbind,lapply(1:replicates, function(rep){
        load(paste(pathstart,"maxentHerb", nams, "Sp", x,"kfold",rep, ".Rda",sep=""))
        outinner <- data.frame(SpeciesNum = x, kfold = rep, HerbType = nams, xm@presence)
        outinner
        }))
      outno      
    }))
    out
  }))

  prPCA <- princomp(habsp[,-c(1:3)])
  allsphabsp <- data.frame(habsp[,1:3],prPCA$scores)
  allsphabsp$HerbType <- as.character(allsphabsp$HerbType)
  
  # for all species and both error and no and EOR, dropping parameters (kfolds in EOR; only 1)
  habspecificity <- do.call(rbind,
                            lapply(split(allsphabsp, 
                                         list(allsphabsp$SpeciesNum,
                                              allsphabsp$kfold,
                                              allsphabsp$HerbType), drop=TRUE), function(x){
      p <- ggplot(x, aes(Comp.1,Comp.2))+
      geom_point()+
      stat_ellipse(segments=201) #default is to draw 51 line segments to make the ellipse
    # get ellipse coordinates
    pb <- ggplot_build(p)
    table(pb$data[[2]]$group)
    el <- pb$data[[2]][c("x","y")]
    
    # Center of ellipse
    ctr <- MASS::cov.trob(el)$center
    
    # Distance to center from each point on ellipse
    dist2center <- sqrt(rowSums((t(t(el)-ctr))^2))
    
    # Area of ellipse from semi-major and semi-minor axes which are largest and smallest of dist to center
    habitatspecificity <- pi*min(dist2center)*max(dist2center)
    ellipseoutfold <- data.frame(SpeciesNum = unique(x$SpeciesNum), 
                                 kfold = unique(x$kfold), 
                                 HerbType = unique(x$HerbType), habspec = habitatspecificity)
    ellipseoutfold
        }))
  habspecificity
}

accuracyhists <- function(pathstart, probmapnames, whichones, reps = 1:10){
  lapply(whichones, function(i){
  lrhist <- lapply(reps, function(k){
    r <- raster(paste(pathstart,"ProbTiffSp",i,probmapnames,k,".tif", sep=""))
    
    polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                    g1g2names$Taxon[i]),] 
    # Only want ones after 1980
    years <- as.numeric(substring(polys$LASTOBS,1,4))
    yearlater1980 <- c()
    for(l in 1:length(years)){
      yearlater1980[l] <- if(years[l]>1980){
                                      l } else {
                                        NA
                                      }
    }
    yearlater1980 <- yearlater1980[!is.na(yearlater1980)]
    polys <- polys[yearlater1980,]
    
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
    f <- spTransform(polys, CRS("+proj=longlat +datum=WGS84"))   
    fr <- extract(r, f, small = TRUE, weights = TRUE)
    # Want the value [,1] for each polygon but use the weight [,2] to get the pro-rated cells 
    out <- do.call(rbind,fr)
    out
    })
  lrhist
  })
}
```

1. Select background points trying to account for biased sampling (would have sampled within area where presence points were)  
2. Select background points from larger area   
3. Select background points ramdomly from entire possible area    
```{r}
notnull <- which(!unlist(lapply(distXsp_EOR, is.null)))
length(notnull)
match(1:68,notnull)
atleast12 <- unlist(lapply(notnull, function(l){
  if(nrow(distXsp_EOR[[l]][[2]])>11) l
  }))

# Selected polygons mapped after 1980, found overlapping raster cells for points; thinned to matching number of points from herbarium specimens (the number of raster cells covered by herbarium specimens collected after 1980). May lead to repeated points from EOR records. 
distXsp_justEOR_forspdf <- mapply('[[', distXsp_EOR, 2)
distXsp_justEOR_spdf <- lapply(1:68, function(x) NA)
for(i in atleast12){
  out <- data.frame(distXsp_justEOR_forspdf[[i]])
  colnames(out) <- c("decimalLongitude","decimalLatitude")
  distXsp_justEOR_spdf[[i]] <- out
}

distdistribution <- do.call(rbind, mapply('[[', distXsp_EOR, 1))
hist(distdistribution$Dist/1000, breaks=50,main="Error distribution (km)") 


# Herbarium specimens after 1980
distXsp_justHerb <- mapply('[[', distXsp_EOR, 1)
distXsp_justHerb <- lapply(distXsp_justHerb, function(x){
  out <- x[x$year > 1980,]
  out
})

```

Run maxent for the three datasets - EOR, As-IS, and Error; all with background of 5000 meters
```{r}
filenames <-  c("EOR_bg5000","As-Is_bg5000","Error_bg5000")
pathstart <- ("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_EOR_asis_error/")

# Sample size will be at least 12 except for some where there were not enough mapped polygons to cover 12 different raster cells, in this case there are repeated points. 
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"),
          spatialpointsdataframe_herb = distXsp_justEOR_spdf,
          maxentarguments = FALSE, filenames = filenames[1], 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 5000)

# Herbarium as-is
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
          spatialpointsdataframe_herb = distXsp_justHerb,
          maxentarguments = FALSE, filenames = filenames[2], 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 5000)


# Herbarium Error
maxentrun(whichones = atleast12, numberofReps = 10, error = TRUE,
          Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
          distdistribution = distdistribution$Dist,
          spatialpointsdataframe_herb = distXsp_justHerb,
          maxentarguments = FALSE, filenames = filenames[3], 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 5000)
```

The patternmatch needs to be "PredictHerb" filename from maxentrun() and "Sp" 
The rasternames are "Herb" and filenames
```{r}
patternmatch <- paste("PredictHerb", filenames, "Sp", sep="")
rasternames <- paste("Herb", filenames, "kfold", sep="")

lapply(1:3, function(x) stitchtogether(atleast12, pathstart=pathstart, patternmatch = patternmatch[x], rasternames = rasternames[x]))

# habitat specificity

habsp_smallbg <- habitatSpecificity(atleast12, pathstart, replicates = 10, filenames = filenames)
save(habsp_smallbg, file= paste(pathstart,"habsp_smallbg.Rda", sep=""))


```

Run maxent for the three datasets - EOR, As-IS, and Error; all with background of 500000 meters
```{r}
filenamesbig <-  c("EOR_bg500000","As-Is_bg500000","Error_bg500000")
pathstart <- ("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_EOR_asis_error/")

# Sample size will be at least 12 except for some where there were not enough mapped polygons to cover 12 different raster cells, in this case there are repeated points. 
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"),
          spatialpointsdataframe_herb = distXsp_justEOR_spdf,
          maxentarguments = FALSE, filenames = filenamesbig[1], 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 500000)

# Herbarium as-is
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
          spatialpointsdataframe_herb = distXsp_justHerb,
          maxentarguments = FALSE, filenames = filenamesbig[2], 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 500000)


# Herbarium Error
maxentrun(whichones = atleast12, numberofReps = 10, error = TRUE,
          Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
          distdistribution = distdistribution$Dist,
          spatialpointsdataframe_herb = distXsp_justHerb,
          maxentarguments = FALSE, filenames = filenamesbig[3], 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 500000)
```

The patternmatch needs to be "PredictHerb" filename from maxentrun() and "Sp" 
The rasternames are "Herb" and filenames
```{r}
patternmatchbig <- paste("PredictHerb", filenamesbig, "Sp", sep="")
rasternames <- paste("Herb", filenamesbig, "kfold", sep="")

lapply(1:3, function(x) stitchtogether(atleast12, pathstart=pathstart, patternmatch = patternmatchbig[x], rasternames = rasternames[x]))

# habitat specificity

habsp_bigbg <- habitatSpecificity(atleast12, pathstart, replicates = 10, filenames = filenamesbig)
save(habsp_bigbg, file= paste(pathstart,"habsp_bigbg.Rda", sep=""))


```




```{r}
lapply(filenames, function(x){
  forhistofaverage(whichones = atleast12, pathstart = pathstart, patternmatch = paste("Herb", x, sep=""))
  })

lapply(filenames, function(x){
  forhistofsd(whichones = atleast12, pathstart = pathstart, patternmatch = paste("Herb", x, sep=""))
  })
```

Also average and SD for the larger background area ones
```{r}
lapply(filenamesbig, function(x){
  forhistofaverage(whichones = atleast12, pathstart = pathstart, patternmatch = paste("Herb", x, sep=""))
  })

lapply(filenamesbig, function(x){
  forhistofsd(whichones = atleast12, pathstart = pathstart, patternmatch = paste("Herb", x, sep=""))
  })
```

How correlated within EOR and how correlated across entire range  
Or really how similar are the niches derived from the different data?
```{r}

# dismo::nicheEquivalency
# dismo::nicheOverlap

correlations <- function(pathstart, filenames, rasterstack, whichones){
  lrhist <- lapply(whichones, function(i){
    
      # How correlated are the averages? 
      r1 <- raster(paste(pathstart,"AvgTiffSp",i,"Herb",filenames[1],
                         g1g2namesall68$AcceptedName[i],".tif", sep=""))
      r2 <- raster(paste(pathstart,"AvgTiffSp",i,"Herb",filenames[2],
                         g1g2namesall68$AcceptedName[i],".tif", sep=""))
      r3 <- raster(paste(pathstart,"AvgTiffSp",i,"Herb",filenames[3],
                         g1g2namesall68$AcceptedName[i],".tif", sep=""))
      
      # Pearson correlation measures the strength of the linear relationship between normally distriubted variables
      # Spearman rank correlation for variables not normally distributed or when the relationship is not linear. 
      # cor_1$mean should just be the average of all pixels in each layer
      cor_1 <- layerStats(stack(r1,r2,r3), 'pearson', na.rm=TRUE)
      out_cor <- cor_1$`pearson correlation coefficient`
      
      overlaps1_2 <- nicheOverlap(r1,r2,mask=FALSE, checkNegatives = FALSE)
      overlaps1_3 <- nicheOverlap(r1,r3, mask=FALSE, checkNegatives=FALSE)
      overlaps2_3 <- nicheOverlap(r2,r3, mask=FALSE, checkNegatives=FALSE)
      
      list(cor_1, out_cor, data.frame(OverlapEOR_AsIs = overlaps1_2, 
                                      OverlapEOR_Error = overlaps1_3, 
                                      OverlapAsIs_Error = overlaps2_3))
  })
  lrhist
}

    # # Sample from the kfolds and repeat a few times        
      # sp1 <- read.csv(paste(pathstart, "presenceHerb",filenames[1],"Sp", i, "kfold", 
      #                       sample(1:10, 1),".csv", sep=""))
      # sp2 <- read.csv(paste(pathstart, "presenceHerb",filenames[2],"Sp", i, "kfold", 
      #                       sample(1:10, 1), ".csv",sep=""))
      # sp3 <- read.csv(paste(pathstart, "presenceHerb",filenames[3],"Sp", i, "kfold", 
      #                       sample(1:10, 1),".csv", sep=""))
      # Sp1 <- SpatialPoints(sp1[,c("decimalLongitude","decimalLatitude")],
      #                      proj4string = 
      #                        CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
      # Sp2 <- SpatialPoints(sp2[,c("decimalLongitude","decimalLatitude")],
      #                      proj4string = 
      #                        CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
      # Sp3 <- SpatialPoints(sp3[,c("decimalLongitude","decimalLatitude")],
      #                      proj4string = 
      #                        CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
      
      # equivalency_overlap <- replicate(100, function(x){
      #   equiv1_2 <- nicheEquivalency(Sp1, Sp2, rasterstack, n=10)
      #   equiv1_3 <- nicheEquivalency(Sp1, Sp3, rasterstack, n=10)
      #   equiv2_3 <- nicheEquivalency(Sp2, Sp3, rasterstack, n=10)
      #   })
  
      # overlap <- nicheOverlap(r1,r2)
      
```


# to test 
whichones <- atleast12[1]
filenames # small
pathstart # "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_EOR_asis_error/"

```{r}
smallbackgroundcor <- correlations(pathstart = pathstart, filenames = filenames,
                                  whichones = atleast12)
smallbackgroundcor[[1]]

bigbackgroundcor <- correlations(pathstart = pathstart, filenames = filenamesbig, 
                                 whichones = atleast12)

OverlapSmall <- mapply('[[', smallbackgroundcor, 3)
dimnames(OverlapSmall)
OverlapSmall.df <- data.frame(t(matrix(unlist(OverlapSmall),3,22)))
colnames(OverlapSmall.df) <- dimnames(OverlapSmall)[[1]]

ggplot()
```

```{r}
cl <- makeCluster(10)

#bootstrapping by taking 100 samples, so slow, maybe better to just go through each? The presence point are the same for all the As-Is/uncleaned but should be different for some EOR and all error

All_nicheEquivalency <- lapply(atleast12, function(i) {
      # Sample from the kfolds and repeat a few times
      sp1 <- read.csv(paste(pathstart, "presenceHerb",filenames[1],"Sp", i, "kfold",
                            sample(1:10, 1),".csv", sep=""))
      sp2 <- read.csv(paste(pathstart, "presenceHerb",filenames[2],"Sp", i, "kfold1",
                            ".csv",sep="")) # As-Is or uncleaned all the same
      sp3 <- read.csv(paste(pathstart, "presenceHerb",filenames[3],"Sp", i, "kfold",
                            sample(1:10, 1),".csv", sep=""))
      Sp1 <- SpatialPoints(sp1[,c("decimalLongitude","decimalLatitude")],
                           proj4string =
                             CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
      Sp2 <- SpatialPoints(sp2[,c("decimalLongitude","decimalLatitude")],
                           proj4string =
                             CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
      Sp3 <- SpatialPoints(sp3[,c("decimalLongitude","decimalLatitude")],
                           proj4string =
                             CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))

      registerDoParallel(cl)
      trials <- 100
      foreach(icount(trials),  
              .combine='c', 
              .packages = c("dismo")) %dopar% {
                
                equiv1_2 <- nicheEquivalency(Sp1, Sp2, rasterstack, n=100)
                equiv1_3 <- nicheEquivalency(Sp1, Sp3, rasterstack, n=100)
                equiv2_3 <- nicheEquivalency(Sp2, Sp3, rasterstack, n=100)
                list(equiv1_2,equiv1_3,equiv2_3)
              }
      
      stopCluster(cl)
      })

save(equiv1_2, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/equiv1_2_Sp1.Rda") 
```

## Errors, need more paralelling or more power to do the 30 meter resolution one
Use smaller predictor variables
Run maxent for the three datasets - EOR, As-IS, and Error; all with background of 5000 meters
```{r}
coElev <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Elevation_VT/CO_Mosaic_Elevation_VT/co_elev_VT_WGS84.tif")
coAspect <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Aspect_VT/co_aspect_VT_WGS84.tif")
coSlope <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Slope_VT/co_slope_VT_WGS84.tif")
rasterstack_2 <- stack(list(coElev, coAspect, coSlope))
rscrs_2 <- rasterstack_2@crs@projargs # "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
```
Maybe need more slices? so each is smaller?
```{r}
filenames30mrasters <-  c("EOR_bg5000","As-Is_bg5000","Error_bg5000")
pathstart30m <- ("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_EOR_asis_error_30mrasters/")

# Sample size will be at least 12 except for some where there were not enough mapped polygons to cover 12 different raster cells, in this case there are repeated points. 
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"),
          spatialpointsdataframe_herb = distXsp_justEOR_spdf,
          maxentarguments = FALSE, filenames = filenames30mrasters[1], 
          predictorvariables = rasterstack_2, pathstart = pathstart30m, backgroundscale = 5000)
  

# Herbarium as-is
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
          spatialpointsdataframe_herb = distXsp_justHerb,
          maxentarguments = FALSE, filenames = filenames30mrasters[2], 
          predictorvariables = rasterstack_2, pathstart = pathstart30m, backgroundscale = 5000)


# Herbarium Error
maxentrun(whichones = atleast12, numberofReps = 10, error = TRUE,
          Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
          distdistribution = distdistribution$Dist,
          spatialpointsdataframe_herb = distXsp_justHerb,
          maxentarguments = FALSE, filenames = filenames30mrasters[3], 
          predictorvariables = rasterstack_2, pathstart = pathstart30m, backgroundscale = 5000)
```

The patternmatch needs to be "PredictHerb" filename from maxentrun() and "Sp" 
The rasternames are "Herb" and filenames
```{r}
patternmatch <- paste("PredictHerb", filenames30mrasters, "Sp", sep="")
rasternames <- paste("Herb", filenames30mrasters, "kfold", sep="")

lapply(1:3, function(x) stitchtogether(atleast12, pathstart=pathstart30m, patternmatch = patternmatch[x], rasternames = rasternames[x]))

# habitat specificity

habsp_smallbg <- habitatSpecificity(atleast12, pathstart, replicates = 10, filenames = filenames)
save(habsp_smallbg, file= paste(pathstart,"habsp_smallbg.Rda", sep=""))


```

```{r}

```