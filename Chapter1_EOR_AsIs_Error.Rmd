---
title: "Chapter1_EORtoHerbtoHerbwitherror"
author: "Michelle DePrenger-Levin"
date: "June 4, 2019"
output: html_document
---

```{r}
rm(list=ls())

```

Packages
```{r}
# Plotting
library(gridExtra)
library(grid)
library(lattice)
library(ggplot2)
library(grid) # for rectGrob
library(RCurl)

# Models
require(lme4)
require(AICcmodavg)
library(splancs)
library(Rmisc)
library(rgdal)
library(ENMeval)
# devtools::install_github("ropensci/prism")
library(prism)

# Mapping
library(rgeos)
library(raster)
library(maptools)
library(dismo)

# Parallelization
library(foreach)
library(parallel)
library(doParallel)
library(magrittr) # pipe %>%

# Taxonomy
library(Taxonstand)

```

Functions
```{r}

ScaleBar <- function(reference_raster_utm, round_to_nearest_km, width_percent, y_percent_from_bottom, x_percent_from_left, y_text_percent_from_bottom, ...) {
    # Round by max to nearest... e.g. 5 km 
    mround <- function(x,base){ 
        base*round(x/base) 
    }   
    # scale bar size adjustment to avoid decimals
        scale_size <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*width_percent)/1000
        scale_size_adj <- mround(scale_size, round_to_nearest_km)
        scale_size_adj_plot <- (scale_size_adj*1000)/2
    # Horizontal percent position (x) for scale bar
        x_position <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*x_percent_from_left)+xmin(reference_raster_utm)
    # Vertical percent position y for scale bar
        y_position <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_percent_from_bottom)+ymin(reference_raster_utm)
        y_position_text <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_text_percent_from_bottom)+ymin(reference_raster_utm)
    # Draw line on plot
        library(sp)
        x_ends <- c((x_position-scale_size_adj_plot), (x_position+scale_size_adj_plot))
        y_ends <- c((y_position), (y_position))
        scale_bar_line <- SpatialLines(list(Lines(Line(cbind(x_ends, y_ends)), ID="length")))
        projection(scale_bar_line) <- projection(reference_raster_utm)
        plot(scale_bar_line, add=TRUE, ...)
        text(x_position, y_position_text, paste0(scale_size_adj, "km"))
}

thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}
```

Raw data
```{r}

colocounties <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties_wgs84")
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")


load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2namesall68.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/coloradosps.g1g2_168.Rda")
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")
l1G1G2and <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2","G1G2"),])
l1G1G2and$PolyID <- do.call(rbind, lapply(split(l1G1G2and,l1G1G2and$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))

# Predictor layers (DEM layers resampled to match at Bioclim 30 arc second scale)
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")
bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif")
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)
rm(bio1_res,bio12_res,coAspect_res,coElev_res,coRugged_res)
gc()
```

Grid cells are around 1km anyway so round to about 1.1 km
```{r}
coloradosps.g1g2_168$decimalLatitude <- as.numeric(as.character(coloradosps.g1g2_168$decimalLatitude))
coloradosps.g1g2_168$decimalLongitude <- as.numeric(as.character(coloradosps.g1g2_168$decimalLongitude))
coloradosps.g1g2_168$year <- as.numeric(as.character(coloradosps.g1g2_168$year))

coloradosps.g1g2_168$lon2 <- round(coloradosps.g1g2_168$decimalLongitude, 2)
coloradosps.g1g2_168$lat2 <- round(coloradosps.g1g2_168$decimalLatitude, 2)

length(table(coloradosps.g1g2_168$lon2)) # 325 
length(table(coloradosps.g1g2_168$decimalLongitude)) # 870
```



Points for SDMs    
       1. EOs sample size matching Herbarium specimens sample size, use thin.max
       2. Herbarium specimens as-is
       3. Herbarium specimens with additional error (to be created from distance distribution)
```{r}
distXsp_EOR <- lapply(1:nrow(g1g2namesall68), function(i){
  gc()
  g1g2now <- coloradosps.g1g2_168[coloradosps.g1g2_168$scientificName %in%
                                c(g1g2namesall68$Taxon[i],g1g2namesall68$AcceptedName[i])&
                                !is.na(coloradosps.g1g2_168$decimalLatitude),]
  g1g2now$year <- as.numeric(as.character(substring(g1g2now$year,1,4)))
   # remove points with errors in the year field
  g1g2now <- g1g2now[g1g2now$year>1800,]
  
  g1g2now$decimalLatitude <- as.numeric(as.character(g1g2now$decimalLatitude))
  g1g2now$decimalLongitude <- as.numeric(as.character(g1g2now$decimalLongitude))
  # remove points not in Colorado
  g1g2now <- g1g2now[g1g2now$decimalLatitude>35,]
  g1g2now <- g1g2now[g1g2now$decimalLongitude>(-113),]
  # discard observations that lack specimens
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c("scientificName","scientificNameAuthorship","institutionCode", 
                        "recordedBy","year","decimalLatitude","decimalLongitude")] # ,"lat2","lon2"
  gc()
  
  
  if(nrow(g1g2now)>0){
  # put grid points across colorado, sample from it for each polygons
    polys <- l1G1G2and[l1G1G2and$GNAME %in% c(g1g2namesall68$AcceptedName[i],
                                        g1g2namesall68$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
    totalarea <- sum(area(disaggregate(polys)))
  # area of each polygon
    # areanow <- sapply(slot(polys,"polygons"), slot, "area")
  

  # Convert polys to match rasterstack; only those mapped after 1980
    polys@data$LASTOBS <- as.numeric(substring(polys@data$LASTOBS,1,4))
    polys_after1980 <- polys[polys$LASTOBS > 1980,]
    polys_latlon <- spTransform(polys, CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))

    # Get cell number of where the herbarium specimens fall; for records after 1980
      Herbcell <- cellFromXY(rasterstack, g1g2now[g1g2now$year>1980
                                                  ,c("decimalLongitude","decimalLatitude")])

    # Get cell number
      cell <- cellFromPolygon(rasterstack, polys_latlon, weights =TRUE)
      EORpnts <- rasterToPoints(rasterstack[[1]])[unique(as.vector(do.call(rbind,cell)[,1])),c(1:2)]
    # Thin to same number of points available in Herbarium specimens
      EORpnts <- thin.max(EORpnts,c("x","y"),length(unique(Herbcell)))
        
    gc()
    
  #turn into spatialpointsdataframe for individual species
    coordinates(g1g2now) <- ~decimalLongitude+decimalLatitude
    proj4string(g1g2now) <- CRS("+init=epsg:4326")  # CRS("+proj=longlat +datum=WGS84")
    g1g2now <- spTransform(g1g2now, CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
  # The minimum distance from each point to the nearest polygon
    distnow <- apply(gDistance(g1g2now,polys, byid=TRUE),2,min)
    gc()
    
    g1g2distarea <- data.frame(Species = g1g2namesall68$AcceptedName[i], 
                               g1g2now,Dist = distnow, Area = totalarea,
                               EORdate = polys$LASTOBS[apply(gDistance(g1g2now,polys,
                                                                       byid=TRUE),2,which.min)],
                               Yeardiff = g1g2now$year- as.numeric(substring(as.character(polys$LASTOBS[apply(gDistance(g1g2now,polys, byid=TRUE),2,which.min)]),1,4)))
    gc()
    
    out <- list(g1g2distarea, EORpnts)
    gc()
    out
    }
  })
save(distXsp_EOR, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_EOR.Rda") 

```

#Maxent function
```{r}
maxentrun <- function(whichones, spatialpointsdataframe_herb, 
                      Whichproj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"),
                      numberofReps = 10, 
                      maxentarguments = FALSE, predictorvariables = rasterstack, 
                      pathstart, filenames, kfoldnum = 4, 
                      error = FALSE, distdistribution = NULL, backgroundscale = 5000){
        for(x in whichones){
            pointsspdf <- SpatialPointsDataFrame(coords = spatialpointsdataframe_herb[[x]][,c("decimalLongitude","decimalLatitude")],
                                                 data = spatialpointsdataframe_herb[[x]],
                                                 proj4string = Whichproj4string)
          if(error == TRUE){
               # for each point I will draw a circle of size (drawn from the distribution of error seen distXspall$Dist) and then pick a random point along the circle.
              errorpointsout <- do.call(rbind,lapply(1:nrow(pointsspdf), function(r){
                errordist <- sample(distdistribution, 1)
                if(errordist>0){
                  erroraround <- gBuffer(pointsspdf[r,], width=errordist)
                  newpoint <- erroraround@polygons[[1]]@Polygons[[1]]@coords
                  out <- newpoint[sample(1:nrow(newpoint),1),]
                } else {
                  out <- pointsspdf@coords[r,]
                  }
                out
                }))
                
                df <- SpatialPointsDataFrame(coords = errorpointsout,
                                             data = pointsspdf@data,
                                             proj4string = CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
                circlesout <- circles(df, d = backgroundscale) #Should be 5km around
                polygns <- polygons(circlesout)
                bgpnts <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
                
                convertxy <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
                proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
                bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
          } else {
                convertxy <- spTransform(pointsspdf, CRS("+proj=longlat +datum=WGS84"))
                circlesout <- circles(pointsspdf, d = backgroundscale)
                polygns <- polygons(circlesout)
                bgpnts <- spsample(polygns, 300, "stratified")
                # proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
                bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
            
          }
            
             for(rep in 1:numberofReps){
                convertxy$kfold <- kfold(convertxy, k=kfoldnum) # to have 75:25%
                if(maxentarguments == TRUE){
                  xm <- maxent(x = predictorvariables,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords,
                           args=c("noautofeature","noproduct","nothreshold"))
                } else {
                  xm <- maxent(x = predictorvariables,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords)
                }
                
                write.csv(data.frame(convertxy@coords,convertxy@data),
                          paste(pathstart,"presenceHerb",filenames,"Sp",x,"kfold",rep,".csv", sep=""))
                # write.csv(data.frame(bgpnts@coords, convertxy@data[1,c("Species","Area")]),
                #           paste(pathstart,"presenceHerb",filenames,"Sp",x,"kfold",rep,".csv", sep=""))
                save(xm, file= paste(pathstart,"maxentHerb",filenames,"Sp",x,"kfold",rep,".Rda", sep=""))        
        
                gc()
                #register parallel computing backend
                ncores <- detectCores()-1
                cl = parallel::makeCluster(ncores)
                doParallel::registerDoParallel(cl,ncores)
                #compute indices for data splitting
                rows = 1:nrow(predictorvariables)
                split = sort(rows%%ncores)+1
                outname = paste(pathstart,"PredictHerb",filenames,"Sp", x,"kfold",rep, sep="")
                #perform the prediction on subsets of the predictor dataset
                foreach(i=unique(split), .combine=c)%dopar%{
                  rows_sub = rows[split==i]
                  sub = raster::crop(predictorvariables,raster::extent(predictorvariables, min(rows_sub), max(rows_sub), 
                                                                1, ncol(predictorvariables)))
                  raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
                }
        
                e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, predictorvariables)
                save(e, file= paste(pathstart,"evaluateHerb",filenames,"Sp",x,"kfold",rep,".Rda", sep=""))
        
                rm(xm)
                gc()
                stopCluster(cl)
             }
                e
        }
}



```


1. Select background points trying to account for biased sampling (would have sampled within area where presence points were)  
2. Select background points from larger area   
3. Select background points ramdomly from entire possible area    
```{r}
notnull <- which(!unlist(lapply(distXsp_EOR, is.null)))
length(notnull)
match(1:68,notnull)
atleast12 <- unlist(lapply(notnull, function(l){
  if(nrow(distXsp_EOR[[l]][[2]])>11) l
  }))


distXsp_justEOR_forspdf <- mapply('[[', distXsp_EOR, 2)
distXsp_justEOR_spdf <- lapply(1:68, function(x) NA)
for(i in atleast12){
  out <- data.frame(distXsp_justEOR_forspdf[[i]])
  colnames(out) <- c("decimalLongitude","decimalLatitude")
  distXsp_justEOR_spdf[[i]] <- out
}

pathstart <- ("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_EOR_asis_error/")
maxentrun(whichones = atleast12, numberofReps = 10, error = FALSE,
          Whichproj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"),
          spatialpointsdataframe_herb = distXsp_justEOR_spdf,
          maxentarguments = FALSE, filenames = "EOR_bg5000", 
          predictorvariables = rasterstack, pathstart = pathstart, backgroundscale = 5000)



```
