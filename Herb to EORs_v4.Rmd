---
title: "Herbarium Bias CNHP"
author: "Michelle DePrenger-Levin"
date: "December 4, 2017"
output: html_document
---


cd /p/hackathon/Simulations/

```{r}
rm(list=ls())

# install.packages("NicheMapR") based on animal needs anyway, mechanistic
library(ggplot2)
library(rgeos)
library(sp)
# library(spdep)
library(rgdal)
library(maptools)
library(raster)
library(Taxonstand)
# library(RCurl)
# library(taxize)
# library(ggmap)

library(dismo)
library(ENMeval)
# library(biomod2)
library(spThin)

library(tidyr)
library(stringr)
library(magrittr)
devtools::install_github("ropensci/prism")
library(prism)

library(doParallel)
library(parallel)
library(foreach)
require(lme4)
require(lattice)
require(AICcmodavg)


     library(splancs)

# #Skip making these, takes a long time
# load("P:/hackathon/Simulations/circleEOR.Rda")
# load("P:/hackathon/Simulations/circleHerb.Rda")
# load("P:/hackathon/Simulations/EORgrid.thin.Rda")
# # load("P:/hackathon/Simulations/circleEOR.Rda")
# load("P:/hackathon/Simulations/envs.backgEOR.Rda")
# load("P:/hackathon/Simulations/envs.backgHerb.Rda")
# load("P:/hackathon/Simulations/Herb.thin1000.Rda")
# load("P:/hackathon/Simulations/EORgrid.thin.Rda")

load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2names.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid.Rda")


load("P:/hackathon/Simulations/coloradosps.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorsinglecell.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorandherb.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp1.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_herbpost1980.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorpost1980.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_data.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_data2.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Maxent46species.Rda")

colocounties <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties_wgs84")
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")


ScaleBar <- function(reference_raster_utm, round_to_nearest_km, width_percent, y_percent_from_bottom, x_percent_from_left, y_text_percent_from_bottom, ...) {
    # Round by max to nearest... e.g. 5 km 
    mround <- function(x,base){ 
        base*round(x/base) 
    }   
    # scale bar size adjustment to avoid decimals
        scale_size <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*width_percent)/1000
        scale_size_adj <- mround(scale_size, round_to_nearest_km)
        scale_size_adj_plot <- (scale_size_adj*1000)/2
    # Horizontal percent position (x) for scale bar
        x_position <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*x_percent_from_left)+xmin(reference_raster_utm)
    # Vertical percent position y for scale bar
        y_position <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_percent_from_bottom)+ymin(reference_raster_utm)
        y_position_text <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_text_percent_from_bottom)+ymin(reference_raster_utm)
    # Draw line on plot
        library(sp)
        x_ends <- c((x_position-scale_size_adj_plot), (x_position+scale_size_adj_plot))
        y_ends <- c((y_position), (y_position))
        scale_bar_line <- SpatialLines(list(Lines(Line(cbind(x_ends, y_ends)), ID="length")))
        projection(scale_bar_line) <- projection(reference_raster_utm)
        plot(scale_bar_line, add=TRUE, ...)
        text(x_position, y_position_text, paste0(scale_size_adj, "km"))
}


```
Make grid points and thin to the number of herb points right away. 
```{r}
thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}

```

Want to use elevation, slope and aspect, ruggedness
```{r}

# coElev <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Elevation_VT/CO_Mosaic_Elevation_VT/co_elev_VT_WGS84.tif")
# 
# coElev_biosize <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Elevation_VT/co_elev_WGS84_30sec.tif")
# 
# coAspect <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Aspect_VT/co_aspect_VT_WGS84.tif")
# 
# coSlope <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Slope_VT/co_slope_VT_WGS84.tif")

coElev <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/coplus50int.tif")

coAspect <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/aspect50int.tif")

coSlope <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/COplus_slope50.tif")

coRugged <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/COplus_ruggedInt50.tif")


```



```{r}

l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")

#Each polygon might be made of multiple disconnected polygons. Need to separate and label
l1G1G2 <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2"),])
l1G1G2$PolyID <- do.call(rbind, lapply(split(l1G1G2,l1G1G2$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))


l1G1G2and <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2","G1G2"),])
l1G1G2and$PolyID <- do.call(rbind, lapply(split(l1G1G2and,l1G1G2and$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))
namesg1g2 <- table(as.character(l1G1G2$GNAME))
length(namesg1g2) #60 species
namesg1g2and <- table(as.character(l1G1G2and$GNAME))
length(namesg1g2and) # 68
namesg1g2and <- c(namesg1g2and[match(names(namesg1g2),names(namesg1g2and))],
                  namesg1g2and[setdiff(names(namesg1g2and),names(namesg1g2))])
g1g2names61_68 <- TPL(names(namesg1g2and[61:68]))
proj4string(l1G1G2and) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")

namesg1g2 <- table(l1G1G2$GNAME)
length(namesg1g2[namesg1g2 > 0]) #60 species
g1g2names <- TPL(names(namesg1g2[namesg1g2 > 0]))
table(g1g2names$Taxonomic.status)
# 2 not in there, "Gutierrezia elegans" "Oonopsis sp. 1", 10 synonyms, 3 unresolved
# save(g1g2names, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2names.Rda")

g1g2names[g1g2names$Taxonomic.status == "Unresolved",]
#Gilia sedifolia
#Ipomopsis ramosa
#Packera mancosana
```

Cite MODIS data: <https://lpdaac.usgs.gov/citing_our_data>   
<https://lpdaac.usgs.gov/data_access/data_pool>  - need to get data but weeky mainenance is every wednesday until noon   
Got snow data https://search.earthdata.nasa.gov/data/retrieve/5396545932 can compare to NCAR's data.   
got some veg data or getting https://search.earthdata.nasa.gov/data/retrieve/2536564325  
```{r}
library(ncdf4)
#library(maptools)
#library(extRemes)
library(fields)
library(abind)
library(prism)

library(raster)
library(rasterVis)
#library(measurements)
library(ENMeval)
library(RCurl)
library(dismo)

#install.packages("digest")
library(devtools)
#install_github('hadley/rvest')
library(rvest)

# add the command to bind along the 3rd dimension
abind3 <- function(...) { abind(along = 3, ...) }

```



#Michelle DePrenger-Levin      
In ArcMap do this: <https://blogs.esri.com/esri/arcgis/2010/09/16/nearbygroup/>
repeat distance analysis in R          
"coloradosps" == SEINet collections from Colorado - downloaded 12/6/2017 from SEINet        
Only G1G2 EORs (to limit range of species)
"colonames" == TPL synonomy for all coloradosps names
```{r}
coloradosps <- read.csv("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/SEINET G1 G2 Vouchers/occurrences.csv")

#save(coloradosps, file= "P:/hackathon/Simulations/coloradosps.Rda")
#nrow(coloradosps) #567328

howlongrecordedby <- nchar(as.character(coloradosps$recordedBy))
recordedby <- unique(coloradosps$recordedBy[howlongrecordedby < 100])

#table(coloradosps$basisOfRecord) # PreservedSpecimen: 566067; preservedspecimen: 55; Preserved specimen: 143; Photograph: 1; Observation: 124; Native and Naturalized Flora of; HumanObservation; many just wrong column info in this


# both of these from OBI: California Polytechnic State University
#coloradosps[coloradosps$basisOfRecord == "Plants of Jefferson County Open",] #68 plus 1 more with some other typo
#coloradosps[coloradosps$basisOfRecord == "Plants of Colorado",] #68 plus 1 more with some other typo

#Subset by just preserved specimens  
coloradosps$basisOfRecord <- as.character(coloradosps$basisOfRecord)
coloradosps.specimens <- coloradosps[grep("specimen",coloradosps$basisOfRecord,
                                          ignore.case=TRUE),]
#table(coloradosps.specimens$basisOfRecord)

coloradosps.specimens <- coloradosps.specimens[nchar(coloradosps.specimens$basisOfRecord)<50,]

#Now only preserved specimens
coloradosps <- coloradosps.specimens
#nrow(coloradosps) #566265

g1g2names$AcceptedName <- paste(g1g2names$New.Genus,g1g2names$New.Species)
#match SEINet names to either the given or accepted names from G1/G2s
#length(unique(g1g2names$Taxon))
#length(unique(g1g2names$AcceptedName)) #60
#length(unique(c(g1g2names$Taxon,g1g2names$AcceptedName))) #71 


rowstomatch <- lapply(c("Taxon","AcceptedName"), function(x){
   coloradosps[,"scientificName"] %in%  g1g2names[,x]
})

#The rows to keep that match either an accepted or synonym or unresolved name for a G1G2 species
#coloradosps.specimens was intermediate to get rid of none specimen records
coloradosps.g1g2 <- unique(rbind(coloradosps[rowstomatch[[1]],],coloradosps[rowstomatch[[2]],]))
nrow(coloradosps.g1g2)
hist(as.numeric(as.character(coloradosps.g1g2$decimalLatitude)))
#write.table(sort(unique(coloradosps.g1g2$scientificName)), "clipboard", sep="\t", row.names=FALSE)
plot(as.numeric(as.character(coloradosps.g1g2$decimalLongitude)),
     as.numeric(as.character(coloradosps.g1g2$decimalLatitude)),
     xlab="Longitude",ylab="Latitude",pch=16,cex=0.5)
```
How many are within 0.01 decimals of each other, round to two decimals - per Soltis 
```{r}
coloradosps.g1g2$decimalLatitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLatitude))
coloradosps.g1g2$decimalLongitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLongitude))
# ctrl+shift+c to comment/uncomment
# coloradosps.g1g2[which(coloradosps.g1g2$decimalLatitude <37),]
# coloradosps.g1g2[which(coloradosps.g1g2$decimalLongitude < -109.2),]

coloradosps.g1g2$lon2 <- round(coloradosps.g1g2$decimalLongitude,2) # about 1.1 km 
coloradosps.g1g2$lat2 <- round(coloradosps.g1g2$decimalLatitude,2)

coloradosps.g1g2$lon3 <- round(coloradosps.g1g2$decimalLongitude,3) # about 110 m
coloradosps.g1g2$lat3 <- round(coloradosps.g1g2$decimalLatitude,3)

#convert points from WGS84 to NAD83
projected <- coloradosps.g1g2[complete.cases(coloradosps.g1g2[,c("lat2","lon2")]),]
coordinates(projected) <- ~ lon2+lat2
proj4string(projected) <- CRS("+proj=longlat +datum=WGS84") 
projected <- spTransform(projected, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))

# write.csv(coloradosps.g1g2, "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/FieldData_EORG1G2_WGS84.csv")
```


There seems to be lots of points in Denver but no EOs!    
gray60 or 80, black dots for publication   , col="midnightblue"
```{r}

plot(colocounties.UTM,border="gray50") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2, border="gray60", add=TRUE, lwd=5) #
plot(projected, add=TRUE, pch=20, cex=0.5)


polys_46 <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[notnull],
                                       g1g2names$Taxon[notnull]),] 
    # l1G1G2[l1G1G2$GNAME %in% as.character(mapply(FUN=function(x) unique(x$GNAME)[1],g1g2names[notnull,])),]
plot(polys, lwd=5)
plot(polys_46, border="pink", add=TRUE)
str(as.character(mapply(FUN=function(x) unique(x$GNAME)[1],g1g2names[notnull,])))
unique(as.character(polys_46$GNAME))

# Was HerbPntsEORs_CO.jpg --> changing to Figure 1 in .eps format
# grDevices::setEPS; says ps.options needs to be called before calling postscript and the override with more arguments to postscript

outside <- extent(rasterstack[[1]])
e <- as(outside, "SpatialPolygons")
sp::proj4string(e) <-  CRS("+proj=longlat +datum=WGS84") 

e.geo <- sp::spTransform(e, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))

# setEPS()
# postscript("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/Figure_1.eps", width=250, height=175)
jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/Figure_1.jpg",
     width=250, height=175,units='mm', res=300)

# the extents of the rasters
# plot(e.geo)
plot(colocounties.UTM,border="gray60") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2and, border="gray60", add=TRUE, lwd=4) #
plot(projected, add=TRUE, pch=20, cex=0.5)
ScaleBar(colocounties.UTM,
             10, .25, .05, .85, .10, lwd=1)

dev.off()
```

```{r}
jpeg("Q:/Research/Presentations/External Conference presentations/Natural Areas Conference 2018/EORs.jpg",
     width=170, height=150,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2, border="goldenrod", add=TRUE, lwd=5) #☻
#plot(projected, add=TRUE, pch=20, cex=0.5)

dev.off()

```

```{r}
jpeg("Q:/Research/Presentations/External Conference presentations/Natural Areas Conference 2018/herbs.jpg",
     width=170, height=150,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
#plot(l1G1G2, border="blue", add=TRUE, lwd=5) #☻
plot(projected, col = "blue", add=TRUE, pch=20, cex=0.5)

dev.off()

```

```{r}
jpeg("Q:/Research/Presentations/External Conference presentations/Natural Areas Conference 2018/both.jpg",
     width=170, height=150,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2, border="goldenrod", add=TRUE, lwd=5) 
plot(projected, col="blue", add=TRUE, pch=20, cex=0.5)

dev.off()

```
       [1] WGS84                     WGS 84                    WGS 1984                      
       [4] WGS96                     WGS 72                    WGS-84                     
       [7] WGS 1984.                 WGS83                     WGS84 (UTM Datum: NAD83)   
      [10] WGS84  (UTM Datum: NAD83) WGS84, Google Earth       WGS 1983                   
      [13] WGS 1984,                 WGS98                     WGS85                       
      [16] WGS86                     WGS89                     WGS95                       
      [19] WGS87                     WGS88                     WGS97                       
      [22] WGS92                     WGS 83                    WGS93                       
      [25] WGS94                     WGS84/NAD83               WGS90                        
      [28] WGS 19                    WGS99                     WGS91      
      
      "The latest revision is WGS 84 (also known as WGS 1984, EPSG:4326), established in 1984 and last revised in 2004.[1] Earlier schemes included WGS 72, WGS 66, and WGS 60. WGS 84 is the reference coordinate system used by the Global Positioning System."


Trying to reduce memory before running 
        > rm(colocounties)
        > rm(colocounties.UTM)
        > rm(coloradosps.g1g2)
        > rm(coloradosps.specimens)
        > rm(familyxyear)
        > rm(herbariumxyear)
        > rm(projected)

#Already loaded! Skip
```{r}
# oh no, want only after 1980 collections

distXsp_v3 <- lapply(1:60, function(i){
  gc()
  g1g2now <- coloradosps.g1g2[coloradosps.g1g2$scientificName %in%
                                c(g1g2names$Taxon[i],g1g2names$AcceptedName[i])&
                                !is.na(coloradosps.g1g2$decimalLatitude),]
  
  g1g2now <- g1g2now[as.numeric(as.character(g1g2now$year))>1980,]
  g1g2now <- g1g2now[g1g2now$decimalLatitude>0,]
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)]
  gc()
  
  
  if(nrow(g1g2now)>0){
  # put grid points across colorado, sample from it for each polygons
    polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                        g1g2names$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")

    
    totalarea <- sum(area(disaggregate(polys)))
  # area of each polygon
    areanow <- sapply(slot(polys,"polygons"), slot, "area")
    
  # Proportional area to the whole area number to thin
    EORpnts <- do.call(rbind, lapply(1:length(polys), function(f){
      outline <- polys@polygons[[f]]@Polygons[[1]]@coords
      grid <- makegrid(polys, cellsize = 50) # cellsize in map units!
      names(grid) <- c("x","y")
      gridout <- grid[inout(grid,outline), ]
      if(nrow(gridout)>1){
        gridthin <- thin.max(gridout,c("x","y"),round(nrow(g1g2now)*(areanow[[f]]/totalarea),0))
        gc()
        } else {
          if(nrow(gridout)>0) {
            gridthin <- gridout 
          } else {
            gridthin <- NULL
          }
          }
      gridthin
      }))
    gc()
    
  #turn into spatialpointsdataframe for individual species
    coordinates(g1g2now) <- ~decimalLongitude+decimalLatitude
    proj4string(g1g2now) <- CRS("+init=epsg:4326")  # CRS("+proj=longlat +datum=WGS84")
    g1g2now <- spTransform(g1g2now, CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
  # The minimum distance from each point to the nearest polygon
    distnow <- apply(gDistance(g1g2now,polys, byid=TRUE),2,min)
    gc()
    
    out <- list(g1g2now,distnow, areanow, EORpnts)
    gc()
    out
    }
  })

save(distXsp_v3, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_v3.Rda") 

```




# testing background points   
either use KDE with kernelUD or Minimum convex polygon (MCP)
```{r}
library(adehabitatHR)
library(ks)
class(distXsp_v3[[1]][[1]])

xy <- data.frame(distXsp_v3[[1]][[1]]@coords)
names(xy) <- c("X","Y")
# coordinates(xy) <- ~ X+Y
xy <- SpatialPoints(xy)

# If added in points alnog roads then could make the contour even closer to parts where likely surveyed. 
# 95% home range contour
ud <- kernelUD(xy, extent=0.5, grid=150)
ver <- getverticeshr(ud, 95)

# kde.foo <- kde(xy, xmin=c(-5,-5), xmax=c(5,5), bgridsize=c(151,151))
# just put random points for background points witin the kernelUD 
bgpts <- spsample(ver, 300, "stratified")

verMCP <- mcp(xy, percent=95)

plot(ver)
# plot(verMCP, col="blue", add=TRUE)
points(bgpts, col="red")
points(xy, col="green")
points( spsample(ver, 300, "nonaligned"), col="black", pch=16)
points( spsample(ver, 300, "random"), col="orange", pch=3)

# If you want to introduce bias:
mm <- ud@coords[order(ud@coords[,1], ud@coords[,2]),]
mm
```



```{r}
g1g2names[g1g2names$Family=="Plantaginaceae",]#Add the Family for Gutierrezia: Asteraceae  and Oonopsis: Asteraceae
g1g2names$Family[g1g2names$Family==""] <- "Asteraceae"
g1g2names$Family[g1g2names$Family=="Compositae"] <- "Asteraceae"
g1g2names$Family[g1g2names$Family=="Leguminosae"] <- "Fabaceae"

```

select background points that are closer to road so pick more background points around roads and most where buffer around population and roads overlap.     
Or like Wunder's student's bat paper, just use random points from the circles made earlier, just a buffer, cite Elith   
Or de-bias presence records for areas near roads. Phillips et al. 2009: design selection of background data to reflect same sample selection bias as occurrence data.   
```{r}
coroads <- shapefile("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Roads/Local Roads/Local Roads SHP/LROADS.shp")

#Planer
proj4string(coroads) #"+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
r <- raster(extent(coroads))
proj4string(r) <- proj4string(coroads)
r.smaller <- disaggregate(r, fact=2)

dd <- gDistance(coroads, as(r, "SpatialPoints"), byid=TRUE)
r[] <- apply(dd,1,min)

dd.smaller <- gDistance(coroads, as(r.smaller, "SpatialPoints"), byid=TRUE)
r.smaller[] <- apply(dd.smaller,1,min)

toraster <- raster(extent(r.smaller))
proj4string(toraster) <- rscrs

r.longlat <- projectRaster(r.smaller,crs = rscrs)

plot(r)
plot(r.smaller)

plot(r.longlat)
plot(circleHerb[[2]], add=TRUE)

plot(rasterstack[[1]], xlim=c(-109,-103), ylim=c(37,41))

plot(r.smaller[r.smaller<8000])
plot(coroads, add=TRUE)
```

Either background points are selected with more frequency closer to roads or 'background' is a buffer around roads and around points and selected randomly within that overlap - all need to match the number of presence points. 

Without quality presence–absence data, discrimination metrics such as TSS can be misleading measures of model performance
Boris Leroy  Robin Delsol  Bernard Hugueny  Christine N. Meynard  Chéïma Barhoumi Morgane Barbet‐Massin  Céline Bellard
First published: 02 July 2018    
   
1. Add up all the distances as proportions or chance of getting to these, act as contributions like fecundity but in reverse.   
2. OR, know the number of grid cells within a few of the polygon, more likely to have surveyed closer to a road and closer to the point or line of the EOR polygon.   
3. will want proportionally close number of presence and background points. so use Binomial distribution to figure out probability of placing random background points in a cell and at what frequency.. over cells? randomly across background area? Use Bernolli to select which cells to include? http://users.stat.ufl.edu/~abhisheksaha/sta4321/lect12.pdf       
4. use makegrid with n = the probability? 


     1. Could use the comparison of more points (appropriate density?) within EORs vs. the sparse data because of biases and practices of herbarium collections to compare overlap of niche models for herb, eor, and sample size same eor. how many background?    
     2. Can't I get the background points from VisTrails? Yes! Background points were always set to 300 for my first crack at it. Too many? Maybe, maybe fine. Or just understand the bias it creats for AUC, sensitivity, specificity and such. 




http://www.earthskysea.org/!ecology/sdmShortCourseKState2012/grinnellExercise/exercise-tuning-maxent-using-beta-and-aic.html  
https://cran.r-project.org/web/packages/ENMeval/vignettes/ENMeval-vignette.html    
Use AICc with Maxent to find best model  
```{r}



```


create a raster in R as distance from road
```{r}
localroads <- readOGR(dsn = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Roads/Local Roads/Local Roads SHP", layer="LROADS")


bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)

#Create a raster to hold distance from road in the same size and extent of the bioclim layers
r <- raster()
extent(r) <- extent(bioclim.colorado[[1]])
projection(r) <- projection(bioclim.colorado[[1]])
res(r) <- res(bioclim.colorado[[1]])

localroads.latlon <- spTransform(localroads, CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))


dd <- gDistance(localroads.latlon, as(r, "SpatialPoints"), byid=TRUE)

```



Is there anything inherintly interesting about the genus? Maybe some genera are more likely to shift in range than others... so yes, keep in.  


```{r}
g1g2names61_68$AcceptedName <- paste(g1g2names61_68$New.Genus,g1g2names61_68$New.Species,sep=" ")
l1G1G2and$GNAME <- as.character(l1G1G2and$GNAME)

# The additional 8 when I add in the G1G2 not just the G1 and G2
for(i in 61:68){
   polys <- l1G1G2and[l1G1G2and$GNAME %in% c(g1g2names61_68$AcceptedName[i-60],
                                        g1g2names61_68$Taxon[i-60]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
    print(paste(g1g2names61_68$AcceptedName[i-60],  g1g2names61_68$Taxon[i-60]))
    print(table(as.character(polys$LASTOBS)))
    print(sort(as.numeric(substring(polys$LASTOBS,1,4))))
    names(coloradosps.g1g2_6168[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)])
names(coloradosps.g1g2[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)])
}

coloradosps <- read.csv("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/SEINET G1 G2 Vouchers/occurrences.csv")

rowstomatch6168 <- lapply(c("Taxon","AcceptedName"), function(x){
   coloradosps[,"scientificName"] %in%  g1g2names61_68[,x]
})
# Picks the ones that match either list one=Taxon, or list two AcceptedName for which some are duplicates, take unique rows. 
coloradosps.g1g2_6168 <- unique(rbind(coloradosps[rowstomatch6168[[1]],],
                                      coloradosps[rowstomatch6168[[2]],]))
nrow(coloradosps.g1g2_6168)


coloradosps.g1g2_6168$decimalLatitude <- 
  as.numeric(as.character(coloradosps.g1g2_6168$decimalLatitude))
coloradosps.g1g2_6168$decimalLongitude <- 
  as.numeric(as.character(coloradosps.g1g2_6168$decimalLongitude))
coloradosps.g1g2_6168$lon2 <- round(coloradosps.g1g2_6168$decimalLongitude,2) # about 1.1 km 
coloradosps.g1g2_6168$lat2 <- round(coloradosps.g1g2_6168$decimalLatitude,2)
coloradosps.g1g2_6168$lon3 <- round(coloradosps.g1g2_6168$decimalLongitude,3) # about 110 m
coloradosps.g1g2_6168$lat3 <- round(coloradosps.g1g2_6168$decimalLatitude,3)

names(coloradosps.g1g2_6168[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)])
names(coloradosps.g1g2[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)])

coloradosps.g1g2 <- read.csv("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/FieldData_EORG1G2_WGS84.csv")
namesg1g2 <- table(as.character(l1G1G2$GNAME))
g1g2names <- TPL(names(namesg1g2))
namesfoo <- lapply(1:2, function(i){
  gc()
  g1g2now <- coloradosps.g1g2[coloradosps.g1g2$scientificName %in%
                                c(g1g2names$Taxon[i],g1g2names$AcceptedName[i])&
                                !is.na(coloradosps.g1g2$decimalLatitude),]
  
  g1g2now <- g1g2now[as.numeric(as.character(g1g2now$year))>1800,]
  # remove points not in Colorado
  g1g2now <- g1g2now[g1g2now$decimalLatitude>35,]
  g1g2now <- g1g2now[g1g2now$decimalLongitude>(-113),]
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)]
  names(g1g2now)
})
names(distXsp_noEORgrid68[[1]])
head(distXsp_noEORgrid68[[1]])
names(distXsp_noEORgrid[[1]])
      namesfoo[[1]]

## START HERE! can't figure out why rows are different in the old and new way!
```

```{r}
distXsp_noEORgrid68 <- lapply(61:68, function(i){
  gc()
  g1g2now <- coloradosps.g1g2_6168[coloradosps.g1g2_6168$scientificName %in%
                                c(g1g2names61_68$Taxon[i-60],g1g2names61_68$AcceptedName[i-60])&
                                !is.na(coloradosps.g1g2_6168$decimalLatitude),]
  g1g2now$year <- as.numeric(as.character(substring(g1g2now$year,1,4)))
  g1g2now <- g1g2now[g1g2now$year>1800,]
  # remove points not in Colorado
  g1g2now <- g1g2now[g1g2now$decimalLatitude>35,]
  g1g2now <- g1g2now[g1g2now$decimalLongitude>(-113),]
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)]
  gc()
  
  if(nrow(g1g2now)>0){
  # put grid points across colorado, sample from it for each polygons
    polys <- l1G1G2and[l1G1G2and$GNAME %in% c(g1g2names61_68$AcceptedName[i-60],
                                        g1g2names61_68$Taxon[i-60]),] 
    # proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
        
    years <- as.numeric(substring(polys$LASTOBS,1,4))
    yearsnotNA <- c()
    for(l in 1:length(years)){
      yearsnotNA[l] <- if(years[l]<9999){ 
                                      l } else {
                                        NA
                                      }
    }
    yearsnotNA <- yearsnotNA[!is.na(yearsnotNA)] 
    polys <- polys[yearsnotNA,]
    
    totalarea <- sum(area(disaggregate(polys)))
  # area of each polygon
    areanow <- sapply(slot(polys,"polygons"), slot, "area")
    
  #turn into spatialpointsdataframe for individual species
    coordinates(g1g2now) <- ~decimalLongitude+decimalLatitude
    proj4string(g1g2now) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
    g1g2now <- spTransform(g1g2now, CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
  # The minimum distance from each point to the nearest polygon
    distnow <- apply(gDistance(g1g2now,polys, byid=TRUE),2,min)
    gc()
   
  out <- data.frame(Species = g1g2names61_68$AcceptedName[i-60], g1g2now,Dist = distnow, Area = totalarea, 
                    EORdate = polys$LASTOBS[apply(gDistance(g1g2now,polys, byid=TRUE),2,which.min)],
                    Yeardiff = g1g2now$year- as.numeric(substring(as.character(polys$LASTOBS[apply(gDistance(g1g2now,polys, byid=TRUE),2,which.min)]),1,4)))
    gc()
    out
    }
  })
save(distXsp_noEORgrid68, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid68.Rda") 

distXsp_noEORgrid68[[1]]
```

Yeardiff is the herbarium colleciton year - the polygon mapped year (LastOBS) so positive values are herbarium later than mapped, negative numbers are the herbarium colleciton before the mapped time
```{r}
distXspall[,which(is.na(match(names(distXspall),names(distXsp_noEORgrid68[[1]]))))]

distXspall <- do.call(rbind, distXsp_noEORgrid)
distXspall <- rbind(distXspall[,-c(doesntmatch)],
                    do.call(rbind, distXsp_noEORgrid68)[,-c(doesntmatch)])
distXspall$New.Genus <- gsub("([A-Za-z]+).*", "\\1", distXspall$Species)
table(distXspall$Yeardiff) # 9999 for unknown year of EOR mapping --> removed now
distXspall[distXspall$Yeardiff< -100,c("EORdate","year")]
names(distXspall)
```
But isn't the whole point that I want to vary over lots of genera?   
Models included (1) species range, (2) collection year, (3) Genus, (4) years between collection and mapping, (5) collection year + species range, (6) collection year * species range, (7) Genus * Year, (8) Genus * collection year * species range, (9) Genus * years between collection and mapping * species range, and (10) intercept only (null model).
```{r}
f1 <- lm(Dist ~ as.factor(New.Genus)*year + Area, data= distXspall)
f2 <- lm(Dist ~ year + Area, data= distXspall)
f3 <- lm(Dist ~ year, data= distXspall)
f4 <- lm(Dist ~ Area, data= distXspall) #x is the area of the species known range
f5 <- lm(Dist ~ 1, data= distXspall)
f6 <- lm(Dist ~ year*Area, data= distXspall) #year given the range
f7 <- lm(Dist ~ as.factor(New.Genus)*(year), data= distXspall)
f8 <- lm(Dist ~ Yeardiff, data= distXspall) # range shift
f9 <- lm(Dist ~ as.factor(New.Genus)*year*Area, data= distXspall)
f10 <- lm(Dist ~ as.factor(New.Genus)*Yeardiff*Area, data= distXspall)


(lmresults <- aictab(list(f1,f2,f3,f4,f5,f6,f7,f8,f9,f10),
       modnames=as.character(unlist(lapply(list(f1,f2,f3,f4,f5,f6,f7,f8,f9,f10),formula))),
       second.ord = FALSE))

evidence(aictab(cand.set = list(f1,f2,f3,f4,f5,f6,f7,f8,f9,f10),
                modnames = as.character(unlist(lapply(list(f1,f2,f3,f4,f5,f6,f7,f8,f9,f10),formula)))))

sapply(1:length(lmresults$Delta_AICc), function(i){
  exp(-0.5*lmresults$Delta_AICc[i])/sum(exp(-0.5*lmresults$Delta_AICc))
})

(er1 <- exp(0.5*lmresults$Delta_AICc[2]))
(er2 <- exp(0.5*lmresults$Delta_AICc[3]))

```

When ignoring genus since those are so unevenly applied (lots of mustards)
```{r}

# Why is aictab adding an extra parameter
# maybe AICc

str(distXspall)
# f1 <- lm(Dist ~ as.factor(New.Genus)*year + Area, data= distXspall)
f2 <- lm(Dist ~ year + Area, data= distXspall)
f3 <- lm(Dist ~ year, data= distXspall)
f4 <- lm(Dist ~ Area, data= distXspall) #x is the area of the species known range
f5 <- lm(Dist ~ 1, data= distXspall)
f6 <- lm(Dist ~ year*Area, data= distXspall) #year given the range
# f7 <- lm(Dist ~ as.factor(New.Genus)*(year), data= distXspall)
f8 <- lm(Dist ~ Yeardiff, data= distXspall) # range shift
# f9 <- lm(Dist ~ as.factor(New.Genus)*year*Area, data= distXspall)
# f10 <- lm(Dist ~ as.factor(New.Genus)*Yeardiff*Area, data= distXspall)

f11 <- lm(Dist ~ Yeardiff*Area, data= distXspall) # range shift by specificity

f12 <- lm(Dist ~ Yeardiff+Area, data= distXspall) # range shift by specificity

aictab(list(f4))

AICc(f4, return.K = TRUE)
AIC
str(foo)

(lmresults <- aictab(list(f2,f3,f4,f5,f6,f8,f11,f12),
       modnames=as.character(unlist(lapply(list(f2,f3,f4,f5,f6,f8,f11,f12),formula))),
       second.ord=FALSE))

evidence(aictab(cand.set = list(f2,f3,f4,f5,f6,f8,f11,f12),
                modnames = as.character(unlist(lapply(list(f2,f3,f4,f5,f6,f8,f11,f12),formula))))) #, second.ord=FALSE

sapply(1:length(lmresults$Delta_AICc), function(i){
  exp(-0.5*lmresults$Delta_AICc[i])/sum(exp(-0.5*lmresults$Delta_AICc))
})

(er1 <- exp(0.5*lmresults$Delta_AICc[2]))
(er2 <- exp(0.5*lmresults$Delta_AICc[3]))
(er3 <- exp(0.5*lmresults$Delta_AICc[4]))
(er4 <- exp(0.5*lmresults$Delta_AICc[5]))
(er5 <- exp(0.5*lmresults$Delta_AICc[6]))

```

```{r}
distXspall$areabin <- 100
distXspall$areabin[distXspall$Area < max(distXspall$Area)] <- 95
distXspall$areabin[distXspall$Area < quantile(distXspall$Area, .75)] <- 75
distXspall$areabin[distXspall$Area < quantile(distXspall$Area, .5)] <- 50
distXspall$areabin[distXspall$Area < quantile(distXspall$Area, .25)] <- 25
distXspall$areabin[distXspall$Area == min(distXspall$Area)] <- 1
table(distXspall$areabin)

ggplot(distXspall, aes(Yeardiff, Dist/1000))+
  geom_jitter(position=position_jitter(1), aes(colour=Area/(1000^2)), size=2, alpha=0.5, pch=16)+  # geom_point(aes(colour=year))+
  stat_smooth(method="lm")+
  theme_bw()+
  # facet_wrap(~areabin, nrow=2)+
  xlab("Year (Herb - CNHP)")+
  ylab("Distance (km) to nearest EOR")+
  scale_colour_gradientn(colours = rev(c("#FF0000", "#FFA500", "#FFFF00", "#008000", "#9999ff", "#000066"))) # (low="black",high="lightgreen")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
ggplot(distXspall, aes(Area/1000000, Dist/1000))+
  geom_jitter(position=position_jitter(1.5), aes(colour=Yeardiff), size=2, alpha=0.5, pch=21)+  # geom_point(aes(colour=year))+
  stat_smooth(method="lm")+
  theme_bw()+
  xlab("Species Range")+
  ylab("Distance (km) to nearest EOR")+
  facet_wrap(~New.Genus)+
  scale_colour_gradientn(colours = rev(c("#FF0000", "#FFA500", "#FFFF00", "#008000", "#9999ff", "#000066"))) # (low="black",high="lightgreen")

```
#Convext hull or tiny circles around eors vs herbarium vs. both together, how much change?    

The Weber example of an out of state person mapping a collection to Gray's Peak from Chicago Lake that should be Mount Evans.     
- <https://conps.org/wp-content/uploads/2015/05/Mount_Evans_Summit_Lake_4-24-2011.pdf>    

"coloradosps" == SEINet collections from Colorado - downloaded 12/6/2017 from SEINet      
"coloG1G2" == species matching names in L1 EORs but without any synonym corrections     
"seinet" == Mo worked on this, made distances from nearest EOR and looked at posted informaiton to figure out what might have been used to pick point on map        
      
ITISlist is synonmy pulled from ITIS into SQL    
TPL is pulling from synonym from the plant list   "colo"   
      "seinetMo"is synonymy with TPL for Mo's list of 53 species (that are G1/G2s)   
      "colonames" is synonym with TPL for all colorado specimens from SEINet   

<https://rpubs.com/spoonerf/SDM4>   
        
#ENMeval vignette
<https://cran.r-project.org/web/packages/ENMeval/vignettes/ENMeval-vignette.html>   
```{r}
bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39) #at 0.5 minutes of a degree
##just get the datafiles lat and long from pca_eorandherb and extract the bioclim variables in addtion to the monthly precip, min, max temps

plot(bioclim.colorado$bio1_12)
plot(colocounties, add=TRUE)

# Use rasters in a RasterStack:
class(bioclim.colorado)

#Need back to latlon for bioclim layers
pointsXsp.latlon <- list()
for(i in 1:length(want)){
  pointsXsp.latlon[[i]] <- spTransform(distXsp[[want[i]]][[1]], CRS(proj4string(bioclim.colorado)))
}

```

```{r}
jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/Figure2_v2.jpg",
     width=225, height=105,units='mm', res=300)

layout(matrix(c(1,2,3), 1,3))
plot(distXspall$Area,
     distXspall$Dist,
     xlab=expression(paste("Species Range km" ^2)),
     ylab=expression(paste("km")),
     pch=16, cex= .5, yaxt="n", xaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
     axis(1, at=c(0,10,20,30,40,50,60,70,80,90)*(1000^2), labels=c(0,10,20,30,40,50,60,70,80,90))
abline(lm(Dist~Area, data=distXspall))
mtext("a)", side=3, line=0, adj=0)
plot(jitter(distXspall$year ),
     distXspall$Dist,
     xlab="Year",
     ylab="",
     pch=16, cex= .25, yaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
abline(lm(Dist~year, data=distXspall))
mtext("b)", side=3, line=0, adj=0)
plot(jitter(distXspall$Yeardiff ),
     distXspall$Dist,
     xlab="Difference in collection year and mapped year",
     ylab="",
     pch=16, cex= .25, yaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
abline(lm(Dist~Yeardiff, data=distXspall))
mtext("c)", side=3, line=0, adj=0)
dev.off()
```

#Spatial thinning
<https://cran.r-project.org/web/packages/spThin/vignettes/spThin_vignette.html>     
Thin to create dataset in which all occurences are at least _thin.par_ distance apart. helps reduce effect of uneven, biased, species occurence collections on spatial model outcomes   
Got through 19 of them, go from 20 to length(wantEOR)   
SKIP, already loaded
```{r}
# The EOR grid points from distXsp is the forth item. Wants lat long, they are. 
#for(i in 1:length(wantEOR)){
#for(i in 20:length(wantEOR)){
#for(i in 21:length(wantEOR)){

EORgrid.thin <- list()
#for(i in c(1:18,21:47,49:length(wantEOR))){
for(i in c(20,48)){
  EORsp <- data.frame(distXsp[[wantEOR[i]]][[4]]@coords,
                      species=g1g2names$AcceptedName[wantEOR[i]])
    EORgrid.thin[[i]] <- thin(loc.data = EORsp,
                         lat.col = "x2", long.col = "x1",
                         spec.col="species",
                         thin.par = 1, reps=10,
                         locs.thinned.list.return = TRUE,
                         write.files = TRUE, max.files=5,
                         out.dir = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Thinned/",paste(out.base="EORsp_1km",i,"_",g1g2names$AcceptedName[wantEOR[i]],sep=""), write.log.file = TRUE,
                         log.file = "EORgridthinned_log.txt")
}

save(EORgrid.thin, file= "P:/hackathon/Simulations/EORgrid.thin.Rda")
```


```{r}
Herb.thin1000 <- list()
for(i in 1:length(want)){
  Herbsp <- data.frame(pointsXsp.latlon[[i]]@coords,
                       species=g1g2names$AcceptedName[want[i]])
  Herb.thin1000[[i]] <- thin(loc.data = Herbsp,
                     lat.col = "decimalLatitude", long.col = "decimalLongitude",
                     spec.col="species",
                     thin.par = 1, reps=1000,
                     locs.thinned.list.return = TRUE,
                     write.files = TRUE, max.files=5,
                     out.dir = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Thinned/",paste(out.base="Herb.thin_1km_1000",i,"_",g1g2names$AcceptedName[wantEOR[i]],sep=""), write.log.file = TRUE,
                     log.file = "EORgridthinned1000_log.txt")
}

save(Herb.thin1000, file= "P:/hackathon/Simulations/Herb.thin1000.Rda")
```


### Background points  
Can either do bounding box (plus some buffer) or circles at some diameter   
    
    - there are 60 species L1/L2 species with data   
    - 59 species have EOR data    
    - 46 species have herbarium data avalaible through SEINet    
    - wantEOR are the ones from the 60 that have EOR data so wantEOR[i] in a loop would get the ones I want    
    - want[i] would get teh 46 that have herbarium data from the list of 60 species   


Create the full dataframes for each species   
https://www.molecularecologist.com/2013/04/species-distribution-models-in-r/     

```{r}
#Create bckground points, give them a 0 and same column names with lat long. Give eors a 1 and herb a 2 for looking at groups but then do a clustering

sort(unique(coloradosps.g1g2_6168$scientificName)) #68 names since a few synonyms 
sort(unique(g1g2names$AcceptedName)) #60 names, why no Astragalus anisus??  
sort(unique(g1g2names$Taxon)) #60 names, why no Astragalus anisus??   

```


https://www.molecularecologist.com/2013/04/species-distribution-models-in-r/    
EOR presence is 1 and background is 3    
Herb presence is 2 and background is 4
```{r}
#dec-mar precip, max temp
winterPrecip <- stackApply(rasterstack[[c(12,1:3)]], 1, mean)
winterMaxtemp <- stackApply(rasterstack[[c(12,1:3)+12]], 1, mean)
winterMintemp <- stackApply(rasterstack[[c(12,1:3)+24]], 1, mean)
fallPrecip <- stackApply(rasterstack[[c(8:11)]], 1, mean)
fallMaxtemp <- stackApply(rasterstack[[c(8:11)+12]], 1, mean)
fallMintemp <- stackApply(rasterstack[[c(8:11)+24]], 1, mean)
summerPrecip <- stackApply(rasterstack[[c(4:7)]], 1, mean)
summerMaxtemp <- stackApply(rasterstack[[c(4:7)+12]], 1, mean)
summerMintemp <- stackApply(rasterstack[[c(4:7)+24]], 1, mean)

cor.plot(cor(pca_data2[[1]][c(48:56)]), numbers=TRUE)

#would lke to use scaled, colorado layers
us <- getData("GADM", country="USA", level=1)
# extract states (need to uppercase everything)
swstates <- c("Colorado", "Wyoming", "Utah", "New Mexico" ,"Arizona")

sw = us[match(toupper(swstates),toupper(us$NAME_1)),]
sw <- spTransform(sw, CRS(proj4string(winterPrecip)))

# now use the mask function
winPrecipclip <- mask(winterPrecip, sw)
winTmaxclip <- mask(winterMaxtemp, sw)

winterMintempclip <- mask(winterMintemp, sw)
fallPrecipclip <- mask(fallPrecip, sw)
fallTmaxclip <- mask(fallMaxtemp, sw)
fallMintempclip <- mask(fallMintemp,sw)
summerPrecipclip <- mask(summerPrecip,sw)
summerMaxtempclip <- mask(summerMaxtemp,sw) #error
summerMintempclip <- mask(summerMintemp, sw) #error



# winter temps and precip important to give moisture to plants in spring, melt, and to hit germination needs, fall temp is not coorelated and should impact most fruit produciton for most species, too hot and it'll all dry up too much. 
stackmini <- stack(winPrecipclip,winTmaxclip,winterMintempclip, 
                   #fallPrecipclip, 
                   fallTmaxclip) #, fallMintempclip)
                   #, summerPrecipclip)

save(stackmini, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/stackmini.Rda")
```

```{r}

jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/EnvironVariables.jpg",
     width=200, height=200, units='mm', res=300)

layout(matrix(c(1,2,3,4), 2,2, byrow=FALSE),
       width = c(5,5), height=c(5,5))

plot(winPrecipclip, xlim=c(-109,-103),ylim=c(35,42),
     xlab="lon", ylab="lat",
     main="Winter Precipitation")

plot(winTmaxclip, xlim=c(-109,-103),ylim=c(35,42),
     xlab="lon", ylab="lat",
     main="Maximum Winter Temperature")

plot(winterMintempclip, xlim=c(-109,-103),ylim=c(35,42),
     xlab="lon", ylab="lat",
     main="Minimum Winter Temperature")
     
plot(fallTmaxclip, xlim=c(-109,-103),ylim=c(35,42),
     xlab="lon", ylab="lat",
     main="Maximum Fall Temperature")

dev.off()

```

Reference stackmini to have same environmental variables in PCA as in the maxent models
```{r}

animatepca_data <- Map(data.frame, pca_data2, SpeciesID=as.list(seq(1,length(pca_data2),1)))

pca_all <- lapply(1:length(pca_data2), function(i){
  x <- animatepca_data[[i]]
  x.pca <- princomp(~WinterPrecip+SummerPrecip+WinterMinTemp+WinterMaxTemp+FallMaxTemp, 
                    data = x[,c("WinterPrecip","SummerPrecip","WinterMinTemp","WinterMaxTemp","FallMaxTemp")], 
                    na.action = na.omit, cor=TRUE)
  # x.load <- loadings(x.pca)
  x.pc1 <- predict(x.pca)
  x.pc <- data.frame(x.pc1,x[!is.na(x$WinterMaxTemp),]) #x$pa where 1=EOR presence, 3=EOR background; 2=Herb presence, 4=herb background
  x.PoV <- x.pca$sdev^2/sum(x.pca$sdev^2) #Percent of variance explained by the components
  out <- data.frame(x.pc,PoV1=x.PoV[1],PoV2=x.PoV[2])
  out
})

anim_all <- do.call(rbind, pca_all)
table(anim_all$PoV1)
```

```{r}
animatePCA <- list()
for(i in 1:46){
  animatePCA[[i]] <- ggplot(anim_all[anim_all$SpeciesID == i,], aes(Comp.1, Comp.2, 
                                 colour=as.factor(pa), 
                                 shape=as.factor(pa),
                                 frame=SpeciesID))+
    ggtitle(anim_all$GNAME[anim_all$SpeciesID == i][1])+
    geom_point()+
                    stat_ellipse()+
                    theme_bw()+
                    xlab(paste("PC1 (",round(anim_all$PoV1[anim_all$SpeciesID == i][1],2)*100,"%)",sep=""))+
                    ylab(paste("PC2 (",round(anim_all$PoV2[anim_all$SpeciesID == i][2],2)*100,"%)",sep=""))+
                    theme(plot.title=element_text(hjust=0))+
                    theme(legend.justification=c(0,1), legend.position=c(0,1),
                          legend.background = element_rect(fill=alpha('white', 0.1)))+
                    #labs(color = "Presence/Background", shape = "Presence/Background")+
    scale_shape_manual(name = "Presence/Background", 
                       labels=c("EOR presence",
                              "Herbarium presence",
                              "EOR background",
                              "Herbarium background"),
                       values=c(16,17,1,2)) +               
    scale_colour_manual(name = "Presence/Background",
                       labels=c("EOR presence",
                              "Herbarium presence",
                              "EOR background",
                              "Herbarium background"),
                       values=c("indianred4","hotpink3","lightslategray","lightsteelblue3")) #("darkolivegreen4","green4","lightgrey","ivory4"))
}

for(i in 1:46){
  print(animatePCA[[i]])
}
```


```{r}
# 
# cl <- makeCluster(6)
# registerDoParallel(cl)
# stopCluster(cl)
# 
# memory.limit()
# memory.limit(size=memory.limit()+1000)
# memory.limit(size=memory.limit()-1000) #take it back down a notch? oh, can't!?


#Loop through all the species
Maxent46species <- lapply(1:length(pca_data2), function(i){
  checkrecords <- sapply(split(pca_data2[[i]], pca_data2[[i]]$pa), function(x) nrow(x))
   
  # to keep at least 5 records per group
  if(sum(checkrecords<10)>0){
    NULL
  } else {

        kfoldnum <- 10
        speciestable <- pca_data2[[i]]
        speciestable$group_pa <- unlist(lapply(split(pca_data2[[i]], pca_data2[[i]]$pa), function(x){
          kfold(x$pa, kfoldnum)
          }))
    
      out <- list()
      for(l in 1:10){     #Are 10 repeats for 10 fold enough?
          #randomly select on of the test roups to sample as the training data, 10 fold
          test <- sample(1:10, 1)
          
          train_pEOR <- speciestable[speciestable$pa == 1 & speciestable$group_pa!=test,c("x1","x2")]
          train_pHerb <- speciestable[speciestable$pa == 2 & speciestable$group_pa!=test,c("x1","x2")]
          train_bEOR <- speciestable[speciestable$pa == 3 & speciestable$group_pa!=test,c("x1","x2")]
          train_bHerb <- speciestable[speciestable$pa == 4 & speciestable$group_pa!=test,c("x1","x2")]
          
          test_pEOR <- speciestable[speciestable$pa == 1 & speciestable$group_pa==test,c("x1","x2")]
          test_pHerb <- speciestable[speciestable$pa == 2 & speciestable$group_pa==test,c("x1","x2")]
          test_bEOR <- speciestable[speciestable$pa == 3 & speciestable$group_pa==test,c("x1","x2")]
          test_bHerb <- speciestable[speciestable$pa == 4 & speciestable$group_pa==test,c("x1","x2")]
          
          me <- maxent(stackmini, p=train_pEOR, a=train_bEOR)
          meHerb <- maxent(stackmini, p=train_pHerb, a=train_bHerb)
          
          #evalidate teh model
          e <- dismo::evaluate(test_pEOR, test_bEOR, me, stackmini)
          eHerb <- dismo::evaluate(test_pHerb, test_bHerb, meHerb, stackmini)
          gc()
          
          #Visulatize predictions
          writeRaster(dismo::predict(me, stackmini),paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt/EOR",g1g2names$AcceptedName[i],l,".tif", sep=""),overwrite=TRUE)
          gc()
          writeRaster(dismo::predict(meHerb, stackmini),paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt/Herb",g1g2names$AcceptedName[i],l,".tif", sep=""),overwrite=TRUE)
          gc()
          thres <- dismo::threshold(e) 
          thresHerb <- dismo::threshold(eHerb)
          # 1: which group to withhold, 2: maxent for EOR, 3: maxent for Herbarium, 4: evaluate EOR, 5: evaluate Herbarium, 6: thresholds for EOR, 7: thresholds for Herbarium, 8: species
          out[[l]] <- list(test,me,meHerb,e,eHerb,thres,thresHerb,g1g2names$AcceptedName[i])#,pme,pmeHerb)
          gc()
      }
      out
  }
})

save(Maxent46species, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Maxent46species.Rda")
```

1: which group to withhold, 2: maxent for EOR, 3: maxent for Herbarium, 4: evaluate EOR, 5: evaluate Herbarium, 6: thresholds for EOR, 7: thresholds for Herbarium, 8: species
```{r}
#Specificy=Sensitivity or Kappa??
#Make names match raster files
thres_all <- do.call(rbind,lapply(Maxent46species[lapply(Maxent46species, length)>0], function(x){
  species <- sapply(x, '[[', 8)
  EOR_th <- sapply(x, '[[', 6)
  Herb_th <- sapply(x, '[[', 7)
  EOR_ss <- unlist(EOR_th[5,]) #1:kappa, 2:spec_sens, 3:no_omission, 4:prevalence, 5:equal_sens_spec, 6:sensitivity
  HERB_ss <- unlist(Herb_th[5,])
  eorout <- data.frame(threshold=EOR_ss,Species=paste("EOR",gsub(" ","_",species),1:10,sep=""))
  herbout <- data.frame(threshold=HERB_ss,Species=paste("Herb",gsub(" ","_",species),1:10,sep=""))
  rbind(eorout,herbout)
}))

#20 species
maxentspecies <- Maxent46species[lapply(Maxent46species, length)>0]
spRasterEORvsHerb <- lapply(unlist(sapply(maxentspecies, '[[', 8)[8,]),
                            function(sp){
                              lapply(1:10, function(rep){
                                lapply(c("EOR","Herb"), function(comp){
        raster(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt/",
                     comp,sp,rep,".tif", sep=""))
                                })
                              })
                            })

  spRasterEORvsHerb[[1]][[1]][[1]]@file@name
  #Need name to match up threshold with EOR or Herb and species and which map
  spRasterEORvsHerb[[1]][[1]][[2]]@data@names   #!!! Yes!
  
  thres_all[[1]]$Species


auc_all <- sapply(Maxent46species, function(x){
  species <- sapply(x, '[[', 8)
  EOR_eval <- sapply(x, '[[', 4)
  Herb_eval <- sapply(x, '[[', 5)
  EOR_auc <- sapply(EOR_eval, function(y) y@auc)
  HERB_auc <- sapply(Herb_eval, function(y) y@auc)
  data.frame(AUC_EOR=EOR_auc, AUC_Herb=HERB_auc, Species=species)
})

#make raster bricks of EOR and Herbs for each species; just species that got done 
speciesused <- unique(gsub('[[:digit:]]+', '', thres_all$Species))
unlistspRaster <- unlist(spRasterEORvsHerb)
rasterbricks <- lapply(speciesused, function(sp){
  sp1 <- unlistspRaster[grep(sp,
                               sapply(unlistspRaster, function(x) x@data@names))]
  stack(sp1)
})

#Need to pick a way to make a consensus model and do same for both. 
#Should also compare niche models of both to actual distribution defined by CNHP
sapply(1:length(rasterbricks), function(j){
  #r <- raster() #to hold information
  filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt/MeanRasterstack",rasterbricks[[j]]@layers[[1]]@data@names,".tif", sep="")
  x<-rasterbricks[[j]]
  out <- raster(x)
  bs <- blockSize(x)
  out <- writeStart(out, filename, overwrite=TRUE)

  # Loop over each block and do your calculation
  for (i in 1:bs$n) {
      v <- getValues(x, row=bs$row[i], nrows=bs$nrows[i] )
     # mean
        v <- rowMeans(v, na.rm=TRUE)
        out <- writeValues(out, v, bs$row[i])
     }
  out <- writeStop(out)
  return(out)
  gc()
})


averageRaster <- lapply(rasterbricks, function(x){
  gc()
  writeRaster(calc(x, mean), paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt/MeanRaster",x@layers[[1]]@data@names,".tif", sep=""),overwrite=TRUE)
  gc()
})

rasterbricks[[1]]@layers[[1]]@data@names

#Go for threshold of each and then overlap 
thresholdrasters <- lapply(unlist(spRasterEORvsHerb), function(x){
  gc()
  writeRaster((x > thres_all$threshold[thres_all$Species==x@data@names]),
              paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt/Threshold",x@data@names,".tif", sep=""),overwrite=TRUE)
  })


#need to add number and EOR or Herb to threshold extract from raster name
plot(spRasterEORvsHerb[[1]][[1]][[1]] > 
       thres_all$threshold[thres_all$Species == spRasterEORvsHerb[[1]][[1]][[1]]@data@names], 
     1, cex=0.5, legend=T, mar=par("mar"), xaxt="n", yaxt="n", 
     main=paste("Predicted presence of",spRasterEORvsHerb[[1]][[1]][[1]]@data@names,sep=" "))
plot(sw, add=TRUE)

```



Testing the loop for all 46 species
```{r}
group_pa <- do.call(c,sapply(1:4, function(x) kfold(pca_data2[[1]][pca_data2[[1]]$pa==x,],10))) #nope, need seperate for presence and background

#randomly select on of the test roups to sample as the training data
test <- sample(1, 1:10)

train_pEOR <- pca_data2[[1]][pca_data2[[1]]$pa == 1 & group_pa!=test,c("x1","x2")]
train_pHerb <- pca_data2[[1]][pca_data2[[1]]$pa == 2 & group_pa!=test,c("x1","x2")]
train_bEOR <- pca_data2[[1]][pca_data2[[1]]$pa == 3 & group_pa!=test,c("x1","x2")]
train_bHerb <- pca_data2[[1]][pca_data2[[1]]$pa == 4 & group_pa!=test,c("x1","x2")]

test_pEOR <- pca_data2[[1]][pca_data2[[1]]$pa == 1 & group_pa==test,c("x1","x2")]
test_pHerb <- pca_data2[[1]][pca_data2[[1]]$pa == 2 & group_pa==test,c("x1","x2")]
test_bEOR <- pca_data2[[1]][pca_data2[[1]]$pa == 3 & group_pa==test,c("x1","x2")]
test_bHerb <- pca_data2[[1]][pca_data2[[1]]$pa == 4 & group_pa==test,c("x1","x2")]

me <- maxent(stackmini, p=train_pEOR, a=train_bEOR) #put maxent.jar into the java folder of dismo and changed  regedit.exe, navigate to HKEY_LOCAL_MACHINE\SOFTWARE\JavaSoft, right click and change permissions to full operation.


#validate teh model
e <- dismo::evaluate(test_pEOR, test_bEOR, me, stackmini)

#Visulatize predictions
pred_me <- dismo::predict(me, stackmini)
thres <- dismo::threshold(e)

plot(pred_me > thres$spec_sens, 1, cex=0.5, legend=T, mar=par("mar"), xaxt="n", yaxt="n", 
     main=paste("Predicted presence of",g1g2names[[1]][1],sep=" "))
plot(sw, add=TRUE)
```

Steven J. Phillips, Miroslav Dudík, Robert E. Schapire. [Internet] Maxent software for modeling species niches and distributions (Version 3.4.1). Available from url: http://biodiversityinformatics.amnh.org/open_source/maxent/. Accessed on 2018-10-7.

https://stackoverflow.com/questions/32915628/best-way-to-create-response-curves-for-a-glm-species-distribution-model-in-r 
```{r}
corout <- as.data.frame(as.table(cor(pca_data[[1]][,11:length(pca_data[[1]])])))
corout[corout$Freq<0.60,]


m1 <- glm()
```



#Random forest - classification and regression trees   
Either a formula, or (1) data.frame with predictor variables, (2) vector with response. categorical will classification, interval will do regression. 
```{r}

library(randomForest)

bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)


plot(bioclim.colorado$bio1_12)
plot(colocounties, add=TRUE)

#When loop, use "i in want" or lapply(want, function(i)) which are non-NA in the list for distXsp[[i]][[1]]@coords

#need back to lat long
pointsXsp.latlon <- list()
for(i in 1:length(want)){
  pointsXsp.latlon[[i]] <- spTransform(distXsp[[want[1]]][[1]], CRS("+proj=longlat +datum=WGS84"))
}

##COME BACK TO THIS AND SEE WHAT NEEDS TO BE Done to do random forest
presvals <- extract(bioclim.colorado, )


library(dismo)

kfoldnum <- 5

#Make a training and testing set, will want to iterative over all sets, keeping one out each time
#lapply(1:kfoldnum, function(x){})

group <- kfold(distXsp[[1]][[1]]@coords, kfoldnum)
pres_train <- distXsp[[1]][[1]]@coords[group != 1,]
pres_test <- distXsp[[1]][[1]]@coords[group == 1,]

ext <- extent(-109, -102, 36, 41)
backg <- randomPoints(bioclim.colorado, n=300, ext=ext, extf=1.25)
colnames(backg) <- dimnames(pres_test)[[2]]
groupbk <- kfold(backg, kfoldnum)
backg_train <- backg[groupbk != 1,]
backg_test <- backg[groupbk == 1,]






```

While Chapter1_SDM is running making the strips of probability maps     
Put together all the strips to make one probability map for each Herbarium species  
```{r}
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_v3.Rda")
notnull <- which(!unlist(lapply(mapply('[[', distXsp_v3, 1), is.null)))
atleast12 <- c()
for(l in notnull){
  atleast12[match(l,notnull)] <- if(nrow(distXsp_v3[[l]][[1]]@coords)>11){ 
    l } else {
      NA
    }
}
atleast12 <- atleast12[!is.na(atleast12)] 

pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/"

# Just did Sp1, as of 3:22pm on Feb 20th Sp55 is in the middle of running (for Herbarium specimens); 3:24 after Sp55 done by 4:11pm; sp11kfold4 didn't finish, no _8 .grd so need to fix and then do atleast12[5] for kfold 4; atleast12[6:28]
lapply(atleast12[5], function(i){
  resultpath <- list.files(path = pathstart, pattern = paste("Predict",i,"kfold", sep=""), full.names = TRUE)
  lapply(1:4, function(k){
    x <- lapply(resultpath[grep(paste("kfold",k,sep=""),resultpath)], function(x){
      raster(x)
    })
    x$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/ProbTiffSp",i,"Herbkfold",k,".tif", sep="")
    x$overwrite <- TRUE
    m <- do.call(merge, x)
  })
})




```
Average the 4 kfolds for each    
```{r}
library(snow)
ncores <- 2 # define the number of cores you want to use, 2 on laptop, 12 on desktop
# ,4:28
lapply(atleast12[1], function(x){
  resultpath <- list.files(path = pathstart, pattern = paste("ProbTiffSp",x,"Herbkfold", sep=""), full.names = TRUE)
  allrasts <- stack(resultpath)
  beginCluster(ncores)
  ras.mean <- clusterR(allrasts, calc, args=list(mean, na.rm=T))
  ras.SD <- clusterR(allrasts, calc, args=list(sd, na.rm=T))
  writeRaster(ras.mean, file=paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/ProbMEANSp",x,sep=""), format="GTiff")
  writeRaster(ras.SD, file=paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/ProbSDSp",x,sep=""), format="GTiff")
  endCluster()
})

```




# Loaded at the beginning
```{r}

distXsp_noEORgrid <- lapply(1:60, function(i){
  gc()
  g1g2now <- coloradosps.g1g2[coloradosps.g1g2$scientificName %in%
                                c(g1g2names$Taxon[i],g1g2names$AcceptedName[i])&
                                !is.na(coloradosps.g1g2$decimalLatitude),]
  
  g1g2now <- g1g2now[as.numeric(as.character(g1g2now$year))>1800,]
  # remove points not in Colorado
  g1g2now <- g1g2now[g1g2now$decimalLatitude>35,]
  g1g2now <- g1g2now[g1g2now$decimalLongitude>(-113),]
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)]
  gc()
  
  if(nrow(g1g2now)>0){
  # put grid points across colorado, sample from it for each polygons
    polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                        g1g2names$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
        
    years <- as.numeric(substring(polys$LASTOBS,1,4))
    yearsnotNA <- c()
    for(l in 1:length(years)){
      yearsnotNA[l] <- if(years[l]<9999){ 
                                      l } else {
                                        NA
                                      }
    }
    yearsnotNA <- yearsnotNA[!is.na(yearsnotNA)] 
    polys <- polys[yearsnotNA,]
    
    totalarea <- sum(area(disaggregate(polys)))
  # area of each polygon
    areanow <- sapply(slot(polys,"polygons"), slot, "area")
    
  #turn into spatialpointsdataframe for individual species
    coordinates(g1g2now) <- ~decimalLongitude+decimalLatitude
    proj4string(g1g2now) <- CRS("+init=epsg:4326")  # CRS("+proj=longlat +datum=WGS84")
    g1g2now <- spTransform(g1g2now, CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84"))
  # The minimum distance from each point to the nearest polygon
    distnow <- apply(gDistance(g1g2now,polys, byid=TRUE),2,min)
    gc()
   
  out <- data.frame(Species = g1g2names$AcceptedName[i], g1g2now,Dist = distnow, Area = totalarea, 
                    EORdate = polys$LASTOBS[apply(gDistance(g1g2now,polys, byid=TRUE),2,which.min)],
                    Yeardiff = g1g2now$year- as.numeric(substring(as.character(polys$LASTOBS[apply(gDistance(g1g2now,polys, byid=TRUE),2,which.min)]),1,4)))
    gc()
    out
    }
  })
save(distXsp_noEORgrid, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid.Rda") 
```
