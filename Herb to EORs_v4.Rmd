---
title: "Herbarium Bias CNHP"
author: "Michelle DePrenger-Levin"
date: "December 4, 2017"
output: html_document
---
Use Jessie's cool mapping code: "Q:\Research\All_Herbaria\KHD\Projects\exploring_herbarium_with_maps" 

Rick says don't need quotes for table or column names

MySQL query

#There are only rows in the synonym_links table when the names are synonyms, if it's not in synonym_links, it's the accepted name; taxonomic_units is the main table, if it's a synonym it's linked by synonym_links
SELECT `synonym_links`.*, `taxonomic_units`.* , `taxon_authors_lkp`.*, `geographic_div`.*
FROM `taxonomic_units` 
LEFT JOIN `synonym_links` ON `synonym_links`.`tsn` = `taxonomic_units`.`tsn` 
LEFT JOIN `taxon_authors_lkp` ON `taxon_authors_lkp`.`taxon_author_id` = `taxonomic_units`.`taxon_author_id` 
LEFT JOIN `geographic_div` ON `geographic_div`.`tsn` = `taxonomic_units`.`tsn`
WHERE `taxonomic_units`.`kingdom_id` = 3 AND `taxonomic_units`.`rank_id` = 220 AND `geographic_div`.`geographic_value` IN ('North America')



#The authorities are giving me trouble right now; can do NOT IN (0,3,9999) or whatever
SELECT `synonym_links`.*, `taxonomic_units`.* , `taxon_authors_lkp`.*
FROM `taxonomic_units` 
JOIN `synonym_links` ON `synonym_links`.`tsn` = `taxonomic_units`.`tsn` 
JOIN `taxon_authors_lkp` ON `taxon_authors_lkp`.`taxon_author_id` = `taxonomic_units`.`taxon_author_id` 
WHERE `taxonomic_units`.`kingdom_id` = 3 AND `taxonomic_units`.`rank_id` = 220 AND `taxonomic_units`.`unaccept_reason` IS NULL AND `taxonomic_units`.`taxon_author_id` NOT IN (0) AND `taxonomic_units`.`name_usage` NOT IN ('invalid') AND `taxonomic_units`.`n_usage` IN ('accepted')



#the taxon_authors_lkp.taxon_author_id isn't the tsn, it's the taxonomic_units.taxon_author_id!!!
SELECT `synonym_links`.*, `taxon_authors_lkp`.*, `taxonomic_units`.* 
FROM `taxonomic_units` 
LEFT JOIN `synonym_links` ON `synonym_links`.`tsn` = `taxonomic_units`.`tsn`
LEFT JOIN `taxon_authors_lkp` ON `taxon_authors_lkp`.`taxon_author_id` = `taxonomic_units`.`taxon_author_id` 
WHERE `taxonomic_units`.`kingdom_id` = 3 AND `taxonomic_units`.`rank_id` = 220 



SELECT `synonym_links`.*, `taxon_authors_lkp`.*, `taxonomic_units`.* 
FROM `taxonomic_units` 
LEFT JOIN `synonym_links` ON `synonym_links`.`tsn` = `taxonomic_units`.`tsn`
LEFT JOIN `taxon_authors_lkp` ON `taxon_authors_lkp`.`taxon_author_id` = `taxonomic_units`.`tsn` 
WHERE `taxonomic_units`.`kingdom_id` = 3 AND `taxonomic_units`.`rank_id` = 220 



cd /p/hackathon/Simulations/

```{r}
rm(list=ls())

# install.packages("NicheMapR") based on animal needs anyway, mechanistic
library(ggplot2)
library(rgeos)
library(sp)
library(spdep)
library(rgdal)
library(maptools)
library(raster)
library(Taxonstand)
library(RCurl)
library(taxize)
library(ggmap)

library(gganimate)

library(dismo)
library(ENMeval)
library(biomod2)
library(spThin)

#Skip making these, takes a long time
load("P:/hackathon/Simulations/circleEOR.Rda")
load("P:/hackathon/Simulations/circleHerb.Rda")
load("P:/hackathon/Simulations/EORgrid.thin.Rda")
load("P:/hackathon/Simulations/circleEOR.Rda")
load("P:/hackathon/Simulations/envs.backgEOR.Rda")
load("P:/hackathon/Simulations/envs.backgHerb.Rda")
load("P:/hackathon/Simulations/Herb.thin1000.Rda")
load("P:/hackathon/Simulations/EORgrid.thin.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorsinglecell.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorandherb.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp.Rda")

```
#Resample elevation (and others) to the bioclim sized grid, 30km grid is way to small, computer can't handle 
```{r}

coElev <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Elevation_VT/CO_Mosaic_Elevation_VT/co_elev_VT_WGS84.tif")

coElev_biosize <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Elevation_VT/co_elev_WGS84_30sec.tif")


plot(coElev)
```



```{r}
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")

colocounties <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties_wgs84")
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")

#In lat/lon WGS 84
#plot(colocounties)

#in UTM NAD83
#plot(colocounties.UTM)
#plot(l1eor, add=TRUE)

#Each polygon might be made of multiple disconnected polygons. Need to separate and label
l1G1G2 <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2"),])
l1G1G2$PolyID <- do.call(rbind, lapply(split(l1G1G2,l1G1G2$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))

#How many names in 
#length(unique(l1G1G2$GNAME)) #60
#write.table(unique(l1G1G2$GNAME), "clipboard", sep="\t", row.names=FALSE)


# Could take all the synonyms and names of l1G1G2 to make the list of names to pull from SEINet big list
namesg1g2 <- table(l1G1G2$GNAME)
#length(namesg1g2[namesg1g2 > 0]) #60 species
g1g2names <- TPL(names(namesg1g2[namesg1g2 > 0]))
#table(g1g2names$Taxonomic.status) 
#2 not in there, "Gutierrezia elegans" "Oonopsis sp. 1", 10 synonyms, 3 unresolved

#g1g2names[g1g2names$Taxonomic.status == "Unresolved",]
#Gilia sedifolia
#Ipomopsis ramosa
#Packera mancosana
```


Mo Ewing:    
     1) split all polygons (from CNHP) with ArcGIS 'explosion' tool    
     2) Copy the Feature_id field into the Parcel-num field and annotate each parcel: "a", "b" etc    
     3) Import G1G2 Seinet Vouchers into ArcMap      
     4) Create linking field: "Parcel_num"          
     5) Go through each parcel, linking the Eos by duplicating the Parcel_num.    
     6) determin the closest 'parcel' to each herabarium point using ArcMap 'near' tool Analyst Tools/Proximity/Near   *I assume to the nearest line of the polygon, nearest spot of the polygon, not to the center of the polygon          
     7) Add Map Method informaiton     
            i. "GPS" = indication that GPS was used, just GPS coordinates present    
            ii. "tr" = township/range info only recorded to township and range     
            iii. "trs" = township/Range info recorded to section, or indication that tr conversion tool used       
            iv. "trqs" = Township/Range info recorded to quarter-section       
            v. "Locality" = no verbatim data recorded, only written description recorded    
                     or "Terrain nav" (terrain navigator used)    
                     or "Nat. Geog. TOPO"    
                     or "Mapstedi"     
                     or "digital mape"     
                     or "geoLocate"     
                     or "GoogleEarth"      


# Check when names are good or not from herbarium specimens
```{r}
seinet <- read.csv("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/SEINET G1 G2 Vouchers/seinet_colorado_with_coordinates_ALLG1G2.csv")

seinet <- seinet[seinet$genus != "",]

#table(seinet$basisOfRec) #PreservedSpecimen: 1871 and HumanObservation: 4
seinet <- seinet[seinet$basisOfRecord != "HumanObservation",]
namesSEINet <- names(table(seinet$scientificName)) #93 names
SEINet_names <- TPL(namesSEINet)
#table(SEINet_names$Taxonomic.status) #
#             Accepted    Synonym Unresolved 
#         2         75          9          7 
SEINet_names$scientificNameAccpt <-paste(SEINet_names$New.Genus, SEINet_names$New.Species)
#write.table(SEINet_names[SEINet_names$Taxonomic.status != "Accepted",c(1,14,16,12)], "clipboard", sep="\t", row.names=FALSE)
#SEINet_names[SEINet_names$Taxonomic.status != "Accepted",c(1,14,16,12)]

seinet_TPL <- merge(seinet, SEINet_names, by.x = "scientificName", by.y = "Taxon")
#head(seinet_TPL) # all the information from herbarium collections and if they're accepted names or not

seinet_TPL$family <- toupper(seinet_TPL$family)

#seinet_TPL[seinet_TPL$institutionCode=="USU",]
#seinet_TPL$institutionCode[seinet_TPL$institutionCode=="USU"] <- "USUUB"

namesbyyear <- table(seinet_TPL$Taxonomic.status,seinet_TPL$year)
plot(as.numeric(dimnames(namesbyyear)[[2]]),namesbyyear[2,],col="blue", type="l",
     xlab="Year",ylab="Specimens", ylim=c(0,max(namesbyyear))) #accepted
lines(as.numeric(dimnames(namesbyyear)[[2]]),namesbyyear[3,],col="green") #synonym
lines(as.numeric(dimnames(namesbyyear)[[2]]),namesbyyear[4,],col="orange") #Unresolved
lines(as.numeric(dimnames(namesbyyear)[[2]]),namesbyyear[1,],col="pink") #not in TPL
```
#Families collected over time
```{r}
familyxyear <- data.frame(table(seinet_TPL$year,seinet_TPL$family)) #now changed toupper lowercase $family has 44 levels, inconsistent capitals and lowercase..
familyxyear$Var1 <- as.numeric(as.character(familyxyear$Var1))

familyxyear[familyxyear$Freq>0,]


library(lattice)
xyplot(Freq ~ Var1|Var2, familyxyear[familyxyear$Freq>0,],
       type = c("g","p","r"),
       index = function(x,y) coef(lm(y ~ x))[1],
       xlab = "Year of Collection",
       ylab = "Number of Collections", aspect = "xy")


herbariumxyear <- data.frame(table(seinet_TPL$year,seinet_TPL$institutionCode)) 
ggplot(herbariumxyear[herbariumxyear$Freq>0,],aes(Var1, Freq, colour=Var2 ))+
  geom_point()+
  theme_bw()


unique(seinet_TPL$geodeticDatum)
seinet_TPL[seinet_TPL$geodeticDatum == "27",]
```

Cite MODIS data: <https://lpdaac.usgs.gov/citing_our_data>   
<https://lpdaac.usgs.gov/data_access/data_pool>  - need to get data but weeky mainenance is every wednesday until noon   
Got snow data https://search.earthdata.nasa.gov/data/retrieve/5396545932 can compare to NCAR's data.   
got some veg data or getting https://search.earthdata.nasa.gov/data/retrieve/2536564325  
```{r}
library(ncdf4)
#library(maptools)
#library(extRemes)
library(fields)
library(parallel)
library(doParallel)
library(foreach)
library(abind)
library(prism)

library(raster)
library(rasterVis)
#library(measurements)
library(ENMeval)
library(RCurl)
library(dismo)

#install.packages("digest")
library(devtools)
#install_github('hadley/rvest')
library(rvest)

# add the command to bind along the 3rd dimension
abind3 <- function(...) { abind(along = 3, ...) }

```



#Michelle DePrenger-Levin      
In ArcMap do this: <https://blogs.esri.com/esri/arcgis/2010/09/16/nearbygroup/>
repeat distance analysis in R          
"coloradosps" == SEINet collections from Colorado - downloaded 12/6/2017 from SEINet        
Only G1G2 EORs (to limit range of species)
"colonames" == TPL synonomy for all coloradosps names
```{r}
#coloradosps <- read.csv("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/SEINET G1 G2 Vouchers/occurrences.csv")

#save(coloradosps, file= "P:/hackathon/Simulations/coloradosps.Rda")
load("P:/hackathon/Simulations/coloradosps.Rda")


nrow(coloradosps) #567328

howlongrecordedby <- nchar(as.character(coloradosps$recordedBy))
head(howlongrecordedby<20)
recordedby <- unique(coloradosps$recordedBy[howlongrecordedby < 100])


table(coloradosps$basisOfRecord) # PreservedSpecimen: 566067; preservedspecimen: 55; Preserved specimen: 143; Photograph: 1; Observation: 124; Native and Naturalized Flora of; HumanObservation; many just wrong column info in this


# both of these from OBI: California Polytechnic State University
coloradosps[coloradosps$basisOfRecord == "Plants of Jefferson County Open",] #68 plus 1 more with some other typo
coloradosps[coloradosps$basisOfRecord == "Plants of Colorado",] #68 plus 1 more with some other typo

#Subset by just preserved specimens  
coloradosps$basisOfRecord <- as.character(coloradosps$basisOfRecord)
coloradosps.specimens <- coloradosps[grep("specimen",coloradosps$basisOfRecord,
                                          ignore.case=TRUE),]
table(coloradosps.specimens$basisOfRecord)

coloradosps.specimens <- coloradosps.specimens[nchar(coloradosps.specimens$basisOfRecord)<50,]
table(coloradosps.specimens$basisOfRecord)

#Now only preserved specimens
coloradosps <- coloradosps.specimens
nrow(coloradosps) #566265

g1g2names$AcceptedName <- paste(g1g2names$New.Genus,g1g2names$New.Species)
#match SEINet names to either the given or accepted names from G1/G2s
length(unique(g1g2names$Taxon))
length(unique(g1g2names$AcceptedName)) #60
length(unique(c(g1g2names$Taxon,g1g2names$AcceptedName))) #71 


rowstomatch <- lapply(c("Taxon","AcceptedName"), function(x){
   coloradosps[,"scientificName"] %in%  g1g2names[,x]
})

#The rows to keep that match either an accepted or synonym or unresolved name for a G1G2 species
#coloradosps.specimens was intermediate to get rid of none specimen records
coloradosps.g1g2 <- unique(rbind(coloradosps[rowstomatch[[1]],],coloradosps[rowstomatch[[2]],]))
nrow(coloradosps.g1g2)
hist(as.numeric(as.character(coloradosps.g1g2$decimalLatitude)))
#write.table(sort(unique(coloradosps.g1g2$scientificName)), "clipboard", sep="\t", row.names=FALSE)
plot(as.numeric(as.character(coloradosps.g1g2$decimalLongitude)),
     as.numeric(as.character(coloradosps.g1g2$decimalLatitude)))
```
How many are within 0.01 decimals of each other, round to two decimals - per Soltis 
```{r}
coloradosps.g1g2$decimalLatitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLatitude))
coloradosps.g1g2$decimalLongitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLongitude))

coloradosps.g1g2[which(coloradosps.g1g2$decimalLatitude <37),]
coloradosps.g1g2[which(coloradosps.g1g2$decimalLongitude < -109.2),]

coloradosps.g1g2$lon2 <- round(coloradosps.g1g2$decimalLongitude,2) # about 1.1 km 
coloradosps.g1g2$lat2 <- round(coloradosps.g1g2$decimalLatitude,2)

coloradosps.g1g2$lon3 <- round(coloradosps.g1g2$decimalLongitude,3) # about 110 m
coloradosps.g1g2$lat3 <- round(coloradosps.g1g2$decimalLatitude,3)



duplicated(coloradosps.g1g2[,c("lat2","lon2")])

duplicated(coloradosps.g1g2[,c("lat3","lon3")])

plot(colocounties)
points(coloradosps.g1g2$lon2,coloradosps.g1g2$lat2,pch=20,cex=0.5)
points(coloradosps.g1g2$decimalLongitude,coloradosps.g1g2$decimalLatitude,col="red",
       pch=20,cex=0.5)
points(coloradosps.g1g2$lon3,coloradosps.g1g2$lat3,pch=21,cex=0.5, col="blue")


nrow(coloradosps.g1g2) #-
nrow(coloradosps.g1g2[!duplicated(coloradosps.g1g2[,c("lat2","lon2")]),]) #685

nrow(coloradosps.g1g2[!duplicated(coloradosps.g1g2[,c("lat3","lon3")]),]) #791

nrow(coloradosps.g1g2[duplicated(coloradosps.g1g2[,c("lat3","lon3")]),]) #1660
nrow(coloradosps.g1g2[duplicated(coloradosps.g1g2[,c("lat2","lon2")]),]) #1766


#which ones are in denver?
write.table(coloradosps.g1g2[which(coloradosps.g1g2$decimalLatitude >39.5&
                         coloradosps.g1g2$decimalLatitude <40.1&
                         coloradosps.g1g2$decimalLongitude>-105.5),], 
            "clipboard", sep="\t", row.names=FALSE)

write.table(coloradosps.g1g2[grep("Den",coloradosps.g1g2$county),], 
            "clipboard", sep="\t", row.names=FALSE)
```


```{r}
setdiff(sort(unique(coloradosps.g1g2$scientificName)),sort(unique(l1G1G2$GNAME))) #species from the SEINet specimens that isn't in the names given for G1G2
setdiff(sort(unique(l1G1G2$GNAME)),sort(unique(coloradosps.g1g2$scientificName))) #the first list that's not in the second


#convert points from WGS84 to NAD83
projected <- coloradosps.g1g2[complete.cases(coloradosps.g1g2[,c("lat2","lon2")]),]
coordinates(projected) <- ~ lon2+lat2
proj4string(projected) <- CRS("+proj=longlat +datum=WGS84") 
projected <- spTransform(projected, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))

head(g1g2names)
unique(l1G1G2$PolyID$GNAME)
```

There seems to be lots of points in Denver but no EOs!
```{r}
jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/HerbPntsEORs_CO.jpg",
     width=250, height=225,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2, border="gray80", add=TRUE, lwd=5) #
plot(projected, add=TRUE, pch=20, cex=0.5)

dev.off()

```

```{r}
jpeg("Q:/Research/Presentations/External Conference presentations/Natural Areas Conference 2018/EORs.jpg",
     width=170, height=150,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2, border="goldenrod", add=TRUE, lwd=5) #☻
#plot(projected, add=TRUE, pch=20, cex=0.5)

dev.off()

```

```{r}
jpeg("Q:/Research/Presentations/External Conference presentations/Natural Areas Conference 2018/herbs.jpg",
     width=170, height=150,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
#plot(l1G1G2, border="blue", add=TRUE, lwd=5) #☻
plot(projected, col = "blue", add=TRUE, pch=20, cex=0.5)

dev.off()

```

```{r}
jpeg("Q:/Research/Presentations/External Conference presentations/Natural Areas Conference 2018/both.jpg",
     width=170, height=150,units='mm', res=300)

plot(colocounties.UTM,border="gray30") #colocounties is in WGS84, not in same datum as l1G1G2
plot(l1G1G2, border="goldenrod", add=TRUE, lwd=5) 
plot(projected, col="blue", add=TRUE, pch=20, cex=0.5)

dev.off()

```
       [1] WGS84                     WGS 84                    WGS 1984                      
       [4] WGS96                     WGS 72                    WGS-84                     
       [7] WGS 1984.                 WGS83                     WGS84 (UTM Datum: NAD83)   
      [10] WGS84  (UTM Datum: NAD83) WGS84, Google Earth       WGS 1983                   
      [13] WGS 1984,                 WGS98                     WGS85                       
      [16] WGS86                     WGS89                     WGS95                       
      [19] WGS87                     WGS88                     WGS97                       
      [22] WGS92                     WGS 83                    WGS93                       
      [25] WGS94                     WGS84/NAD83               WGS90                        
      [28] WGS 19                    WGS99                     WGS91      
      
      "The latest revision is WGS 84 (also known as WGS 1984, EPSG:4326), established in 1984 and last revised in 2004.[1] Earlier schemes included WGS 72, WGS 66, and WGS 60. WGS 84 is the reference coordinate system used by the Global Positioning System."

Scale bar attempts
```{r}
myScalebar = function(units_label, yadj=1.5) {

  # Get plot coordinates
  pc = par("usr") 

  # Position scale line between last two major x-axis tick marks
  # and 1/10th of the total y-range above the lower y-axis coordinate
  lines(c(floor(pc[2]-100),floor(pc[2])),     
        rep(pc[3] + 0.1*(pc[4] - pc[3]), 2))

  # Place the units label at the midpoint of and just below the scale line
  text(x=mean(c(floor(pc[2]-100), floor(pc[2]))), 
       y=pc[3] + 0.1*(pc[4] - pc[3]),
       label=units_label, adj=c(0.5, yadj))
}
```

```{r}
ScaleBar <- function(reference_raster_utm, round_to_nearest_km, width_percent, y_percent_from_bottom, x_percent_from_left, y_text_percent_from_bottom, ...) {
    # Round by max to nearest... e.g. 5 km 
    mround <- function(x,base){ 
        base*round(x/base) 
    }   
    # scale bar size adjustment to avoid decimals
        scale_size <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*width_percent)/1000
        scale_size_adj <- mround(scale_size, round_to_nearest_km)
        scale_size_adj_plot <- (scale_size_adj*1000)/2
    # Horizontal percent position (x) for scale bar
        x_position <- ((xmax(reference_raster_utm)-xmin(reference_raster_utm))*x_percent_from_left)+xmin(reference_raster_utm)
    # Vertical percent position y for scale bar
        y_position <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_percent_from_bottom)+ymin(reference_raster_utm)
        y_position_text <- ((ymax(reference_raster_utm)-ymin(reference_raster_utm))*y_text_percent_from_bottom)+ymin(reference_raster_utm)
    # Draw line on plot
        library(sp)
        x_ends <- c((x_position-scale_size_adj_plot), (x_position+scale_size_adj_plot))
        y_ends <- c((y_position), (y_position))
        scale_bar_line <- SpatialLines(list(Lines(Line(cbind(x_ends, y_ends)), ID="length")))
        projection(scale_bar_line) <- projection(reference_raster_utm)
        plot(scale_bar_line, add=TRUE, ...)
        text(x_position, y_position_text, paste0(scale_size_adj, "km"))
}

```


```{r}
us <- getData('GADM', country = 'US', level = 1)
colorado <- us[us$NAME_1 == "Colorado",]
projLL <- proj4string(colorado)

colorado<- spTransform(colorado, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
i<-1
 polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                         g1g2names$Taxon[i]),] 
 
grid <- makegrid(polys, cellsize = 100) # cellsize in map units!
grid <- SpatialPoints(grid, proj4string = CRS(proj4string(polys)))

length(grid[polys,]) #106 points
```

#map each species, map each EOR, check distance from points to nearest EORs
```{r}
#l1G1G2 are in UTM zone 13
l1G1G2@proj4string <- CRS("+proj=utm +zone=13 ellps=NAD83") 
# says  projargs: chr "+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84
#transform to UTM to match l1G1G2
#60 names with the listed name and the accepted name acording to TPL

proj4string(l1G1G2) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
coloradosps.dist <- coloradosps.g1g2
coloradosps.dist$distNearEOR <- NA

distXsp <- lapply(1:nrow(g1g2names), function(i){
  #put grid points across colorado, sample from it for each polygons
     polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                         g1g2names$Taxon[i]),] 
     grid <- makegrid(polys, cellsize = 100) # cellsize in map units!
     grid <- SpatialPointsDataFrame(grid, 
                                    data.frame(id = 1:nrow(grid), Species = g1g2names$AcceptedName[i]),
                                    proj4string = CRS(proj4string(polys)))
     EORpnts <- data.frame(grid[polys,]@coords)
  if(nrow(EORpnts)>0){
    coordinates(EORpnts) <- ~ x1+x2
    proj4string(EORpnts) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
    EORpnts <- spTransform(EORpnts, CRS("+proj=longlat +datum=WGS84"))
  } else {
    EORpnts <- NA
  }
     
  g1g2now <- coloradosps.g1g2[coloradosps.g1g2$scientificName %in%
                                c(g1g2names$Taxon[i],g1g2names$AcceptedName[i]),]
  
  areanow <- sapply(slot(l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                         g1g2names$Taxon[i]),], "polygons"), 
         slot, "area")

  g1g2now$decimalLatitude <- as.numeric(as.character(g1g2now$decimalLatitude))
  g1g2now$decimalLongitude <- as.numeric(as.character(g1g2now$decimalLongitude))
  g1g2now <- g1g2now[!is.na(g1g2now$decimalLatitude),]
  g1g2now <- g1g2now[!is.na(g1g2now$decimalLongitude),]
  if(nrow(g1g2now)>0){
    #turn into spatialpointsdataframe for individual species
    coordinates(g1g2now) <- ~decimalLongitude+decimalLatitude
    proj4string(g1g2now) <- CRS("+proj=longlat +datum=WGS84") 
    g1g2now <- spTransform(g1g2now, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
    distnow <- apply(gDistance(g1g2now,
                               l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                                          g1g2names$Taxon[i]),], byid=TRUE),
                     2,min)
    
    
    out <- list(g1g2now, distnow, areanow, EORpnts)
  } else {
      out <- list(NA,NA, areanow, EORpnts)
    }
  out
  })

distXspbind <- do.call(c,mapply('[[', distXsp, 2))
 
length(distXspbind[is.na(distXspbind)]) #14 don't have any data
distXspbind <- distXspbind[!is.na(distXspbind)]
coloradosps.dist$distNearEOR[which(rownames(coloradosps.dist) %in%
                                         names(distXspbind))] <-unname(distXspbind)
  
save(distXsp, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp.Rda")
```

```{r}

plot(distNearEOR~as.factor(scientificName), coloradosps.dist[coloradosps.dist$distNearEOR<500000,], las=2)

nrow(coloradosps.dist) #2451
colo.merged <- merge(coloradosps.dist, g1g2names, by.x = "scientificName", by.y="AcceptedName")
nrow(colo.merged) #2251
colo.merged.taxon <- merge(coloradosps.dist, g1g2names, by.x = "scientificName", by.y="Taxon")
nrow(colo.merged.taxon) #2121
## Want the ones that are only in the first and only the second and one copy of the middle ones... 
colo.all <- unique(rbind(colo.merged[,-grep("^Taxon$", names(colo.merged))], 
                         colo.merged.taxon[,-grep("^AcceptedName$",names(colo.merged.taxon))]))
nrow(colo.all) #2451
#Names that aren't in TPL
unique(colo.all$scientificName[colo.all$Family==""]) #"Gutierrezia elegans"
colo.all$Family[colo.all$Family==""] <- "Asteraceae"


plot(distNearEOR~as.factor(Family), colo.all[colo.all$distNearEOR<500000,], las=2,
     xlab="",ylab="")
require(lme4)
require(lattice)


length(table(colo.merged$Taxon)) #58 species with some data


#Write table for VisTrails field data
nrow(seinet_TPL)
seinet_TPL.cc <- seinet_TPL[seinet_TPL$decimalLongitude > -110,]
seinet_TPL.cc <- seinet_TPL.cc[seinet_TPL.cc$decimalLatitude > 35, ]

plot(seinet_TPL.cc$decimalLongitude,seinet_TPL.cc$decimalLatitude)

write.csv(seinet_TPL.cc, "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/FieldData_EORG1G2.csv")

write.csv(seinet_TPL.cc, "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Alpine_Phenology_2/Species_SEINet/FieldData_EORG1G2.csv")

herbspecimennumxsp<-table(seinet_TPL.cc$scientificNameAccpt)


whoswho <- data.frame(table(seinet_TPL.cc$scientificNameAccpt,seinet_TPL.cc$scientificName))
whoswho[whoswho$Freq>0,]  



```



#Animate maps over each species with points and polygons   

```{r}
all.g1g2now <- do.call(c,mapply('[[', distXsp, 1)) #all the transformed to UTM species points
all.g1g2now <- all.g1g2now[!is.na(all.g1g2now)]

plot(colocounties.UTM, border="grey80")
plot(l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[1],g1g2names$Taxon[1]),],
     border = "red", add=TRUE, lwd=4)
points(distXsp[[1]][[1]], pch=16, cex=0.25)
ScaleBar(raster(colocounties.UTM), 100, .20, .10, .75, .07, lwd=2)
```

# Follow niche modeling with background points by Iturbide et al 2015  
```{r}
if (!require(devtools)) install.packages("devtools")
devtools::install_git("https://github.com/SantanderMetGroup/mopa.git")


library(mopa)
```

```{r}
OCSVMprofiling<-function(xy, varstack, background = NULL, nu=.5){
  if (class(xy) != "list")  xy <- list(xy)
  if(is.null(background)) background <- backgroundGrid(varstack[[1]])$xy
  if (class(background) != "list")  background <- rep(list(background), length(xy))
  
  bioclim <-varstack
  absence <- list()    
  presence <- list()
  for(i in 1:length(xy)){
    length(absence) <- i
    coo <- background[[i]]
    mat <- cbind(xy[[i]], rep(1, nrow(xy[[i]])))
    mat <- biomat(mat, bioclim)
    mod <- svm(mat[,-1], y=NULL, type='one-classification', nu=nu)
    proj <- biomat(cbind(coo,rep(1,nrow(coo))), bioclim)
    pre <- predict(mod, proj[,-1])
    absence[[i]] <- coo[(which(pre==0)),]
    presence[[i]] <- coo[(which(pre!=0)),]
  }
  if(length(absence) == 1){
    absence <- absence[[1]]
    presence <- presence[[1]]
  }else{
    names(absence) <- names(xy)
    names(presence) <- names(xy)
  }
  return(list("absence"=absence, "presence"=presence))
}
```

Get background points that don't overlap with presence and are at differnt distances away
```{r}


```




Get the coordiates from each saved to use as csvs in VisTrails. 
```{r}
distXsp[[1]][[2]] #The distances from each herbarium point to the nearest EOR
distXsp[[1]][[3]] #The areas of each EOR polygon for that species
distXsp[[1]][[4]] #The 100 meter grid points within EORs

g1g2names

#lat/lon WGS 84
plot(colocounties)
points(distXsp[[1]][[4]], pch=20, col="blue", cex=0.5)


#AsMi
plot(colocounties)
points(distXsp[[4]][[4]]) 


#distXsp[[i]][[1]] are the herbarium points, SpatialPointsDataFrame
speciesNoHerb <- do.call(c,mapply('[[', distXsp, 1))
want <- which(do.call(c,lapply(speciesNoHerb, function(x) !is.na(x))))
wantEOR <- which(do.call(c,lapply(mapply('[[', distXsp, 4),
                         function(x) !is.na(x))))

bboxes <- lapply(want, function(i){
  speciesNoHerb[[i]]@bbox
  })

#If there are multiple names/synonyms
unique(speciesNoHerb[[1]]@data$scientificName)

#All the points
speciesNoHerb[[1]]@coords

#points in the EORs
EORsxsp <- mapply('[[', distXsp, 4)

for(i in wantEOR){
  write.csv((EORsxsp[[i]]@coords),
            paste("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/FieldData_EORG1G2",g1g2names$AcceptedName[i],".csv", sep=""))
}


# make them match the number of points that the herbarium specimens have
for(i in wantEOR){
  if(nrow(EORsxsp[[i]]@coords)>herbspecimennumxsp[i]){
  write.csv(EORsxsp[[i]]@coords[sample(1:nrow(EORsxsp[[i]]@coords), herbspecimennumxsp[i]),],
            paste("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/FieldData_EORsamplesizematch",g1g2names$AcceptedName[i],".csv", sep=""))
  }
}

# spatial thinning instead of just matching the points that the herbarium specimens have. Spatially thin the herbarium specimens as well. 

```

    
    

Test a PCoA for all grid EOR points and all Herb points. Then limit by year, can we figure out which EOR are historic points? 
```{r}

library(tidyr)
library(stringr)
library(raster)
library(magrittr)
library(prism)

options(prism.path = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Prism_Climate_Data/30Year_Normal") 


#get_prism_normals(type="tmax", resolution = "800m", keepZip = FALSE, mon = 1:12)
#get_prism_normals(type="tmin", resolution = "800m", keepZip = FALSE, mon = 1:12)
#get_prism_normals(type="ppt", resolution = "800m", keepZip = FALSE, mon = 1:12)
# stack rasters
rasterstack <- ls_prism_data() %>% prism_stack(.) # many skipping the first 6 that are provisional
#get the projection from the raster stack
rscrs <- rasterstack@crs@projargs # "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"
```
     
     for(poo in 1:length(polys)){
       print(polys[poo,]@bbox)
       poogrid <- makegrid(polys[poo,], cellsize = 800, pretty = FALSE)
       #plot(polys[poo,])
       plot(poogrid)
        # ScaleBar(polys[i,],0.01, .25, .20, .15, .17, lwd=2) 
       
```{r}
cellsize <- 10
     grid <- lapply(1:length(polys), function(i){
       if(sqrt((polys[i,]@bbox[3]-polys[i,]@bbox[1])*(polys[i,]@bbox[4]-polys[i,]@bbox[2]))/cellsize < 1){
         center <- gCentroid(polys[i,])
         centerout <- SpatialPointsDataFrame(center, data.frame(id=1,
                                                                polys@data$PolyID@data[i,]),
                                             proj4string = CRS(proj4string(polys[i,])))
         centerout
         } else {
           grid <- makegrid(polys[i,], cellsize = cellsize, pretty=FALSE) #1km 
           gridout <- SpatialPointsDataFrame(grid, data.frame(id=1:nrow(grid),
                                                              polys@data$PolyID@data[i,]),
                                             proj4string = CRS(proj4string(polys[i,])))
           gridout
           }
       })

```


```{r, eval=FALSE}


#uses l1G1G2 for pca of the eors
# use coloradosps.g1g2 for the herbarium, go species by species and get the grid points and the herb points and extract the rasterbrick things (add elevation and others to the raster stack)
proj4string(l1G1G2) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
#coloradosps.dist <- coloradosps.g1g2
#coloradosps.dist$distNearEOR <- NA

pca_eorandherb <- lapply(1:nrow(g1g2names), function(sp){
  #put grid points across colorado, sample from it for each polygons
     polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[sp],
                                         g1g2names$Taxon[sp]),] 

     cellsize <- 100
     grid <- lapply(1:length(polys), function(i){
       if(sqrt((polys[i,]@bbox[3]-polys[i,]@bbox[1])*(polys[i,]@bbox[4]-polys[i,]@bbox[2]))/cellsize < 1){
         grid <- makegrid(polys[i,], cellsize = 10, pretty=FALSE) #0.1km
         gridout <- SpatialPointsDataFrame(grid, data.frame(id=1:nrow(grid),polyid=i,
                                                            polys@data$PolyID@data[i,]),
                                             proj4string = CRS(proj4string(polys[i,])))
           gridout
         } else {
           grid <- makegrid(polys[i,], cellsize = cellsize, pretty=FALSE) #1km 
           gridout <- SpatialPointsDataFrame(grid, data.frame(id=1:nrow(grid),polyid=i,
                                                              polys@data$PolyID@data[i,]),
                                             proj4string = CRS(proj4string(polys[i,])))
           gridout
           }
       })
     

     ov <- lapply(1:length(polys), function(i){
         out <- grid[[i]][polys[i,],]
         out
         })

     eor_data <- lapply(1:length(ov), function(x){
       if(nrow(ov[[x]]@data)==0){
         center <- gCentroid(polys[i,])
         centerout <- SpatialPointsDataFrame(center, data.frame(id=1,polyid=x,
                                                                polys@data$PolyID@data[i,]),
                                             proj4string = CRS(proj4string(polys[i,])))
         out <- spTransform(centerout, CRS(paste(rscrs)))
         out
       } else {
         out <- spTransform(ov[[x]], CRS(paste(rscrs)))
         out
       }
     })
     
     mergedEORs <- do.call(rbind,eor_data)
     data_eor <- data.frame(coordinates(mergedEORs),id=mergedEORs$id,polyid=mergedEORs$polyid,
                            Bestcrs=mergedEORs$BESTSRC, firstobs=mergedEORs$FIRSTOBS, 
                            GRANK=mergedEORs$GRANK,
                            GNAME=mergedEORs$GNAME,ENDEMIC=mergedEORs$ENDEMIC, 
                            Lastobs=mergedEORs$LASTOBS,
                            extract(rasterstack, mergedEORs))
     data_eor
})

  
```


as.Date(polys[[1]]@data$LASTOBS)>"1987-01-01"
str(mergedEORs@data)
mergedEORs@data[as.Date(mergedEORs@data$LASTOBS) > "1987-01-01",] 

Get rid of data from polygons only seen before 1981
get rid of repeted values for all the climate things, do only one row for each cell
Column 4 is each polygon's id so there's only one point for each raster grid over a polygon but at least one point per polygon. 
```{r}
pca_eorsinglecell <- lapply(pca_eorandherb, function(x){
  x[!duplicated(x[,c(4,11:length(x))]),]
})

pca_eorpost1980 <- lapply(pca_eorandherb, function(x){
  x <- x[!grepl("-99",x$Lastobs),]
  x <- x[(as.Date(x$Lastobs)>"1980-12-31"),]
  out <- x[!duplicated(x[,c(4,11:length(x))]),]
  out
})

save(pca_eorsinglecell, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorsinglecell.Rda")
save(pca_eorandherb, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorandherb.Rda")
save(pca_eorpost1980, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_eorpost1980.Rda")


```


CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))

```{r}

#make into spatialpointsdataframes, make in UTM like EORs
eorsinglecell <- lapply(pca_eorsinglecell, function(x){
  coordinates(x) <- ~ x1+x2
  proj4string(x) <- CRS(paste(rscrs))
  projectedx <- spTransform(x, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
})

eorlotsofcell <- lapply(pca_eorandherb, function(x){
  coordinates(x) <- ~ x1+x2
  proj4string(x) <- CRS(paste(rscrs))
  projectedx <- spTransform(x, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
})

eorpost1980 <- lapply(pca_eorpost1980, function(x){
  coordinates(x) <- ~ x1+x2
  proj4string(x) <- CRS(paste(rscrs))
  projectedx <- spTransform(x, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
})


polys <- lapply(1:nrow(g1g2names), function(i){
  #put grid points across colorado, sample from it for each polygons
     polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                         g1g2names$Taxon[i]),]
     polys
     })

for(j in 10:13){
  for(i in 1:length(polys[[j]])){
    plot(polys[[j]][i,], border="blue",lwd=3, main=polys[[j]][i,]@data$LASTOBS)
    plot(eorsinglecell[[j]], pch=21, col="red",add=TRUE)
    plot(polys[[j]], border="yellow", add=TRUE)
    ScaleBar(polys[[j]][i,],
             0.01, .25, .20, .15, .17, lwd=2) #first is round to nearest km
  }
}

polys[[2]]@data$LASTOBS

for(j in 3:5){
  for(i in 1:length(polys[[j]])){
    plot(polys[[j]][i,], border="blue", main=polys[[j]][i,]@data$LASTOBS)
    plot(eorlotsofcell[[j]], pch=21, col="red",add=TRUE)
    ScaleBar(polys[[j]][i,],
             0.01, .25, .20, .15, .17, lwd=2) #first is round to nearest km
  }
}


for(j in 3:5){
  for(i in 1:length(polys[[j]])){
    plot(polys[[j]][i,], border="blue", main=polys[[j]][i,]@data$LASTOBS)
    plot(eorpost1980[[j]], pch=21, col="red",add=TRUE)
    ScaleBar(polys[[j]][i,],
             0.01, .25, .20, .15, .17, lwd=2) #first is round to nearest km
  }
}

for(p in 1:60){
  plot(eorlotsofcell)
}

for(i in 1:3){
  plot(polys[[i]], border="goldenrod", lwd=10, main=polys[[j]][i,]@data$LASTOBS)
  plot(eorsinglecell[[i]], add=TRUE)
    ScaleBar(polys[[j]][i,],
             0.01, .25, .20, .15, .17, lwd=2) #first is round to nearest km
}



```

```{r}
for(i in 1:length(polys)){
  plot(polys[i,], border="blue")
  plot(grid[[i]], pch=20, cex=0.5, add=TRUE)
  ScaleBar(polys[i,],
           0.01, .25, .20, .15, .17, lwd=2) #first is round to nearest km
}

```



```{r}

#The first in all these are the herbarium records
(distXsp[[1]][[1]]) #+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0   Need to transform

proj4string((distXsp[[1]][[4]]))

#distXsp[[i]][[1]] are the herbarium points, SpatialPointsDataFrame
speciesNoHerb <- do.call(c,mapply('[[', distXsp, 1))
want <- which(do.call(c,lapply(speciesNoHerb, function(x) !is.na(x))))

(distXsp[[want[3]]][[1]])

pca_herb <- lapply(want, function(x){
  out <- spTransform(distXsp[[x]][[1]], CRS(paste(rscrs)))
  pca_herbout <- data.frame(coordinates(out),id=out$id,polyid=NA,
                            Bestcrs=out$institutionCode, firstobs=out$eventDate, 
                            GRANK=NA,
                            GNAME=out$scientificName,ENDEMIC=NA, 
                            Lastobs=out$eventDate,
                            extract(rasterstack, out))
  pca_herbout
})




# since sampling bias is known issue, only one point per climate raster value (columns 11:length) are kept; don't know if sampling density is due to bias or higher area of suitability. hummm. 
pca_herbpost1980 <- lapply(pca_herb, function(x){
  colnames(x) <- c("x1","x2",colnames(x)[3:length(x)])
  x <- x[(which(nchar(as.character(x$Lastobs)) == 10)),]
  x <- x[!grepl("-99",x$Lastobs),]
  x <- x[(as.Date(x$Lastobs)>"1980-12-31"),]
  out <- x[!duplicated(x[,c(11:length(x))]),]
  out
})
```

select background points that are closer to road so pick more background points around roads and most where buffer around population and roads overlap.   
```{r}
coroads <- shapefile("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Roads/Local Roads/Local Roads SHP/LROADS.shp")

#plot(coroads)

#Planer
proj4string(coroads) #"+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
r <- raster(extent(coroads))
proj4string(r) <- proj4string(coroads)
r.smaller <- disaggregate(r, fact=2)

dd <- gDistance(coroads, as(r, "SpatialPoints"), byid=TRUE)
r[] <- apply(dd,1,min)

dd.smaller <- gDistance(coroads, as(r.smaller, "SpatialPoints"), byid=TRUE)
r.smaller[] <- apply(dd.smaller,1,min)


plot(r)
plot(r.smaller)
plot(rasterstack[[1]], xlim=c(-109,-103), ylim=c(37,41))

plot(r.smaller[r.smaller<8000])

plot(coroads, add=TRUE)
```

Either background points are selected with more frequency closer to roads or 'background' is a buffer around roads and around points and selected randomly within that overlap - all need to match the number of presence points. 
```{r}
bkgrnd <- calc(r.smaller, fun= function(X) sampleRandom(r.smaller, size= x))

samplesize <- calc(r.smaller, fun=function(x) 1-(1/(x/100))/100)

hist(samplesize)

layerbackgroundpoints <- sampleRandom(r.smaller, size = ) 

```


```{r}
#Rasterstack is in longlat so needs the elipsoid dist2line. 
roadsraster <- raster(extent(rasterstack[[1]]))
proj4string(roadsraster) <- CRS(rscrs) #This is for the climate data

coroads_longlat <- spTransform(coroads, CRS(rscrs))

#dd <- gDistance(coroads_longlat, as(roadsraster, "SpatialPoints"), byid=TRUE)
library(geosphere)

dd <- dist2Line(as(roadsraster, "SpatialPoints"), as(coroads_longlat, "SpatialLines"))

```



```{r}
#Create bckground points, give them a 0 and same column names with lat long. Give eors a 1 and herb a 2 for looking at groups but then do a clustering

pca_data <- lapply(1:length(want), function(x){
  eor <- 
  rbind(pca_eorpost1980[[want[x]]], pca_herbpost1980[[x]])
})

```




https://stackoverflow.com/questions/32915628/best-way-to-create-response-curves-for-a-glm-species-distribution-model-in-r 
```{r}
corout <- as.data.frame(as.table(cor(pca_data[[1]][,11:length(pca_data[[1]])])))
corout[corout$Freq<0.60,]


m1 <- glm()
```





 From VisTrails
```{r}
DrEx_EOR <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/NicheModels/Draba exunguiculata_EOR/Maxent_EORvHerb_1/maxent_bin_map.tif")

DrEx <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/NicheModels/Draba exunguiculata/Maxent_1/maxent_bin_map.tif")

#DrExEORmatchss <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/NicheModels/Draba exunguiculata_EORsamplesizematch/Maxent_EORvHerb_1/maxent_bin_map.tif")


#Following my code from Elevation_nichemodels_Vistrails.Rmd, make overlap be 3, 2 be EOR, and Herbarium be 1
#EOR <- DrEx_EOR

plot(DrEx_EOR)
plot(DrEx)
#plot(DrExEORmatchss)

AsMi_EOR <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/NicheModels/Astragalus microcymbus_EOR/Maxent_EORvHerb_1/maxent_bin_map.tif")

AsMi <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/NicheModels/Astragalus microcymbus/Maxent_1/maxent_bin_map.tif")

#Following my code from Elevation_nichemodels_Vistrails.Rmd, make overlap be 3, 2 be EOR, and Herbarium be 1

AsMiEORmatchss <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/NicheModels/Astragalus microcymbus_EORsamplesizematch/Maxent_EORvHerb_1/maxent_bin_map.tif")


plot(AsMi_EOR,main="EOR")
plot(colocounties, add=TRUE)
plot(AsMi, main="Herb")
plot(colocounties, add=TRUE)
plot(AsMiEORmatchss, main="EOR sample size match herb")
plot(colocounties, add=TRUE)
points(projected[grep("micro", projected$scientificName),])

```
layout plot  
```{r}
jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/EOR_Herb_EORthin_AsMi.jpg",
     width=700, height=170,units='mm', res=300)

nf <- layout(matrix(c(1,2,3), 1,3, byrow=FALSE),
             width=c(6,6,6), height=c(1))
layout.show(nf)

op <- par(no.readonly=TRUE)
par(mai=c(1.5,2,3.5,3)/4)

#EOR
plot(AsMi_EOR)
plot(colocounties, add=TRUE)
mtext("a)", side=3, cex=2, line=0.5, at=par("usr")[1]+0.05*diff(par("usr")[1:2]))
points(distXsp[[4]][[4]],pch=20, cex=0.5)

#Herbarium collections
plot(AsMi)
plot(colocounties, add=TRUE)
mtext("b)", side=3,cex=2,  line=0.5, at=par("usr")[1]+0.05*diff(par("usr")[1:2]))

#Thinned EOR points to match Herbarium points
plot(AsMiEORmatchss)
plot(colocounties, add=TRUE)
mtext("c)", side=3,cex=2,  line=0.5, at=par("usr")[1]+0.05*diff(par("usr")[1:2]))

dev.off()

```


http://www.earthskysea.org/!ecology/sdmShortCourseKState2012/grinnellExercise/exercise-tuning-maxent-using-beta-and-aic.html  
https://cran.r-project.org/web/packages/ENMeval/vignettes/ENMeval-vignette.html    
Use AICc with Maxent to find best model  
```{r}



```


create a raster in R as distance from road
```{r}
localroads <- readOGR(dsn = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/Roads/Local Roads/Local Roads SHP", layer="LROADS")


bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)

#Create a raster to hold distance from road in the same size and extent of the bioclim layers
r <- raster()
extent(r) <- extent(bioclim.colorado[[1]])
projection(r) <- projection(bioclim.colorado[[1]])
res(r) <- res(bioclim.colorado[[1]])

localroads.latlon <- spTransform(localroads, CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))


dd <- gDistance(localroads.latlon, as(r, "SpatialPoints"), byid=TRUE)

```



```{r}
str(distXspbind) #1091
hist(distXspbind/1000, main = "Distance (km) from points to nearest EOR",
     xlab="km", breaks=1000, xlim=c(1,500))

vals <- density(distXspbind)
pStar <- vals$x[which(vals$y==max(vals$y))]

plot(density(distXspbind), xlim=c(0,50000))
abline(v=pStar, col="red")
abline(h=max(vals$y)-qlnorm(0.95))

length(distXspbind[distXspbind>100]) #816

length(distXspbind[distXspbind<=100]) #275

median(distXspbind)

reps <- 50000
ssize <- 500
rand.diff <- unlist(lapply(1:reps, function(x) median(sample(distXspbind,ssize))))
ctrl95CI <- sd(rand.diff)/sqrt(ssize)*qt(0.975,df=ssize) 
ctrl95CI.l <- sd(rand.diff)/sqrt(ssize)*qt(0.025,df=ssize)


hist(rand.diff)
abline(v=mean(rand.diff)+ctrl95CI, col="red")
abline(v=mean(rand.diff)+ctrl95CI.l, col="red")

```


```{r}
for(i in want){
  plot(l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],g1g2names$Taxon[i]),],
       border = rgb(1,0,0,0.5),  main=g1g2names$AcceptedName[i], lwd=3,
       xlim=c(min(distXsp[[i]][[1]]@coords[,1]),max(distXsp[[i]][[1]]@coords[,1])),
       ylim=c(min(distXsp[[i]][[1]]@coords[,2]),max(distXsp[[i]][[1]]@coords[,2])))
  points(distXsp[[i]][[1]], pch=16, cex=0.5, col=rgb(0,0,0,0.75))
  ScaleBar(raster(l1G1G2[l1G1G2$GNAME %in%
                           c(g1g2names$AcceptedName[i],g1g2names$Taxon[i]),]), 
           1, .25, .20, .15, .17, lwd=2)
}

```

4/6/2018 - Danielle Gualtieri working on Colton Gaines protocol for mapping and adding uncertainty protocol (similar to Mo's work)  6/11/2018 - long gone, hasn't been back in a while, not doing the work any more


#Mechanistic models based on matrix models growth rates and fecundity correlative, use some model selection? for best prediction by species  
```{r}
load("Q:/Research/Stats & Software/COMPADRE_PlantMAtrixDatabase/COMPADRE_v.4.0.1.RData")



```



# How do the maping techniques change by time, herbarium, or collector (amount of informaiton given)?   
#Some data cleaning of colo.all, use colo.test first
```{r}
i <- sapply(colo.all, is.factor)
colo.all[i]<-lapply(colo.all[i], as.character)

colo.all$year <- as.numeric(colo.all$year)
colo.all$decimalLatitude <- as.numeric(colo.all$decimalLatitude)
colo.all$decimalLongitude <- as.numeric(colo.all$decimalLongitude)
colo.all$minimumElevationInMeters <- as.numeric(colo.all$minimumElevationInMeters)

colo.all[colo.all$recordNumber == 9088,] #year is 1999, not recorded at Fort Lewis
colo.all[colo.all$recordNumber == 1596,] #another repeat, should be 1997 not 1007
## Ok to get rid of duplicates that resulted in wrong years
colo.all <- colo.all[colo.all$year > 1800,]

colo.all$coordinateUncertaintyInMeters <-
  as.numeric(colo.all$coordinateUncertaintyInMeters)
#How many specimens give an uncertainty in meters (square meters?)
length(colo.all$coordinateUncertaintyInMeters[!is.na(colo.all$coordinateUncertaintyInMeters) & !is.na(colo.all$decimalLatitude)])/
  length(colo.all$coordinateUncertaintyInMeters[!is.na(colo.all$decimalLatitude)])

colo.all[is.na(colo.all$coordinateUncertaintyInMeters),]

colo.all[colo.all$distNearEOR>50000 & !is.na(colo.all$distNearEOR),c(56,57,83,61,63,66,67)] #611551meters is width of colorado about

#Can't have missing data
colo.all.ll <- colo.all[!is.na(colo.all$decimalLatitude)&
                       !is.na(colo.all$decimalLongitude),]
coordinates(colo.all.ll) <-~decimalLongitude+decimalLatitude
proj4string(colo.all.ll) <- CRS("+proj=longlat +datum=WGS84") 
colo.all.ll <- spTransform(colo.all.ll, CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))

all.county <- over(colo.all.ll, colocounties.UTM[,"COUNTY"])
colo.all.ll$InCounty <- all.county[,1]


table(colo.all.ll$county[colo.all.ll$county != colo.all.ll$InCounty])
colo.all.ll@data[colo.all.ll$county != colo.all.ll$InCounty &
              !is.na(colo.all.ll$county),c("scientificName","institutionCode","county","InCounty","georeferencedBy")]

#Which county are the points really in
colocounties.UTM.df <- as.data.frame(colocounties.UTM)
colocounties.UTM.df$id <- as.numeric(rownames(colocounties.UTM.df))

plot(colocounties.UTM, border="grey80")
plot(colo.all.ll, add=TRUE, pch=16, cex=0.5)

#Make a Levenshtein distance matric between names (like that paper!)
countymatch<- adist(colo.all.ll@data$county[!is.na(colo.all.ll@data$county)&
                                              colo.all.ll@data$county!=""],
                    colo.all.ll@data$InCounty[!is.na(colo.all.ll@data$county)&
                                              colo.all.ll@data$county!=""],
                    partial=TRUE,ignore.case = TRUE)
#Single linkage method
#hcfar <- hclust(as.dist(countymatch), method='single')


#errors so try clean up county column
colo.all.ll$countyclean <- gsub("Co.*","",colo.all.ll$county)
#trim trailing white space
colo.all.ll$countyclean <- sub("\\s+$", "", colo.all.ll$countyclean)
colo.all.ll$countyclean <- toupper(colo.all.ll$countyclean)

colo.all.ll@data[!(colo.all.ll$countyclean %in%colo.all.ll$InCounty),]

nrow(colo.all.ll@data[!(colo.all.ll$countyclean %in%colo.all.ll$InCounty),])/
       nrow(colo.all.ll)

colo.all.ll@data[!(colo.all.ll$countyclean %in%colo.all.ll$InCounty),]

```


Assuming CNHP is nearly correct 
```{r}
colo.all[colo.all$recordNumber%in%
           colo.all.ll@data$recordNumber[colo.all.ll$distNearEOR>50000] & !is.na(colo.all$decimalLatitude),
         c("scientificName","decimalLatitude","decimalLongitude","county","verbatimCoordinates",
           "habitat","locality","recordNumber")] ##Location would be correct but decimalLongitude goes to -160.4; The easting has an extra zero: -105.7131, 38.1374; 3972 m


#row 99: 21864 entered 27.47444 lat, probably meant 37.47
#Row 753 21864 again with an extra trailing 0 for the easting got to -160 for long
#row 1382 5733 zone 12 and NAD27, SEINet couldnt' figure that out maybe?
#row 1393 5733 seems correct! **keep this one, lose the rest 5733; the other two are duplicates!
#row 1394 5733 This time missing a digit in the easting so it put it in Nevada

colo.all.ll@data[rownames(colo.all.ll@data) == 99,]
```


#Random forest - classification and regression trees   
Either a formula, or (1) data.frame with predictor variables, (2) vector with response. categorical will classification, interval will do regression. 
```{r}

library(randomForest)

bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)


plot(bioclim.colorado$bio1_12)
plot(colocounties, add=TRUE)

#When loop, use "i in want" or lapply(want, function(i)) which are non-NA in the list for distXsp[[i]][[1]]@coords

#need back to lat long
pointsXsp.latlon <- list()
for(i in 1:length(want)){
  pointsXsp.latlon[[i]] <- spTransform(distXsp[[want[1]]][[1]], CRS("+proj=longlat +datum=WGS84"))
}

##COME BACK TO THIS AND SEE WHAT NEEDS TO BE Done to do random forest
presvals <- extract(bioclim.colorado, )


library(dismo)

kfoldnum <- 5

#Make a training and testing set, will want to iterative over all sets, keeping one out each time
#lapply(1:kfoldnum, function(x){})

group <- kfold(distXsp[[1]][[1]]@coords, kfoldnum)
pres_train <- distXsp[[1]][[1]]@coords[group != 1,]
pres_test <- distXsp[[1]][[1]]@coords[group == 1,]

ext <- extent(-109, -102, 36, 41)
backg <- randomPoints(bioclim.colorado, n=300, ext=ext, extf=1.25)
colnames(backg) <- dimnames(pres_test)[[2]]
groupbk <- kfold(backg, kfoldnum)
backg_train <- backg[groupbk != 1,]
backg_test <- backg[groupbk == 1,]






```


```{r}
ggplot(colo.all.ll@data[colo.all.ll$distNearEOR<500000,], aes(year, distNearEOR/1000))+
  geom_point()+
  theme_bw()+
#  geom_hline(yintercept=(57936.4/1000), col="red")+ #if off by 36 miles
#  geom_hline(yintercept=(666), col="blue")+ #if off by 1 zone, 111km wide at equator
  stat_smooth(method="lm")+
  ylab("Distance (km) to nearest EOR")
```

Total area of EOR polygons per spcies for the the 46 species with mapped herbarium records 
```{r}
speciesNoEOR <- lapply(want, function(x){
  out <- sum(distXsp[[x]][[3]])
  out
})

areaxsp <- unlist(lapply(want, function(x) sum(distXsp[[x]][[3]])))
areaxsp <- data.frame(Area = areaxsp, AccName = g1g2names$AcceptedName[want])

mediandistxsp <- unlist(lapply(want, function(x) median(distXsp[[x]][[2]])))

area_distxsp <- rep(areaxsp$Area, times= unlist(lapply(want,function(x) length(distXsp[[x]][[2]]))))
sp_distxsp <- rep(areaxsp$AccName, times= unlist(lapply(want,function(x) length(distXsp[[x]][[2]]))))

toplot <- data.frame(area_distxsp, sp_distxsp, distXspbind)

#One is factor, but they are the same! 46 species
areaxsp$AccName <- as.character(areaxsp$AccName) 

colo.all.ll$AcceptedName <- paste(colo.all.ll$New.Genus,colo.all.ll$New.Species)
colo.all.ll@data <- merge(colo.all.ll@data,areaxsp, 
                          by.x ="AcceptedName", by.y="AccName")

toplot[which(toplot$area_distxsp==max(toplot$area_distxsp)),]


ggplot(toplot[toplot$distXspbind<200000,], aes(area_distxsp, distXspbind/1000))+
  geom_point()+
  theme_bw()+
  stat_smooth(method="lm")+
  ylab("Distance (km) to nearest EOR")+
  xlab("Total EOR area")

```

```{r}
require(AICcmodavg)



f1 <- lm(distNearEOR ~ New.Genus + year + institutionCode + Family + Area, data= colo.all.ll@data)
f2 <- lm(distNearEOR ~ year + institutionCode + Family + Area, data= colo.all.ll)
f3 <- lm(distNearEOR ~ year + Area, data= colo.all.ll)
f4 <- lm(distNearEOR ~ year, data= colo.all.ll)
f5 <- lm(distNearEOR ~ Area, data= colo.all.ll)
f6 <- lm(distNearEOR ~ 1, data= colo.all.ll)

(lmresults <- aictab(list(f1,f2,f3,f4,f5,f6),
       modnames=as.character(unlist(lapply(list(f1,f2,f3,f4,f5,f6),formula)))))

evidence(aictab(cand.set = list(f1,f2,f3,f4,f5,f6),
                modnames = as.character(unlist(lapply(list(f1,f2,f3,f4,f5,f6),formula)))))

sapply(1:length(lmresults$Delta_AICc), function(i){
  exp(-0.5*lmresults$Delta_AICc[i])/sum(exp(-0.5*lmresults$Delta_AICc))
})

(er1 <- exp(0.5*lmresults$Delta_AICc[2]))
(er2 <- exp(0.5*lmresults$Delta_AICc[3]))
```


#how many are in the county they say they should be in? Check Jessie's code for help
```{r}
ggplot(colo.all[colo.all$distNearEOR<50000,], aes(as.numeric(year), distNearEOR))+
  geom_point()+
  stat_smooth(se=FALSE)+
  theme_bw()+
  xlab("Year")+
  ylab("Distance from nearest EOR")+
#  labs(color='Georeference Method')+
   theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
```



#By herbarium 
Maybe regional collections are much better?   
FLD = Fort Lewis College    
DES = Dessert Arizona   
MESA = Colorado Mesa University   
MISSA = Miss State Univ   
NMC = New Mexico State University    
SJNM = San Juan College, New Mexico   
UCR = University of California Riverside    
USUUB = Utah STate University Uintah Basin (probably is USU)   
UVSC = Utah Valley University	U.S.A. Utah. Orem.      




```{r}

local <- c("COLO","CS","DBG","FLD","MESA","RM","RMBL")
Adjacent <- c("ASC","ASU","BRY","DES","NMC","RM","SJNM","UNM","USUUB","UVSC")
far <- c("CM","F","MISSA","MO","NY","RENO","UCR")

colo.all.ll@data$InstNear[colo.all.ll@data$institutionCode %in% local] <- "Local"
colo.all.ll@data$InstNear[colo.all.ll@data$institutionCode %in% Adjacent] <- "Near"
colo.all.ll@data$InstNear[colo.all.ll@data$institutionCode %in% far] <- "Far"

colo.all.ll@data$InstNear <- factor(colo.all.ll@data$InstNear, levels = c("Far","Near","Local"))

ggplot(colo.all.ll@data[colo.all.ll$distNearEOR<500000,], 
       aes(InstNear, distNearEOR/1000))+
  geom_jitter()+
  stat_summary(fun.y=mean, geom="point", shape=18,
                 size=3, color="red")+ 
  geom_violin(trim = FALSE)+
  theme_bw()+
  ylab("Distance (km) to nearest EOR")+
  xlab("Total EOR area")

```

```{r}
colo.all.ll@data$verbatimCoordinates[colo.all.ll$distNearEOR>100]

#How many gave 1/4 section
colo.all.ll@data[grep("1/4", colo.all.ll$verbatimCoordinates),]
mean(colo.all.ll@data$distNearEOR[grep("1/4", colo.all.ll$verbatimCoordinates)])
sd(colo.all.ll@data$distNearEOR[grep("1/4", colo.all.ll$verbatimCoordinates)])


mean(colo.all.ll@data$distNearEOR[grep("", colo.all.ll$verbatimCoordinates)])
sd(colo.all.ll@data$distNearEOR[grep("1/4", colo.all.ll$verbatimCoordinates)])
```



#Convext hull or tiny circles around eors vs herbarium vs. both together, how much change?    

The Weber example of an out of state person mapping a collection to Gray's Peak from Chicago Lake that should be Mount Evans.     
- <https://conps.org/wp-content/uploads/2015/05/Mount_Evans_Summit_Lake_4-24-2011.pdf>    

"coloradosps" == SEINet collections from Colorado - downloaded 12/6/2017 from SEINet      
"coloG1G2" == species matching names in L1 EORs but without any synonym corrections     
"seinet" == Mo worked on this, made distances from nearest EOR and looked at posted informaiton to figure out what might have been used to pick point on map        
      
ITISlist is synonmy pulled from ITIS into SQL    
TPL is pulling from synonym from the plant list   "colo"   
      "seinetMo"is synonymy with TPL for Mo's list of 53 species (that are G1/G2s)   
      "colonames" is synonym with TPL for all colorado specimens from SEINet   

<https://rpubs.com/spoonerf/SDM4>   
        
#ENMeval vignette
<https://cran.r-project.org/web/packages/ENMeval/vignettes/ENMeval-vignette.html>   
```{r}
bioclim.colorado <- getData("worldclim", var="bio", res=0.5, lon=-106, lat = 39)


plot(bioclim.colorado$bio1_12)
plot(colocounties, add=TRUE)


# Use rasters in a RasterStack:
class(bioclim.colorado)


#Need back to latlon for bioclim layers
pointsXsp.latlon <- list()
for(i in 1:length(want)){
  pointsXsp.latlon[[i]] <- spTransform(distXsp[[want[i]]][[1]], CRS("+proj=longlat +datum=WGS84"))
}

# Plot first raster in the stack, bio1
# Add points for all the occurrence points onto the raster
plot(bioclim.colorado[[1]], main=names(bioclim.colorado)[1])
points(pointsXsp.latlon[[15]])



```


#Spatial thinning
<https://cran.r-project.org/web/packages/spThin/vignettes/spThin_vignette.html>     
Thin to create dataset in which all occurences are at least _thin.par_ distance apart. helps reduce effect of uneven, biased, species occurence collections on spatial model outcomes   
Got through 19 of them, go from 20 to length(wantEOR)
```{r}
# The EOR grid points from distXsp is the forth item. Wants lat long, they are. 
#for(i in 1:length(wantEOR)){
#for(i in 20:length(wantEOR)){
#for(i in 21:length(wantEOR)){

EORgrid.thin <- list()
#for(i in c(1:18,21:47,49:length(wantEOR))){
for(i in c(20,48)){
  EORsp <- data.frame(distXsp[[wantEOR[i]]][[4]]@coords,
                      species=g1g2names$AcceptedName[wantEOR[i]])
    EORgrid.thin[[i]] <- thin(loc.data = EORsp,
                         lat.col = "x2", long.col = "x1",
                         spec.col="species",
                         thin.par = 1, reps=10,
                         locs.thinned.list.return = TRUE,
                         write.files = TRUE, max.files=5,
                         out.dir = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Thinned/",paste(out.base="EORsp_1km",i,"_",g1g2names$AcceptedName[wantEOR[i]],sep=""), write.log.file = TRUE,
                         log.file = "EORgridthinned_log.txt")
}

save(EORgrid.thin, file= "P:/hackathon/Simulations/EORgrid.thin.Rda")
```


```{r}
Herb.thin1000 <- list()
for(i in 1:length(want)){
  Herbsp <- data.frame(pointsXsp.latlon[[i]]@coords,
                       species=g1g2names$AcceptedName[want[i]])
  Herb.thin1000[[i]] <- thin(loc.data = Herbsp,
                     lat.col = "decimalLatitude", long.col = "decimalLongitude",
                     spec.col="species",
                     thin.par = 1, reps=1000,
                     locs.thinned.list.return = TRUE,
                     write.files = TRUE, max.files=5,
                     out.dir = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Thinned/",paste(out.base="Herb.thin_1km_1000",i,"_",g1g2names$AcceptedName[wantEOR[i]],sep=""), write.log.file = TRUE,
                     log.file = "EORgridthinned1000_log.txt")
}

save(Herb.thin1000, file= "P:/hackathon/Simulations/Herb.thin1000.Rda")
```

```{r}
plot(EORgrid.thin[[1]][[1]])
plot(EORgrid.thin[[1]][[2]])

for(i in 1:length(EORgrid.thin)){
  plotThin(EORgrid.thin[[i]])
}
```


### Background points  
Can either do bounding box (plus some buffer) or circles at some diameter   
    
    - there are 60 species L1/L2 species with data   
    - 59 species have EOR data    
    - 46 species have herbarium data avalaible through SEINet    
    - wantEOR are the ones from the 60 that have EOR data so wantEOR[i] in a loop would get the ones I want    
    - want[i] would get teh 46 that have herbarium data from the list of 60 species   

##SKIP!! you already loaded these
```{r}
#Circles around herbarium points
circleHerb <- list()
for(i in 1:length(want)){
  circleHerb[[i]] <- circles(pointsXsp.latlon[[i]]@coords, d=50000, lonlat=TRUE)
}

save(circleHerb, file= "P:/hackathon/Simulations/circleHerb.Rda")

#Circles around EOR points. 
circle <- list()
for(i in 1:length(wantEOR)){
  circle[[i]] <- circles(EORsxsp[[wantEOR[i]]]@coords, d=50000, lonlat=TRUE)
}

save(circle, file= "P:/hackathon/Simulations/circleEOR.Rda")
```

#SKIP!!! already loaded
```{r}
plot(colocounties)
plot(circle[[2]], add=TRUE)
points(EORsxsp[[2]]@coords, pch=16)
plot(circle[[3]], add=TRUE, border="red")
points(EORsxsp[[3]]@coords, pch=16)
plot(circle[[4]], add=TRUE, border="blue")
points(EORsxsp[[4]]@coords, pch=16)
plot(circle[[5]], add=TRUE, border="orange")
points(EORsxsp[[5]]@coords, pch=16)

# Need stack of environmental layers  
#Raster stack of just the bioclim variables
class(bioclim.colorado)

# Get backgrounds for each species
envs.backg <- list()
for(i in 1:length(wantEOR)){
  envs.backg[[i]] <- crop(bioclim.colorado, circle[[i]]@polygons)
}

for(i in 1:length(wantEOR)){
  envs.backg[[i]] <- mask(envs.backg[[i]], circle[[i]]@polygons)
}


#Get backgrounds for each species according to the herbarium specimens
envs.backg.herb <- list()
for(i in 1:length(want)){
  envs.backg.herb[[i]] <- crop(bioclim.colorado, circleHerb[[i]]@polygons)
}

for(i in 1:length(want)){
  envs.backg.herb[[i]] <- mask(envs.backg.herb[[i]], circleHerb[[i]]@polygons)
}

#Plot presence points
plot(envs.backg[[wantEOR[19]]][[1]], main=g1g2names$AcceptedName[wantEOR[19]])
points(EORsxsp[[wantEOR[19]]], pch=16)

for(i in 1:length(envs.backg.herb)){
  plot(envs.backg.herb[[i]][[1]], main=g1g2names$AcceptedName[want[match(i,want)]] )
  plot(colocounties, add=TRUE)
}

for(i in 1:60){
  print(paste(i,g1g2names$AcceptedName[i],"or is it:",
              "herb:",
              want[match(i,want)], "and EOR:", wantEOR[match(i,wantEOR)],
        "Just want[i]:", want[i], "and wantEOR[i]", wantEOR[i]))
} 


save(envs.backg, file= "P:/hackathon/Simulations/envs.backgEOR.Rda")
save(envs.backg.herb, file= "P:/hackathon/Simulations/envs.backgHerb.Rda")
```



```{r}
#The item in the list that matches the number, i, is the the match(i, want) or match(i, wantEOR) but some are missing (want and envs.backg.herb are 46 long, wantEOR and envs.backg are 59 long )
for(i in 1:length(want)){
  if(!is.na(wantEOR[match(want[i],wantEOR)])){
    plot(colocounties,
         main=g1g2names$AcceptedName[want[i]])
    plot(envs.backg.herb[[i]][[1]], #just the first bioclim 
         add=TRUE, col=rgb(0,1,1,0.25),border="black")
    plot(envs.backg[[wantEOR[match(want[i],wantEOR)]]][[1]], col=rgb(1,0,0,0.25),
         add=TRUE, legend=FALSE) #from the EORs
    points(pointsXsp.latlon[[i]], pch=20) #herb points
    points(distXsp[[wantEOR[match(want[i], wantEOR)]]][[4]]@coords, col="red", pch=16)

    }
}
  





```




```{r}
# Background points from set area, select number of background points equal to the number of presence points
bg <- list()
for(i in 1:length(wantEOR)){
  bg[[i]] <- as.data.frame(randomPoints(envs.backg[[i]][[1]], n=nrow(EORsxsp[[wantEOR[i]]]@coords)))
}

#Plot presence and background points
for(i in 1:length(wantEOR)){
  plot(envs.backg[[i]][[1]])
  plot(colocounties, add=TRUE)
  points(EORsxsp[[i]], pch=16, cex=0.5)
  points(bg[[i]], pch=21, cex=0.5, col="red")
  scalebar(100, type="line", divs = 4, below="kilometers", lonlat = TRUE)
}

#Try some thinning first, for some that's lots of points that are 

```

Partitioning occurrences for evalutaiton of models to reduce overinflated performace due to biased sampling/autocorrelation among points   
```{r}
#Block partitioning spatially by dividing the data into four bins based on their position in relation to a north/south and east/west partitioning that gets the points into nearly 4 equal size groups. 

#NEED to do this for the herbarium specemins too, not just the EORS!!!

blocks <- list()
for(i in 1:length(pointsXsp.latlon)){ #46 species with points
  blocks[[i]] <- get.block(pointsXsp.latlon[[i]]@coords, bg[[want[i]]])
  
  plot(envs.backg[[i]][[1]], col="gray", legend=FALSE)
  points(EORsxsp[[i]]@coords, pch=21, bg=blocks[[i]]$occ.grp) #In CRS("+proj=longlat +datum=WGS84"), grid points every 100 meters (map units which was UTM) within EOR polygons.
  points(pointsXsp.latlon[[i]])
  
}
```



