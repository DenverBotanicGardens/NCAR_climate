---
title: "R Notebook"
output: html_notebook
---

I think the outputs that don't have _EOR or _herb are the ones that used Herb to train and EOR to test. can see what the AUC patterns were for those. 
Making new herb train and EOR test ones with VisTrails and same size EOR numbers
```{r}
rm(list=ls())

library(ggplot2)
library(rgeos)
library(raster)
library(foreach)
library(parallel)
library(doParallel)

library(dismo)
library(rgeos)
library(Rmisc)



# Instead, load:
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_v3.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgHerb.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgEOR.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presvalsHerb.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presvalsEOR.Rda")


notnull <- which(!unlist(lapply(mapply('[[', distXsp_v3, 1), is.null)))
morethan12 <- c()
for(l in notnull){
  morethan12[match(l,notnull)] <- if(nrow(distXsp_v3[[l]][[1]]@coords)>12){ 
    l } else {
      NA
    }
}
morethan12 <- morethan12[!is.na(morethan12)]  


xEOR <- mapply('[[', distXsp_v3, 4)
EORcoords <- xEOR[!unlist(lapply(xEOR, is.null))]
notnullEOR <- which(!unlist(lapply(xEOR, is.null)))

template <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/PARC_COplus_slope25/COplus_slope50.tif")


# February 26, 2019 added _bioclim where I've resampled to the bioclim raster cell size (less than 1km)
# coplus50int.tif
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
# aspect50int.tif
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")

# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")

plot(coRugged_res)
bio1 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_01.tif")
bio12 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_12.tif")

bio1_res <- resample(bio1, coRugged_res, method="bilinear",
                     filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif", overwrite=TRUE)

bio12_res <- resample(bio12, coRugged_res, method="bilinear",
                      filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled.tif_bioclim", overwrite=TRUE)

# 
# bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled.tif")
# bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled.tif")
gc()

extent(bio1_res)
extent(coRugged_res)
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)


```

Get all the files that I'm making with VisTrails, then extract the information from the sets I want. Named similar runs the same way. 
```{r}
maxouts2 <- list.dirs(path = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/EORvHERB_2019/EORvHERB_2019",full.names = TRUE, recursive = TRUE)


#EORsamesize matches _Sp with the same number
# These all have k-fold of 5 so keeping out 20% each time to test but for some, too few points, so should compare to subsampling with replacement/bootstrapping 
EORsame <- maxouts2[grepl("_EORsamesize", maxouts2)]
speciesEOR <- unique(unlist(lapply(regmatches(EORsame, gregexpr("[[:digit:]]+", EORsame)),"[[", 3)))

# Must be an easier way but only want the first folder, don't want to dig in any deeper
EORsamesub <- EORsame[!grepl("Merged", EORsame)]
EORsamesub <- EORsamesub[!grepl("plots", EORsamesub)]
EORsamesub <- EORsamesub[!grepl("cvSplit", EORsamesub)]
EORsamesub <- EORsamesub[!grepl("Expanded", EORsamesub)]
EORsamesub <- EORsamesub[!grepl("responseCurves", EORsamesub)]

# The 9th layer is the folder for that Maxent output
unique(sapply(strsplit(EORsamesub,"/"), function(x){
  x[9]
}))

# Which species number is each? 
unique(sapply(strsplit(EORsame,"Sp"), function(x){
  as.numeric(gsub("([0-9]+).*$", "\\1", x[2]))
}))

# Split at the Sp, take that second string that starts with the species number and extract the first number
sapply(strsplit(EORsamesub, "Sp"), function(x){
  as.numeric(gsub("([0-9]+).*$", "\\1", x[2]))
})

# Where is the information about EOR size and distances to match to the names? 
AUCresults2 <- do.call(rbind,lapply(EORsamesub, function(x){
  resultfile <- read.csv(paste(x,"/maxentResults.csv", sep=""))
  resultfile$Species <- as.numeric(resultfile$Species)
  y <- strsplit(x,"Sp")
  resultfile$Species <- as.numeric(gsub("([0-9]+).*$", "\\1", y[[1]][2]))
  resultfile
}))

hist(AUCresults2$Training.AUC)

jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/AUC_EOR.jpg",
     width=200, height=175,units='mm', res=300)
hist(AUCresults2$Training.AUC, breaks = 10,
     main="",
     xlab="AUC")
dev.off()
```

Now get these rasters and see where the EOR differs from the Herb
```{r}
# Need to resample to the bioclim extent - more like 1 km than the 30 meters. or slightly larger that I've got it to.
bio1 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_01.tif")

coElev <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/coplus50int.tif")
coAspect <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/aspect50int.tif")
coSlope <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/COplus_slope50.tif")
coRugged <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/COplus_ruggedInt50.tif")

# Bioclim and DEMs are in coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
# toraster <- coElev
# bio1_UTM <- projectRaster(bio1, toraster, method = "bilinear",
#                           filename="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/bio1_UTM.tif")
# plot(bio1_UTM)
plot(bio1)

bio1crop <- crop(bio1_UTM, extent(coElev), filename="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/bio1crop.tif")
plot(bio1crop)

resample(coAspect, bio1crop, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")

resample(coSlope, bio1crop, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/SlopeResampled_bioclim.tif")

resample(coRugged, bio1crop, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")

# Get raster1 to match coElev, no go coElev to raster1
resample(coElev, bio1crop, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")



# Use the resampled one instead
# coElev <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/coplus50int.tif")
# coAspect <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/aspect50int.tif")
# coSlope <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/COplus_slope50.tif")
# coRugged <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/COplus_ruggedInt50.tif")

# x<-EORsamesub[[1]]
# raster1 <- raster(paste(x,"/Maxent_prob_map.tif", sep=""))

# resample(coAspect, raster1, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled.tif")
# 
# resample(coSlope, raster1, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/SlopeResampled.tif")
# 
# resample(coRugged, raster1, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled.tif")

# Get raster1 to match coElev, no go coElev to raster1
# resample(coElev, raster1, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled.tif")

# resample(coElev, raster1, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled.tif")

coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled.tif")

coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled.tif")

coSlope_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/SlopeResampled.tif")

coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled.tif")

# Function to calculate the linear model of one raster to another
# 1 would be the intercept I guess, while y are the values for y (from the resulting probability map)
# Don't quite get it
          # X <- cbind(1, y)
          # invXtX <- solve(t(X) %*% X) %*% t(X)
          # quickfun <- function(i) (invXtX %*% i)
          # # raster::calc calculates values for a new raster from another
          # m <- calc(s, quickfun) 
          # names(m) <- c('intercept', 'slope')
# r <- calc(s, fun)
# y <- values(raster1)
# X1 <- values(coElev)

# Could also ignore the not likely but that cuts off lots... maybe just the really near 0?
raster1sm <- raster1
raster1sm[raster1sm<0.05] <- NA

# But this is basically just what maxent does, right? but with a prior that is flat or 'maximizes entropy'?
s <- stack(raster1, coElev_res, coAspect_res, coSlope_res, coRugged_res)
# Make it a little smaller
v <- sampleRegular(s, 100000)  
v <- data.frame(na.omit(v))
variables <- names(v)
m <- lm(v[,1] ~ v[,2] + v[,3] + v[,4] + v[,5])
summary(m)
plot(v[,5],v[,1],
     xlab = names(v)[5],
     ylab = names(v)[1])
# I think I want to compare the EOR to climate and Herb and see if the slopes are different
# What do I really want to see? Maybe AIC if the model is different for Herb vs. EOR? That would be similar to loadings fo ra PCA? 
library(ks)
library(MASS)
?kde2d
plot(v[,1],v[,2])
contour(kde2d(v[,1], v[,2], lims = c(min(v[,1]), max(v[,1]),
                                     min(v[,2]), max(v[,2]))), 
        levels= c(min(v[,1]), max(v[,1]),
                                     min(v[,2]), max(v[,2])))

# X <- cbind(1, values(s))
# X <- cbind(1, as.matrix(v))
# invXtX <- solve(t(X) %*% X) %*% t(X)
# quickfun <- function(i) (invXtX %*% i)
# m <- quickfun(as.matrix(v))
# summary(m)

EORrasters <- lapply(EORsamesub, function(x){
  raster1 <- raster(paste(x,"/Maxent_prob_map.tif", sep=""))
  s <- stack(raster1, coElev_res, coAspect_res, coSlope_res, coRugged_res)
  v <- sampleRegular(s, 100000)  
  v <- data.frame(na.omit(v))
  variables <- names(v)
  m <- lm(v[,1] ~ v[,2])
  summary(m)
  plot(v[,2],v[,1])
  abline(m)
})

```



Now the herbarium specimens!
```{r}
# Compare to the Herb results
Herbsame <- maxouts2[grepl("Maxent_Sp", maxouts2)]
speciesHerb <- unique(unlist(lapply(regmatches(EORsame, gregexpr("[[:digit:]]+", EORsame)),"[[", 3)))
match(speciesHerb,speciesEOR)

# Must be an easier way but only want the first folder, don't want to dig in any deeper
Herbsamesub <- Herbsame[!grepl("Merged", Herbsame)]
Herbsamesub <- Herbsamesub[!grepl("plots", Herbsamesub)]
Herbsamesub <- Herbsamesub[!grepl("cvSplit", Herbsamesub)]
Herbsamesub <- Herbsamesub[!grepl("Expanded", Herbsamesub)]
Herbsamesub <- Herbsamesub[!grepl("responseCurves", Herbsamesub)]

# read.csv(paste(Herbsamesub[[5]],"/maxentResults.csv", sep=""))

AUClist <- lapply(Herbsamesub, function(x){
  resultfile <- read.csv(paste(x,"/maxentResults.csv", sep=""))
  resultfile$Species <- as.numeric(resultfile$Species)
  y <- strsplit(x,"Sp")
  resultfile$Species <- as.numeric(gsub("([0-9]+).*$", "\\1", y[[1]][2]))
  resultfile
})


# Go back and see if can run those without threshold and such so they're the same. 
# don't want 5, 7, 10
AUCresults3 <- do.call(rbind,lapply(c(1:4,6,8:9,11:14), function(x){
  AUClist[[x]]
}))


# AUCresults3 <- do.call(rbind,lapply(Herbsamesub, function(x){
#   read.csv(paste(x,"/maxentResults.csv", sep=""))
# }))

hist(AUCresults3$Training.AUC)

jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/AUC_Herb.jpg",
     width=200, height=175,units='mm', res=300)
hist(AUCresults3$Training.AUC, breaks = 10,
     main="",
     xlab="AUC")
dev.off()
# TestEOR_ only want one per species, manually go in and delete extras that had mishaps

```

If i can get more, add 'em up
```{r}



jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/AUC_EORandHerb.jpg",
     width=400, height=175,units='mm', res=300)

layout(matrix(c(1,2), 1,2, byrow=FALSE),
             width=c(6,6), height=c(1))
hist(AUCresults2$Training.AUC, breaks = 10,
     main="EOR",
     xlab="AUC")

hist(AUCresults3$Training.AUC, breaks = 10,
     main="Herbarium",
     xlab="AUC")

dev.off()


hist(AUCresults2$Training.AUC, breaks=15, col=rgb(1,0,0,0.5),
     main="Red is EOR; Blue is Herb")  
hist(AUCresults3$Training.AUC, add=TRUE,breaks=15, col=rgb(0,0,1,0.5))

```

# Rounds of VisTrails with elevation: coplus50int; aspect: aspect50int; ruggedness: COplus_ruggedInt50; annual temp Bio1 and annual precip Bio12 

Name the EOR ones as EORSp1... and compare   
<https://gis.stackexchange.com/questions/29118/how-to-find-the-average-raster-value-of-an-area-defined-by-a-shapefile-using-r> 
```{r}
dirs.vistrails <- list.dirs(path = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/EORvHERB_2019/EORvHERB_2019",full.names = TRUE, recursive = TRUE) 

dirs.vistrails[grep("_Sp",dirs.vistrails)]


```


# Maxent 
# VisTrails stopped working, error in making the probability maps so trying here
```{r}
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/pca_data.Rda")


# linkspeciesnumber <- do.call(rbind,lapply(1:length(pca_data), function(x){
#   data.frame(SpNum = x, Species = unique(pca_data[[x]]$GNAME[pca_data[[x]]$pa==3]),
#              Dist = pca_data[[x]]$dist[pca_data[[x]]$pa==2], # pa==2 are herb
#              SpeciesArea = unique(pca_data[[x]]$area[pca_data[[x]]$pa==1]))
# }))
# 
# x <- mapply('[[', distXsp_v3, 1)
# Herbcoords <- x[!unlist(lapply(x, is.null))]
# notnull <- which(!unlist(lapply(x, is.null)))



linkspeciesnumber <- do.call(rbind,lapply(notnull, function(x){
  data.frame(Species = distXsp_v3[[x]][[1]]@data$scientificName[1], Dist = distXsp_v3[[x]][[2]],
             Area = sum(distXsp_v3[[x]][[3]]), SpNum = x, Year=distXsp_v3[[x]][[1]]@data$year,
             distXsp_v3[[x]][[1]]@coords)
}))

Years <- (as.numeric(gsub("([0-9]+).*$", "\\1", linkspeciesnumber$Year)))
linkspeciesnumber$Year <- as.numeric(as.character(linkspeciesnumber$Year))
linkspeciesnumber$Year <- Years
hist(linkspeciesnumber$Year)

ggplot(linkspeciesnumber, aes(Area, log(Dist)))+
  geom_point()+
  stat_smooth(method="lm")+
  ylab("Distance (log(meters))")+
  theme_bw()

plot(log(linkspeciesnumber$Area+1),log(linkspeciesnumber$Dist+1),
     xlab=expression(paste("Species Range log(meters" ^2,")" )),
     ylab=expression(paste("log (meters)")))
abline(lm(log(Dist+1)~log(Area+1), data=linkspeciesnumber))

length(unique(linkspeciesnumber$SpNum))
length(morethan12) # minus 1 for the Boechera missing EOR

max(linkspeciesnumber$Dist)

linkspeciesnumber$Dist[linkspeciesnumber$SpNum==12]
# Current Figure 2: see Herb to EORs_v4.Rmd 
# Removing largest distance that would put the point 3155 miles away, Colorado is 380 miles wide
# The second furthest is 668 miles away from somewhere in Colorado, that's outside of colorado
# The three furthest couldn't fall within Colroado so are removed  
# hypotenuse of colroado is about 472 miles, the third point is 406 miles from nearest EOR
```
Table 1 - species in niche models, put a column indiciating which are SDM
```{r}

out <- Rmisc::summarySE(linkspeciesnumber, "Dist", "SpNum")

tab1 <- do.call(rbind, lapply(split(linkspeciesnumber, linkspeciesnumber$SpNum), function(x){
  data.frame(SpNum = unique(x$SpNum), Species = x$Species[1], DistAvg = summarySE(x, "Dist"), 
             Area = unique(x$Area),
             MinYear = min(x$Year), MaxYear = max(x$Year), AvgLat = summarySE(x, "decimalLatitude"))
})) 

write.csv(tab1, "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/table1.csv")
library(Taxonstand)
TPLtbl1 <- TPL(tab1$Species)
write.csv(TPLtbl1, "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/TPLtbl1.csv")

```


```{r}
jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/Figure2.jpg",
     width=225, height=105,units='mm', res=300)

smallerthan <- sort(linkspeciesnumber$Dist)[length(linkspeciesnumber$Dist)-2]

layout(matrix(c(1,2), 1,2))

plot(linkspeciesnumber$Area[linkspeciesnumber$Dist<smallerthan],
     linkspeciesnumber$Dist[linkspeciesnumber$Dist<smallerthan],
     xlab=expression(paste("Species Range km" ^2)),
     ylab=expression(paste("km")),
     pch=16, cex= .5, yaxt="n", xaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
     axis(1, at=c(0,10,20,30,40,50,60,70,80,90)*(1000^2), labels=c(0,10,20,30,40,50,60,70,80,90))
abline(lm(Dist~Area, data=linkspeciesnumber[linkspeciesnumber$Dist<smallerthan,]))
mtext("a)", side=3, line=0, adj=0)

plot(jitter(linkspeciesnumber$Year[linkspeciesnumber$Dist<smallerthan]),
     linkspeciesnumber$Dist[linkspeciesnumber$Dist<smallerthan],
     xlab="Year",
     ylab="",
     pch=16, cex= .25, yaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
abline(lm(Dist~Year, data=linkspeciesnumber[linkspeciesnumber$Dist<smallerthan,]))
mtext("b)", side=3, line=0, adj=0)


dev.off()

```


The EOR AUC results from VisTrails, samesize runs from ForVisTrails.Rmd where I either thinned to match number of Herbarium records or where I bootstrapped and jittered to get matching points. Used a standalone Dan Warren thinning process to get equally spaced out but covering the most area (of information) for points.
```{r}
 
# 2 is EORs, .x; 3 is Herbs, .y
EORmaxentdata <- merge(linkspeciesnumber, AUCresults2[,c(1:2,5:7)], by.x = "SpNum", by.y = "Species")
EORxHarbymaxentdata <- merge(EORmaxentdata, AUCresults3[,c(1:2,5:7)], by.x = "SpNum", by.y = "Species")

avgDist <- aggregate(EORmaxentdata$Dist, list(EORmaxentdata$SpNum), mean) 
sdDist <- aggregate(EORmaxentdata$Dist, list(EORmaxentdata$SpNum), sd) 
EORsummarymaxent <- merge(unique(linkspeciesnumber), AUCresults2, by.x = "SpNum", by.y = "Species")

summary(lm(Training.AUC ~ Dist,data = EORmaxentdata))

ggplot(EORmaxentdata, aes(Area, Training.AUC))+
  geom_point()+
  stat_smooth(method="lm")+
  theme_bw()

ggplot(EORmaxentdata, aes(log(Dist), Training.AUC))+
  geom_point()+
  stat_smooth(method="lm")+
  theme_bw()

ggplot(EORmaxentdata, aes(as.factor(Training.AUC), log(Dist)))+
  geom_boxplot(outlier.shape=NA) + #avoid plotting outliers twice
  geom_jitter(position=position_jitter(width=.1, height=0))

ggplot(EORmaxentdata, aes(as.factor(Training.AUC), Area))+
  geom_boxplot(outlier.shape=NA) + #avoid plotting outliers twice
  geom_jitter(position=position_jitter(width=.1, height=0))

EORHERBarea <- unique(EORxHarbymaxentdata[,-3])

# Red is EOR, Blue is Herb

plot(log(EORHERBarea$Area), EORHERBarea$Training.AUC.x, col="red",pch=16,
     ylim=c(0.55,.95))
points(log(EORHERBarea$Area), EORHERBarea$Training.AUC.y, col="blue", pch=4)


jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/AUCxSampleSizeandArea.jpg",
     width=250, height=175,units='mm', res=300)
plot(EORHERBarea$X.Training.samples.x, EORHERBarea$Training.AUC.x, col="red",pch=16,
     ylim=c(0.55,.95), cex=round(log(EORHERBarea$Area)-11,0),
     xlab="Training sample size",
     ylab="AUC")
points(EORHERBarea$X.Training.samples.x, EORHERBarea$Training.AUC.y, col="blue", pch=16,
       cex = round(log(EORHERBarea$Area)-11,0))
dev.off()

```


Want to add vegetation types, layer too. should work now that I've got all the other layers a better size
# Loaded these up top
Make maxent commands
for output prediction map, use ENMeval   
Using KDE at 95% in MAxent VisTrails which mostly makes it so that it appears there's less effort in areas with fewer points but might not be the case, just might be smaller popualtions so maybe just circles with a certain radius would be better. Maybe add some points along roads for circles. Could put points along roads and then first pick points along roads within a certain distance from presence points and then 'circles' around all those points ?  
follow https://rspatial.org/sdm/SDM.pdf while VisTrails isnt' working
```{r}
# tested in Herb to EORs_v4

# library(adehabitatHR)
# library(ks)

#Ah ha! so many errors for kernel size, so switch to circles
# bgHerbKDE <- lapply(notnull, function(x){
#   xy <- data.frame(distXsp_v3[[x]][[1]]@coords)
#   names(xy) <- c("X","Y")
#   xy <- SpatialPoints(xy)
#   ud <- kernelUD(xy, extent=0.5, grid=150)
#   ver <- getverticeshr(ud, 80)
#   # just put random points for background points witin the kernelUD 
#   spsample(ver, 300, "stratified")
#   })
# 
# x <- mapply('[[', distXsp_v3, 1)
# Herbcoords <- x[!unlist(lapply(x, is.null))]
# notnull <- which(!unlist(lapply(x, is.null)))
# 
# xEOR <- mapply('[[', distXsp_v3, 4)
# EORcoords <- xEOR[!unlist(lapply(xEOR, is.null))]
# notnullEOR <- which(!unlist(lapply(xEOR, is.null)))

setdiff(notnull,notnullEOR) # 8 is naughty, who is 8?
distXsp_v3[[8]][[1]]@data$scientificName # Boechera glareosa, where did you go?! Boechera gunnisoniana? 

class(distXsp_v3[[1]][[1]])
#Background points, in a 5km circle around presence points, 300 stratified across the circles. Not quite the KDE but if I combined other collections from same trip I think that would be a correct estimator, circles represent the posibility that folks hiked 3 miles on their collection trip, seems likely enough. 

bgHerb <- lapply(notnull, function(x){
  circles <- circles(distXsp_v3[[x]][[1]], d = 5000) #Should be 5km around
  polygns <- polygons(circles)
  bg <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
  # do I want to get just one per cell? I'm gonna skip cellFromXY(mask, bg) # where mask should be my one used to set the size and clip the others in vistrails
  bg
  })
save(bgHerb, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgHerb.Rda")

# I know which they are, in order they are notnullEOR
bgEOR <- lapply(notnullEOR, function(x){
  df <- distXsp_v3[[x]][[4]]
  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  circles <- circles(df, d = 5000) #Should be 5km around
  polygns <- polygons(circles)
  bg <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
  # do I want to get just one per cell? I'm gonna skip cellFromXY(mask, bg) # where mask should be my one used to set the size and clip the others in vistrails
  bg
  })
save(bgEOR, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgEOR.Rda")

names(presvalsEOR[[1]])

```

Extract values from rasters
```{r}

template <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/PARC_COplus_slope25/COplus_slope50.tif")


# coplus50int.tif
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled.tif")
# aspect50int.tif
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled.tif")
# coSlope_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/SlopeResampled.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled.tif")
# bio1 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_01.tif")
# bio12 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_12.tif")

#before resampled to the output Maxent probability map based on template (should be able to do template but it doesn't work...)
resample(bio1, coElev_res, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled.tif", overwrite=TRUE)
resample(bio12, coElev_res, method="bilinear", filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled.tif", overwrite=TRUE)



bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled.tif")


rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)

presvalsHerb <- lapply(notnull, function(x){
  convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
  dfp <- data.frame(pb = 1, extract(rasterstack, convertxy),
                    x1 = convertxy@coords[,1],x2 = convertxy@coords[,2])
  back <- bgHerb[[match(x,notnull)]]
  proj4string(back) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
  convertback <-spTransform(back, CRS("+proj=longlat +datum=WGS84"))
  dfb <- data.frame(pb = 0, extract(rasterstack, convertback),convertback@coords)
  rbind(dfp,dfb)
})

save(presvalsHerb, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presvalsHerb.Rda")


table(presvalsHerb[[4]]$pb)

presvalsEOR <- lapply(notnullEOR, function(x){
  df <- distXsp_v3[[x]][[4]]
  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  convertEOR <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
  dfp <- data.frame(pb = 1, extract(rasterstack, convertEOR))
  back <- bgEOR[[match(x,notnullEOR)]]
  proj4string(back) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
  convertback <-spTransform(back, CRS("+proj=longlat +datum=WGS84"))
  dfb <- data.frame(pb = 0, extract(rasterstack, convertback))
  rbind(dfp,dfb)
})

save(presvalsEOR, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presvalsEOR.Rda")


presvalsEORonly <- lapply(notnullEOR, function(x){
  df <- distXsp_v3[[x]][[4]]
  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  convertEOR <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
  dfp <- data.frame(pb = 1,  x1 = convertEOR@coords[,1],x2 = convertEOR@coords[,2])
  back <- bgEOR[[match(x,notnullEOR)]]
  proj4string(back) <- CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
  convertback <-spTransform(back, CRS("+proj=longlat +datum=WGS84"))
  dfb <- data.frame(pb = 0, convertback@coords)
  rbind(dfp,dfb)
})

#Still not same number of records! how, why, why!?!?
for(i in notnull){
  print(paste(i,paste(distXsp_v3[[i]][[1]]@data$scientificName[1])))
  print(table(presvalsHerb[[match(i,notnull)]]$pb))
  print(table(presvalsEOR[[match(i,notnullEOR )]]$pb))
}

#Could sample again to get same number of records for presence and absence for each
jar <- paste(system.file(package="dismo"), "/java/maxent.jar", sep='')

x<-1
convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
xm <- maxent(rasterstack,convertxy[convertxy$kfold!=1,])
bgpnts <- bgHerb[[1]]
proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
## Loading required namespace: rJava
# plot(xm)
# response(xm)

 # evaluate(pres_test, backg_test, bc, pred_nf)
nrow(convertxy[convertxy$kfold==1,])
nrow(convertxy[convertxy$kfold!=1,])

e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, rasterstack)
ext <- extent(template)
gc()
predict(rasterstack, xm, ext=ext, progress='', filename = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Predict1.tif", )
par(mfrow=c(1,2))
plot(px, main='Maxent, raw values')
plot(wrld_simpl, add=TRUE, border='dark grey')


library(foreach)
library(parallel)
library(doParallel)
#register parallel computing backend
ncores=10
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl,ncores)

#compute indices for data splitting
rows = 1:nrow(rasterstack)
split = sort(rows%%ncores)+1

outname = "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Predict1"

#perform the prediction on subsets of the predictor dataset
prediction = foreach(i=unique(split), .combine=c)%dopar%{
  rows_sub = rows[split==i]
  sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                               1, ncol(rasterstack)))
  raster::predict(sub, xm, filename=paste(outname, i, sep="_"))
}

gc()
ext
template <- raster(ext)
projection(template) <- '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'
writeRaster(template, file="Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Predictall", format="GTiff")

# get all these files we made
pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/"

resultpath <- list.files(path = pathstart, pattern = "Predict1" , full.names = TRUE) #[[1]]

x <- lapply(resultpath, function(x){
  raster(x)
})
# x <- list(r1, r2)
x$filename <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictAll1.tif"
x$overwrite <- TRUE
m <- do.call(merge, x)

plot(m)

```


## Herbarium specimens
```{r}


#Could sample again to get same number of records for presence and absence for each
jar <- paste(system.file(package="dismo"), "/java/maxent.jar", sep='')

ncores=10
cl = parallel::makeCluster(ncores)
ext <- extent(bio1_res)

    
  
for(x in morethan12[-1]){
  set.seed(1234)
    convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
    convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
    xm <- maxent(rasterstack,convertxy[convertxy$kfold!=1,])
    save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/maxentSp",x,".Rda", sep=""))
   
    gc()
    
    #register parallel computing backend
    cl = parallel::makeCluster(ncores)
    doParallel::registerDoParallel(cl,ncores)
    #compute indices for data splitting
    rows = 1:nrow(rasterstack)
    split = sort(rows%%ncores)+1
    outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Predict", x, sep="")
    #perform the prediction on subsets of the predictor dataset
    prediction <- foreach(i=unique(split), .combine=c)%dopar%{
      rows_sub = rows[split==i]
      sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                    1, ncol(rasterstack)))
      raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
    }
    rm(xm)
    gc()
    stopCluster(cl)
    # template <- raster(ext)
    # projection(template) <- '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'
    # writeRaster(template, file=paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Predictall",x,sep=""), format="GTiff")
    # # get all these files we made
    # pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/"
    # resultpath <- list.files(path = pathstart, pattern = paste("Predict",x,sep="") , full.names = TRUE) #[[1]]
    # xout <- lapply(resultpath, function(y){
    #   raster(y)
    #   })
    # 
    # xout$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/Predictall",x,".tif", sep="")
    # xout$overwrite <- TRUE
    # m <- do.call(merge, xout)
  }





```


EOR make maxent models and 10 strips per each probablility map
```{r}

ncores=10
cl = parallel::makeCluster(ncores)
ext <- extent(bio1_res)

# 1 through Sp34 worked but then computer restarted
# morethan12[morethan12!=8]
# morethan12[morethan12>34]

for(x in morethan12[morethan12!=8]){
  set.seed(1234)
  sampleto <- nrow(distXsp_v3[[x]][[1]]@coords)
  df <- distXsp_v3[[x]][[4]]
  # There is one species that there are no EORs mapped and one that results in fewer points that for Herbarium specimens
  if(  table(presvalsHerb[[match(x,notnull)]]$pb)[2]>
       table(presvalsEOR[[match(x,notnullEOR )]]$pb)[2]){
    df <- df[sample(nrow(df), sampleto, replace = TRUE), ]
  } else {
    df <- df[sample(nrow(df), sampleto), ]
       }
  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  convertEOR <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
  convertEOR$kfold <- kfold(convertEOR, k=4) # to have 75:25%
  
  xm <- maxent(rasterstack,convertEOR[convertEOR$kfold!=1,])
  save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/maxentEORSp",x,".Rda", sep=""))
  gc()
  
  #register parallel computing backend
    cl = parallel::makeCluster(ncores)
    doParallel::registerDoParallel(cl,ncores)
    #compute indices for data splitting
    rows = 1:nrow(rasterstack)
    split = sort(rows%%ncores)+1
    outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictEOR", x, sep="")
    #perform the prediction on subsets of the predictor dataset
    prediction <- foreach(i=unique(split), .combine=c)%dopar%{
      rows_sub = rows[split==i]
      sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                    1, ncol(rasterstack)))
      raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
    }
    rm(xm)
    gc()
    stopCluster(cl)
   
  }





```


## Herbarium specimen dataset
Now grab all the maxent models and get the predict and evalute data from them      
Crap, set seed not in there so the background group might be different than it was first, crap crap
I think each maxent model took about 45 minutes 
```{r}

notnull
morethan12

lapply(morethan12, function(x){
    set.seed(1234)
    convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
    convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
    # xm <- maxent(rasterstack,convertxy[convertxy$kfold!=1,])
    load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/maxentSp",x,".Rda", sep=""))
    gc()
    bgpnts <- bgHerb[[match(x,notnull)]]
    proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
    bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
    e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, rasterstack)
    save(e, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/evaluateSp",x,".Rda", sep=""))
    e
    })

# Looks good! matches!
# for(i in morethan12){
#   foo <- spTransform(distXsp_v3[[i]][[1]], CRS("+proj=longlat +datum=WGS84"))
#   foobgpnts <- bgHerb[[match(i,notnull)]]
#   proj4string(foobgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
#   foobgpnts <- spTransform(foobgpnts, CRS("+init=epsg:4326") )
#   plot(foobgpnts, pch=20, col="green", cex=2)
#   plot(foo, add=TRUE, col="blue", cex=0.5)
# }

    
```



# EOR dataset    
Now grab all the maxent models and get the predict and evalute data from them  
```{r}
# They match, all looks good

# for(i in morethan12[morethan12!=8]){
#   fooEORxy <- distXsp_v3[[i]][[4]]
#   coordinates(fooEORxy) <- ~ x + y
#   proj4string(fooEORxy) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
#   fooEORxy <- spTransform(fooEORxy, CRS("+proj=longlat +datum=WGS84"))
#   
#   foobgpnts <- bgEOR[[match(i,notnullEOR)]]
#     proj4string(foobgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
#     foobgpnts <- spTransform(foobgpnts, CRS("+init=epsg:4326") )
#   plot(foobgpnts, pch=20, col="green", cex=2)
#   plot(fooEORxy, add=TRUE, col="blue", cex=0.5)
# }


lapply(morethan12[morethan12!=8], function(x){
    set.seed(1234)
  sampleto <- nrow(distXsp_v3[[x]][[1]]@coords)
    df <- distXsp_v3[[x]][[4]]
    # There is one species that there are no EORs mapped and one that results in fewer points that for Herbarium specimens
    if(  table(presvalsHerb[[match(x,notnull)]]$pb)[2]>
         table(presvalsEOR[[match(x,notnullEOR )]]$pb)[2]){
      df <- df[sample(nrow(df), sampleto, replace = TRUE), ]
    } else {
      df <- df[sample(nrow(df), sampleto), ]
         }
    coordinates(df) <- ~x+y
    proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
    convertEOR <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
    convertEOR$kfold <- kfold(convertEOR, k=4) # to have 75:25%
    load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/maxentEORSp",x,".Rda", sep=""))
    gc()
    bgpnts <- bgEOR[[match(x,notnullEOR)]]
    proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
    bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
    e <- evaluate(convertEOR[convertEOR$kfold==1,], bgpnts, xm, rasterstack)
    save(e, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/evaluateEORSp",x,".Rda", sep=""))
    e
    })

    
```

# Herbarium
```{r}

evaluations <- do.call(rbind,lapply(morethan12, function(x) {
  load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/evaluateSp",x,".Rda", sep=""))
  out <- data.frame(SpNum = x, AUC = e@auc)
  out
})
)

hist(evaluations$AUC)
```

#CNHP/EOR
```{r}

evaluationsEOR <- do.call(rbind,lapply(morethan12[morethan12!=8], function(x) {
  load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/evaluateEORSp",x,".Rda", sep=""))
  out <- data.frame(SpNum = x, AUC = e@auc)
  out
})
)


hist(evaluationsEOR$AUC, col=rgb(0,0,0,0.25), breaks=10, xlim=c(0,1),ylim=c(0,6)) #black
hist(evaluations$AUC, col=rgb(1,0,0,0.25), breaks=10,add=TRUE) # red


hist(evaluationsEOR$AUC - evaluations$AUC[evaluations$SpNum!=8], breaks=10)

evaluations;evaluationsEOR
match(evaluations$SpNum,evaluationsEOR$SpNum)

plotAUCmerge <- merge(evaluations, evaluationsEOR, by = "SpNum")
plotAUCmerge$AUC.diff <- plotAUCmerge$AUC.y - plotAUCmerge$AUC.x


plotAUCdf <- rbind(data.frame(Dataset = "Herb", evaluations[evaluations$SpNum!=8]),
                   data.frame(Dataset = "CNHP", evaluationsEOR))


# presvalsHerb are in order of notnull
pres4ssb <-lapply(morethan12, function(x){
  set.seed(1234)
  press <- presvalsHerb[[match(x,notnull)]][presvalsHerb[[match(x,notnull)]]$pb==1,]
  press$kfold <- kfold(press, k=4)
  back <-  presvalsHerb[[match(x,notnull)]][presvalsHerb[[match(x,notnull)]]$pb==0,]
  back$kfold <- kfold(back, k=4)
  out <- rbind(press,back)
  out
})

pres4ssb[[1]]

# sb <- ssb(pres_test, back_test, pres_train)
ssb.herb <- lapply(pres4ssb, function(x){
  out <- ssb(x[x$kfold==1&x$pb==1,c("x1","x2")], x[x$kfold==1&x$pb==0,c("x1","x2")],
             x[x$kfold!=1&x$pb==1,c("x1","x2")])
  out
})


# # an index of spatial sorting bias (1 is no bias, near 0 is extreme bias)
biases <- unlist(lapply(ssb.herb, function(x){
  x[1]/x[2]
}))

hist(biases, breaks=20)

ssb.herb[[1]][1] / ssb.herb[[1]][2]


```

```{r}

jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/Figure4.jpg",
     width=200, height=175,units='mm', res=300)

hist(plotAUCmerge$AUC.diff, breaks=10, xlab=expression("AUC"["CNHP - Herb"]), main="")

dev.off()


```


# Herbarium dataset

# make all the rasters from the 10 strips
```{r}

ext <- extent(template)

for(x in morethan12){
    template <- raster(ext)
    projection(template) <- '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'
    writeRaster(template, file=paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictallSp",x,sep=""), format="GTiff", overwrite=TRUE)
    # get all these files we made
    pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/"
    resultpath <- list.files(path = pathstart, pattern = paste("Predict",x,sep="") , full.names = TRUE) #[[1]]
    xout <- lapply(resultpath, function(y){
      raster(y)
      })
    
    xout$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictallSp",x,".tif", sep="")
    xout$overwrite <- TRUE
    m <- do.call(merge, xout)
}
```


# make all the EOR rasters from the 10 strips

# EOR dataset
```{r}

ext <- extent(template)

for(x in morethan12[morethan12!=8]){
    template <- raster(ext)
    projection(template) <- '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'
    writeRaster(template, file=paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictallEORSp",x,sep=""), format="GTiff", overwrite=TRUE)
    # get all these files we made
    pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/"
    resultpath <- list.files(path = pathstart, pattern = paste("PredictEOR",x,sep="") , full.names = TRUE) #[[1]]
    xout <- lapply(resultpath, function(y){
      raster(y)
      })
    
    xout$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictallEORSp",x,".tif", sep="")
    xout$overwrite <- TRUE
    m <- do.call(merge, xout)
}
```


Examine the maps
```{r}
sp1 <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/PredictallSp1.tif")

plot(sp1, main=distXsp_v3[[1]][[1]]$scientificName[1])
```


Why dont' have at least the number of points for EORs that have for Herb in some of them? 
```{r}
thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}


load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2names.Rda")
library(maptools)
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")

l1G1G2 <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2"),])
l1G1G2$PolyID <- do.call(rbind, lapply(split(l1G1G2,l1G1G2$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))
coloradosps <- read.csv("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/SEINET G1 G2 Vouchers/occurrences.csv")
rowstomatch <- lapply(c("Taxon","AcceptedName"), function(x){
   coloradosps[,"scientificName"] %in%  g1g2names[,x]
})

coloradosps.g1g2 <- unique(rbind(coloradosps[rowstomatch[[1]],],coloradosps[rowstomatch[[2]],]))
coloradosps.g1g2$decimalLatitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLatitude))
coloradosps.g1g2$decimalLongitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLongitude))
coloradosps.g1g2$lon2 <- round(coloradosps.g1g2$decimalLongitude,2) # about 1.1 km 
coloradosps.g1g2$lat2 <- round(coloradosps.g1g2$decimalLatitude,2)
coloradosps.g1g2$lon3 <- round(coloradosps.g1g2$decimalLongitude,3) # about 110 m
coloradosps.g1g2$lat3 <- round(coloradosps.g1g2$decimalLatitude,3)

     library(splancs)
```


```{r}
i<-notnullEOR[2]

presenceEORpoints <- lapply(notnullEOR, function(i){
  g1g2now <- coloradosps.g1g2[coloradosps.g1g2$scientificName %in%
                                c(g1g2names$Taxon[i],g1g2names$AcceptedName[i])&
                                !is.na(coloradosps.g1g2$decimalLatitude),]
  
  g1g2now <- g1g2now[as.numeric(as.character(g1g2now$year))>1980,]
  g1g2now <- g1g2now[g1g2now$decimalLatitude>0,]
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)]
  
  
   polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                        g1g2names$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
    # years <- format(as.Date(polys$LASTOBS, format="%Y-%m-%d"),"%Y")
    years <- as.numeric(substring(polys$LASTOBS,1,4))
    yearlater1979 <- c()
    for(l in 1:length(years)){
      yearlater1979[l] <- if(years[l]>1979){ 
                                      l } else {
                                        NA
                                      }
    }
    yearlater1979 <- yearlater1979[!is.na(yearlater1979)] 
    
    polys <- polys[yearlater1979,]
    
    totalarea <- sum(area((polys)))
  # area of each polygon
    areanow <- sapply(slot(polys,"polygons"), slot, "area")
  # Proportional area to the whole area number to thin
    EORpnts <- do.call(rbind, lapply(1:length(polys), function(f){
      outline <- polys@polygons[[f]]@Polygons[[1]]@coords
      grid <- makegrid(polys, cellsize = 50) # cellsize in map units!
      names(grid) <- c("x","y")
      gridout <- grid[inout(grid,outline), ]
      if(nrow(gridout)>1){
        gridthin <- thin.max(gridout,c("x","y"),(round(nrow(g1g2now)*(areanow[[f]]/totalarea),0))+1)
        gc()
        } else {
          if(nrow(gridout)>0) {
            gridthin <- gridout 
          } else {
            gridthin <- NULL
          }
          }
      gridthin
      }))
    gc()
    EORpnts
})

save(presenceEORpoints, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presenceEORpoints.Rda")


yearsofPolys <- lapply(notnullEOR, function(i){
    polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                        g1g2names$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    years <- format(as.Date(polys$LASTOBS, format="%Y-%m-%d"),"%Y")
    yearlater1979 <- c()
    for(l in 1:length(years)){
      yearlater1979[l] <- if(years[l]>1979){ 
        l } else {
          NA
        }
    }
    yearlater1979 <- yearlater1979[!is.na(yearlater1979)]  
    table(years[which(years>1979)])
})

for(d in 1:length(yearsofPolys)){
  print(yearsofPolys[[d]])
}



rm(l1eor,l1G1G2,g1g2names,coloradosps,coloradosps.g1g2)
save(presenceEORpoints, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presenceEORpoints.Rda")

notnull

```

```{r}
#Could sample again to get same number of records for presence and absence for each
jar <- paste(system.file(package="dismo"), "/java/maxent.jar", sep='')
ncores=10
    
# should be able to do the ones that are 12 too!

notnull <- which(!unlist(lapply(mapply('[[', distXsp_v3, 1), is.null)))
atleast12 <- c()
for(l in notnull){
  atleast12[match(l,notnull)] <- if(nrow(distXsp_v3[[l]][[1]]@coords)>11){ 
    l } else {
      NA
    }
}
atleast12 <- atleast12[!is.na(atleast12)] 
length(atleast12) # 28 vs. 24 over 12

# coplus50int.tif
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled.tif")
# aspect50int.tif
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled.tif")
bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled.tif")
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)
rm(l, coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)


# need to come back and do atleast12[4] with kfold==4; atleast12[-c(1:5)]

for(x in atleast12[5]){
      # To keep kfold same over all loops
      set.seed(1234)
        convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
        convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
  for(rep in 4){  
        xm <- maxent(rasterstack,convertxy[convertxy$kfold!=rep,])
        save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/maxentSp",x,"kfold",rep,".Rda", sep=""))        

        gc()
        
        #register parallel computing backend
        cl = parallel::makeCluster(ncores)
        doParallel::registerDoParallel(cl,ncores)
        #compute indices for data splitting
        rows = 1:nrow(rasterstack)
        split = sort(rows%%ncores)+1
        outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/Predict", x,"kfold",rep, sep="")
        #perform the prediction on subsets of the predictor dataset
        foreach(i=unique(split), .combine=c)%dopar%{
          rows_sub = rows[split==i]
          sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                        1, ncol(rasterstack)))
          raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
        }
        rm(xm)
        gc()
        stopCluster(cl)
  }
}



```

EOR removing each of the four kfolds one at a time replicates   
```{r}
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presenceEORpoints.Rda")
length(presenceEORpoints)
length(atleast12[atleast12!=8])

xEOR <- mapply('[[', distXsp_v3, 4)
EORcoords <- xEOR[!unlist(lapply(xEOR, is.null))]
notnullEOR <- which(!unlist(lapply(xEOR, is.null)))
notnullEOR

presenceEORpoints[[match(atleast12[4],notnullEOR)]]

library(rgdal)
colocounties.UTM <- readOGR(dsn="Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/Colorado/CO_Counties", layer="counties")

# Yes, these match up even though the first is pretty different, not many mapped where herb specimens are
for(x in atleast12[atleast12!=8]){
  plot(colocounties.UTM, main = paste("Species",x))
  points(distXsp_v3[[x]][[1]]@coords, col="red", pch=16)
  points(presenceEORpoints[[match(x,notnullEOR)]],col="blue")
}

# presenceEORpoints are spread out proportional to the area of each polygon to total species area
# atleast12[atleast12!=8]
# Should exclude 41, issues with the EOR mapped occurences!!!

for(x in atleast12[c(2,4:28)]){
  sampleto <- nrow(distXsp_v3[[x]][[1]]@coords)
  df <- presenceEORpoints[[match(x,notnullEOR)]]
  if(nrow(df)>sampleto){
    df <- df[sample(1:nrow(df),sampleto),] # sample without replacement
  } else {
    df <- df[sample(1:nrow(df),sampleto, replace = TRUE),] 
  }

  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  convertEOR <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
  
      # To keep kfold same over all loops
      set.seed(1234)
      
  convertEOR$kfold <- kfold(convertEOR, k=4) # to have 75:25%
  
  for(rep in 1:4){  
        xm <- maxent(rasterstack,convertxy[convertxy$kfold!=rep,])
        save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/maxentEORSp",x,"kfold",rep,".Rda", sep=""))        

        gc()
        
        #register parallel computing backend
        cl = parallel::makeCluster(ncores)
        doParallel::registerDoParallel(cl,ncores)
        #compute indices for data splitting
        rows = 1:nrow(rasterstack)
        split = sort(rows%%ncores)+1
        outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEntReplicates/PredictEOR", x,"kfold",rep, sep="")
        #perform the prediction on subsets of the predictor dataset
        foreach(i=unique(split), .combine=c)%dopar%{
          rows_sub = rows[split==i]
          sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                        1, ncol(rasterstack)))
          raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
        }
        rm(xm)
        gc()
        stopCluster(cl)
  }
}

```




PCA for how different
```{r}



```
