---
title: "R Notebook"
output: html_notebook
---

Ignore blocks with 'morethan12' and skip to atleast12

I think the outputs that don't have _EOR or _herb are the ones that used Herb to train and EOR to test. can see what the AUC patterns were for those. 
Making new herb train and EOR test ones with VisTrails and same size EOR numbers
```{r}
rm(list=ls())

library(ggplot2)
library(rgeos)
library(raster)
library(foreach)
library(parallel)
library(doParallel)


library(dismo)
library(Rmisc)
library(rgdal)
library(ENMeval)



# Instead, load:
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_v3.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgHerb.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgEOR.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presvalsHerb.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presvalsEOR.Rda")


notnull <- which(!unlist(lapply(mapply('[[', distXsp_v3, 1), is.null)))
morethan12 <- c()
for(l in notnull){
  morethan12[match(l,notnull)] <- if(nrow(distXsp_v3[[l]][[1]]@coords)>12){ 
    l } else {
      NA
    }
}
morethan12 <- morethan12[!is.na(morethan12)]  


xEOR <- mapply('[[', distXsp_v3, 4)
EORcoords <- xEOR[!unlist(lapply(xEOR, is.null))]
notnullEOR <- which(!unlist(lapply(xEOR, is.null)))

# template <- raster("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/VisTrails/PARC_COplus_slope25/COplus_slope50.tif")


# February 26, 2019 added _bioclim where I've resampled to the bioclim raster cell size (less than 1km)
# coplus50int.tif
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
# aspect50int.tif
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")

# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")

# plot(coRugged_res)
# bio1 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_01.tif")
# bio12 <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/BioClim/20190122_WorldClimv2/wc2.0_bio_30s_12.tif")
# 
# bio1_res <- resample(bio1, coRugged_res, method="bilinear",
#                      filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif", overwrite=TRUE)
# 
# bio12_res <- resample(bio12, coRugged_res, method="bilinear",
                       # filename = "Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif", overwrite=TRUE)


bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif")
gc()

rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)


```



# Maxent 
```{r}

linkspeciesnumber <- do.call(rbind,lapply(notnull, function(x){
  data.frame(Species = distXsp_v3[[x]][[1]]@data$scientificName[1], Dist = distXsp_v3[[x]][[2]],
             Area = sum(distXsp_v3[[x]][[3]]), SpNum = x, Year=distXsp_v3[[x]][[1]]@data$year,
             distXsp_v3[[x]][[1]]@coords)
}))

Years <- (as.numeric(gsub("([0-9]+).*$", "\\1", linkspeciesnumber$Year)))
linkspeciesnumber$Year <- as.numeric(as.character(linkspeciesnumber$Year))
linkspeciesnumber$Year <- Years
hist(linkspeciesnumber$Year)
# with distXsp_v3 I've got herbarium records after 1980 but all polygons for EORs

ggplot(linkspeciesnumber, aes(Area, log(Dist)))+
  geom_point()+
  stat_smooth(method="lm")+
  ylab("Distance (log(meters))")+
  theme_bw()

plot(log(linkspeciesnumber$Area+1),log(linkspeciesnumber$Dist+1),
     xlab=expression(paste("Species Range log(meters" ^2,")" )),
     ylab=expression(paste("log (meters)")))
abline(lm(log(Dist+1)~log(Area+1), data=linkspeciesnumber))

length(unique(linkspeciesnumber$SpNum))
length(morethan12) # minus 1 for the Boechera missing EOR

max(linkspeciesnumber$Dist)

linkspeciesnumber$Dist[linkspeciesnumber$SpNum==12]
# Current Figure 2: see Herb to EORs_v4.Rmd 
# Removing largest distance that would put the point 3155 miles away, Colorado is 380 miles wide
# The second furthest is 668 miles away from somewhere in Colorado, that's outside of colorado
# The three furthest couldn't fall within Colroado so are removed  
# hypotenuse of colroado is about 472 miles, the third point is 406 miles from nearest EOR
```
Table 1 - species in niche models, put a column indiciating which are SDM
```{r}

out <- Rmisc::summarySE(linkspeciesnumber, "Dist", "SpNum")

tab1 <- do.call(rbind, lapply(split(linkspeciesnumber, linkspeciesnumber$SpNum), function(x){
  data.frame(SpNum = unique(x$SpNum), Species = x$Species[1], DistAvg = summarySE(x, "Dist"), 
             Area = unique(x$Area),
             MinYear = min(x$Year), MaxYear = max(x$Year), AvgLat = summarySE(x, "decimalLatitude"))
})) 

write.csv(tab1, "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/table1.csv")
library(Taxonstand)
TPLtbl1 <- TPL(tab1$Species)
write.csv(TPLtbl1, "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/TPLtbl1.csv")

```

#Should redo this to make sure all correct years per each
```{r}
jpeg("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Images/Figure2.jpg",
     width=225, height=105,units='mm', res=300)

smallerthan <- sort(linkspeciesnumber$Dist)[length(linkspeciesnumber$Dist)-2]

layout(matrix(c(1,2), 1,2))

plot(linkspeciesnumber$Area[linkspeciesnumber$Dist<smallerthan],
     linkspeciesnumber$Dist[linkspeciesnumber$Dist<smallerthan],
     xlab=expression(paste("Species Range km" ^2)),
     ylab=expression(paste("km")),
     pch=16, cex= .5, yaxt="n", xaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
     axis(1, at=c(0,10,20,30,40,50,60,70,80,90)*(1000^2), labels=c(0,10,20,30,40,50,60,70,80,90))
abline(lm(Dist~Area, data=linkspeciesnumber[linkspeciesnumber$Dist<smallerthan,]))
mtext("a)", side=3, line=0, adj=0)

plot(jitter(linkspeciesnumber$Year[linkspeciesnumber$Dist<smallerthan]),
     linkspeciesnumber$Dist[linkspeciesnumber$Dist<smallerthan],
     xlab="Year",
     ylab="",
     pch=16, cex= .25, yaxt="n")
     axis(2, at=c(0,100,200,300,400)*1000, labels=c(0,100,200,300,400))
abline(lm(Dist~Year, data=linkspeciesnumber[linkspeciesnumber$Dist<smallerthan,]))
mtext("b)", side=3, line=0, adj=0)


dev.off()

```


The EOR AUC results from VisTrails, samesize runs from ForVisTrails.Rmd where I either thinned to match number of Herbarium records or where I bootstrapped and jittered to get matching points. Used a standalone Dan Warren thinning process to get equally spaced out but covering the most area (of information) for points.


Make maxent commands
for output prediction map, use ENMeval   
Using KDE at 95% in MAxent VisTrails which mostly makes it so that it appears there's less effort in areas with fewer points but might not be the case, just might be smaller popualtions so maybe just circles with a certain radius would be better. Maybe add some points along roads for circles. Could put points along roads and then first pick points along roads within a certain distance from presence points and then 'circles' around all those points ?  
follow https://rspatial.org/sdm/SDM.pdf while VisTrails isnt' working
```{r}


setdiff(notnull,notnullEOR) # 8 is naughty, who is 8?
distXsp_v3[[8]][[1]]@data$scientificName # Boechera glareosa, where did you go?! Boechera gunnisoniana? 

#Background points, in a 5km circle around presence points, 300 stratified across the circles. Not quite the KDE but if I combined other collections from same trip I think that would be a correct estimator, circles represent the posibility that folks hiked 3 miles on their collection trip, seems likely enough. 

bgHerb <- lapply(notnull, function(x){
  circles <- circles(distXsp_v3[[x]][[1]], d = 5000) #Should be 5km around
  polygns <- polygons(circles)
  bg <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
  # do I want to get just one per cell? I'm gonna skip cellFromXY(mask, bg) # where mask should be my one used to set the size and clip the others in vistrails
  bg
  })
save(bgHerb, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgHerb.Rda")

# I know which they are, in order they are notnullEOR
bgEOR <- lapply(notnullEOR, function(x){
  df <- distXsp_v3[[x]][[4]]
  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  circles <- circles(df, d = 5000) #Should be 5km around
  polygns <- polygons(circles)
  bg <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
  # do I want to get just one per cell? I'm gonna skip cellFromXY(mask, bg) # where mask should be my one used to set the size and clip the others in vistrails
  bg
  })
save(bgEOR, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgEOR.Rda")

```


## Herbarium specimens as is, replicates instead of new kfold



###############################################################################################
## Skip this
Why dont' have at least the number of points for EORs that have for Herb in some of them? 
```{r}
thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}


load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2names.Rda")
library(maptools)
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")

l1G1G2 <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2"),])
l1G1G2$PolyID <- do.call(rbind, lapply(split(l1G1G2,l1G1G2$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))
coloradosps <- read.csv("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/SEINET G1 G2 Vouchers/occurrences.csv")
rowstomatch <- lapply(c("Taxon","AcceptedName"), function(x){
   coloradosps[,"scientificName"] %in%  g1g2names[,x]
})

coloradosps.g1g2 <- unique(rbind(coloradosps[rowstomatch[[1]],],coloradosps[rowstomatch[[2]],]))
coloradosps.g1g2$decimalLatitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLatitude))
coloradosps.g1g2$decimalLongitude <- 
  as.numeric(as.character(coloradosps.g1g2$decimalLongitude))
coloradosps.g1g2$lon2 <- round(coloradosps.g1g2$decimalLongitude,2) # about 1.1 km 
coloradosps.g1g2$lat2 <- round(coloradosps.g1g2$decimalLatitude,2)
coloradosps.g1g2$lon3 <- round(coloradosps.g1g2$decimalLongitude,3) # about 110 m
coloradosps.g1g2$lat3 <- round(coloradosps.g1g2$decimalLatitude,3)

     library(splancs)
```


```{r}

presenceEORpoints <- lapply(notnullEOR, function(i){
  g1g2now <- coloradosps.g1g2[coloradosps.g1g2$scientificName %in%
                                c(g1g2names$Taxon[i],g1g2names$AcceptedName[i])&
                                !is.na(coloradosps.g1g2$decimalLatitude),]
  
  g1g2now <- g1g2now[as.numeric(as.character(g1g2now$year))>1980,]
  g1g2now <- g1g2now[g1g2now$decimalLatitude>0,]
  g1g2now <- g1g2now[grepl("Specimen",g1g2now$basisOfRecord),]
  g1g2now <- g1g2now[,c(1:2,14:20,30:38,41,43:44,53:62,68:70,83:86)]
  
  
   polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                        g1g2names$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    
    # years <- format(as.Date(polys$LASTOBS, format="%Y-%m-%d"),"%Y")
    years <- as.numeric(substring(polys$LASTOBS,1,4))
    yearlater1980 <- c()
    for(l in 1:length(years)){
      yearlater1980[l] <- if(years[l]>1980){ 
                                      l } else {
                                        NA
                                      }
    }
    yearlater1980 <- yearlater1980[!is.na(yearlater1980)] 
    
    polys <- polys[yearlater1980,]
    
    totalarea <- sum(area((polys)))
  # area of each polygon
    areanow <- sapply(slot(polys,"polygons"), slot, "area")
  # Proportional area to the whole area number to thin
    EORpnts <- do.call(rbind, lapply(1:length(polys), function(f){
      outline <- polys@polygons[[f]]@Polygons[[1]]@coords
      grid <- makegrid(polys, cellsize = 50) # cellsize in map units!
      names(grid) <- c("x","y")
      gridout <- grid[inout(grid,outline), ]
      if(nrow(gridout)>1){
        gridthin <- thin.max(gridout,c("x","y"),(round(nrow(g1g2now)*(areanow[[f]]/totalarea),0))+1)
        gc()
        } else {
          if(nrow(gridout)>0) {
            gridthin <- gridout 
          } else {
            gridthin <- NULL
          }
          }
      gridthin
      }))
    gc()
    EORpnts
})

save(presenceEORpoints, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presenceEORpoints.Rda")


yearsofPolys <- lapply(notnullEOR, function(i){
    polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                        g1g2names$Taxon[i]),] 
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")
    years <- format(as.Date(polys$LASTOBS, format="%Y-%m-%d"),"%Y")
    yearlater1980 <- c()
    for(l in 1:length(years)){
      yearlater1980[l] <- if(years[l]>1980){ 
        l } else {
          NA
        }
    }
    yearlater1980 <- yearlater1980[!is.na(yearlater1980)]  
    table(years[which(years>1980)])
})

for(d in 1:length(yearsofPolys)){
  print(yearsofPolys[[d]])
}



rm(l1eor,l1G1G2,g1g2names,coloradosps,coloradosps.g1g2)
save(presenceEORpoints, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presenceEORpoints.Rda")

presenceEORpoints[[3]]

#These are all after 1980 but 
bgHerb <- lapply(notnull, function(x){
  circles <- circles(distXsp_v3[[x]][[1]], d = 5000) #Should be 5km around
  polygns <- polygons(circles)
  bg <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
  # do I want to get just one per cell? I'm gonna skip cellFromXY(mask, bg) # where mask should be my one used to set the size and clip the others in vistrails
  bg
  })
save(bgHerb, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgHerb.Rda")

# I know which they are, in order they are notnullEOR
bgEOR <- lapply(presenceEORpoints, function(x){
  df <- x
  coordinates(df) <- ~x+y
  proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
  circles <- circles(df, d = 5000) #Should be 5km around
  polygns <- polygons(circles)
  bg <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
  # do I want to get just one per cell? I'm gonna skip cellFromXY(mask, bg) # where mask should be my one used to set the size and clip the others in vistrails
  bg
  })
save(bgEOR, file= "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgEOR.Rda")


distXsp_v3[[1]][[4]]
```

###############################################################################################




## Herbarium without more error, 10 replicates   
```{r}
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/presenceEORpoints.Rda")

#Could sample again to get same number of records for presence and absence for each
jar <- paste(system.file(package="dismo"), "/java/maxent.jar", sep='')
ncores=10
    
# should be able to do the ones that are 12 too!

notnull <- which(!unlist(lapply(mapply('[[', distXsp_v3, 1), is.null)))
atleast12 <- c()
for(l in notnull){
  atleast12[match(l,notnull)] <- if(nrow(distXsp_v3[[l]][[1]]@coords)>11){ 
    l } else {
      NA
    }
}
atleast12 <- atleast12[!is.na(atleast12)] 
length(atleast12) # 28 vs. 24 over 12

rm(coAspect_res, coRugged_res, coElev_res, bio1_res, bio12_res)
gc()

load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgHerb.Rda")
# load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/bgEOR.Rda")

# notes in NicheSpaialIssuesManuscript_PCA from Merow et al. 2013 and ENMTools
# Set parameters for maxent niche models
argsformax <- make.args(RMvalues = 0, # regularization multiplier, seq(0.5, 4,0.5) to test multiple values?
                  fc = "LQH")  # features class combinations; fc = c("L", "LQ", "H", "LQH", "LQHP", "LQHPT"),)

for(x in atleast12){
        convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
        bgpnts <- bgHerb[[match(x,notnull)]]
        proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
        bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
        
  for(rep in 1:10){
        convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
        xm <- maxent(x = rasterstack,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords) # , 
                    # args=c("noautofeature","noproduct","nothreshold"))
        write.csv(data.frame(convertxy@coords,convertxy@data),
                  paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/presenceHerbnoerrorSp",x,"kfold",rep,".csv", sep=""))
        save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/maxentHerbnoerrorSp",x,"kfold",rep,".Rda", sep=""))        

        gc()
        #register parallel computing backend
        cl = parallel::makeCluster(ncores)
        doParallel::registerDoParallel(cl,ncores)
        #compute indices for data splitting
        rows = 1:nrow(rasterstack)
        split = sort(rows%%ncores)+1
        outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/PredictHerbnoerrorSp", x,"kfold",rep, sep="")
        #perform the prediction on subsets of the predictor dataset
        foreach(i=unique(split), .combine=c)%dopar%{
          rows_sub = rows[split==i]
          sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                        1, ncol(rasterstack)))
          raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
        }

        e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, rasterstack)
        save(e, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/evaluateHerbnoerrorSp",x,"kfold",rep,".Rda", sep=""))

        rm(xm)
        gc()
        stopCluster(cl)
  }
        e
}


```


```{r}


###Testing maxent parameters
i<-1
k<-3
convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
xm <- maxent(x = rasterstack,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords,args=c("noautofeature","noproduct","nothreshold"))
        save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/maxentHerbnoerrorSp",x,"kfold",rep,".Rda", sep=""))        

        gc()
        #register parallel computing backend
        cl = parallel::makeCluster(ncores)
        doParallel::registerDoParallel(cl,ncores)
        #compute indices for data splitting
        rows = 1:nrow(rasterstack)
        split = sort(rows%%ncores)+1
        outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/PredictHerbnoerrorSp", x,"kfold",rep, sep="")
        #perform the prediction on subsets of the predictor dataset
        foreach(i=unique(split), .combine=c)%dopar%{
          rows_sub = rows[split==i]
          sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                        1, ncol(rasterstack)))
          raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
        }
  gc()

    resultpath <- list.files(path = pathstart, 
                             pattern = paste("PredictHerbnoerrorSp",i,"kfold",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/ProbTiffSp",i,"Herbnoerrorkfold",k,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
plot(m)
plot(mbackgroundnoargs)
# mbackgroundnoargs <- m
        rm(xm)
        gc()
        stopCluster(cl)
```


Stitch together the maps 
```{r}
pathstart <- ("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/")

  lapply(atleast12, function(i){
  gc()
  lapply(1:10, function(k){
    resultpath <- list.files(path = pathstart, 
                             pattern = paste("PredictHerbnoerrorSp",i,"kfold",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/ProbTiffSp",i,"Herbnoerrorkfold",k,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
  })
})
```

MAxent and stitch together rasters as functions
```{r}

maxentrun <- function(whichones, spatialpointsdataframe_herb = distXsp_v3, numberofReps = 10, arguments)
for(x in atleast12){
        convertxy <- spTransform(distXsp_v3[[x]][[1]], CRS("+proj=longlat +datum=WGS84"))
        bgpnts <- bgHerb[[match(x,notnull)]]
        proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
        bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
        
  for(rep in 1:numberofReps){
        convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
        xm <- maxent(x = rasterstack,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords) # , 
                    # args=c("noautofeature","noproduct","nothreshold"))
        write.csv(data.frame(convertxy@coords,convertxy@data),
                  paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/presenceHerbnoerrorSp",x,"kfold",rep,".csv", sep=""))
        save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/maxentHerbnoerrorSp",x,"kfold",rep,".Rda", sep=""))        

        gc()
        #register parallel computing backend
        cl = parallel::makeCluster(ncores)
        doParallel::registerDoParallel(cl,ncores)
        #compute indices for data splitting
        rows = 1:nrow(rasterstack)
        split = sort(rows%%ncores)+1
        outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/PredictHerbnoerrorSp", x,"kfold",rep, sep="")
        #perform the prediction on subsets of the predictor dataset
        foreach(i=unique(split), .combine=c)%dopar%{
          rows_sub = rows[split==i]
          sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub), max(rows_sub), 
                                                        1, ncol(rasterstack)))
          raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
        }

        e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, rasterstack)
        save(e, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/evaluateHerbnoerrorSp",x,"kfold",rep,".Rda", sep=""))

        rm(xm)
        gc()
        stopCluster(cl)
  }
        e
}
}

stitchtogether <- function(whichones, pathstart, patternmatch, rasternames){
  lapply(whichones, function(i){
  gc()
  lapply(1:10, function(k){
    resultpath <- list.files(path = pathstart, 
                             pattern = paste(patternmatch,i,"kfold",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/ProbTiffSp",i,rasternames,k,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
  })
})
}

pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/"
stitchtogether(atleast12[1:21], pathstart,"PredictHerbWITHerrorSp", "HerbWITHerrorkfold")
```


Take the overlap of all EOR polygons and the rasters to get the histograms of probability   
    1. Do I average over all the replicates? Then what do I do with the SD? That could also be extracted to see how much uncertainty falls within the spatial extent of the known populations. - that is another measure of precision.    
    2. I should get the EORs from Utah, Wyoming, Arizona?, and New Mexico 
```{r}

load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2names.Rda")
library(maptools)
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")
l1G1G2 <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2"),])
l1G1G2$PolyID <- do.call(rbind, lapply(split(l1G1G2,l1G1G2$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))
plot(l1G1G2)

# Crop using extent, rasterize polygon and finally, create poly-raster
#          **** This is the code that you are after ****  f is the polygon, r is the raster
i<-atleast12[5]
k<-8


polys <- l1G1G2[l1G1G2$GNAME %in% c(g1g2names$AcceptedName[i],
                                    g1g2names$Taxon[i]),] 
proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") # CRS("+init=epsg:26913")

plot(l1G1G2)
plot(polys, add=TRUE, border="red", lwd=5)    

r <- raster(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/ProbTiffSp",i,"Herbnoerrorkfold",k,".tif", sep=""))

polys <- spTransform(polys, CRS("+proj=longlat +datum=WGS84"))
load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/evaluateHerbnoerrorSp", i,"kfold",k, ".Rda",sep=""))
e@confusion
e

load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/maxentHerbnoerrorSp", i,"kfold",k, ".Rda",sep=""))

plot(r)
plot(polys, add=TRUE, border=rgb(1,1,0,0.5), lwd=15)  

f <- 
cr <- crop(r, extent(f), snap="out")                    
fr <- rasterize(f, cr)   
lr <- mask(x=cr, mask=fr)

# Plot results
plot(lr)
plot(f,add=T)


```




#  Habitat specificity    
Principal components analysis of predictor variables    
PCA for how different - 
calculate the size of the ellipse <https://stackoverflow.com/questions/38782051/how-to-calculate-the-area-of-ellipse-drawn-by-ggplot2>
```{r}
habsp <- do.call(rbind,lapply(atleast12, function(x){
  out <- do.call(rbind,lapply(1:10, function(rep){
    load(paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/maxentHerbnoerrorSp", x,"kfold",rep, ".Rda",sep=""))
    outinner <- data.frame(SpeciesNum = x, kfold = rep, xm@presence)
    outinner
    }))
  out
  }))


# Would need to add a column for species and another for replicate and then ignore those columns for the princomp of all species and replicates at a time
prPCA <- princomp(habsp[,-c(1:2)])
summary(prPCA)
loadings(prPCA)

allsphabsp <- data.frame(habsp[,1:2],prPCA$scores)

# for one run of one species
ggplot(allsphabsp, aes(Comp.1,Comp.2, colour=as.factor(SpeciesNum)))+
  geom_point()+
  stat_ellipse(segments=201)+ #default is to draw 51 line segments to make the ellipse
  theme_bw()+
  xlab(expression(atop("PC1 (97% variance explained)", "Elevation = 0.974; Bio12 = 0.227")))+
  ylab(expression(atop("PC2 (2% variance explained)","Aspect = -0.999")))
  

# for all species
habspecificity <- do.call(rbind,lapply(atleast12, function(x){
  # get and average across the replicates
  ellipseout <- do.call(rbind,lapply(1:10, function(rep){
    p <- ggplot(allsphabsp[allsphabsp$SpeciesNum==x&allsphabsp$kfold==rep,], 
                aes(Comp.1,Comp.2))+
      geom_point()+
      stat_ellipse(segments=201) #default is to draw 51 line segments to make the ellipse
    # get ellipse coordinates
    pb <- ggplot_build(p)
    table(pb$data[[2]]$group)
    
    el <- pb$data[[2]][c("x","y")]
    
    # Center of ellipse
    ctr <- MASS::cov.trob(el)$center
    
    # Distance to center from each point on ellipse
    dist2center <- sqrt(rowSums((t(t(el)-ctr))^2))
    
    # Area of ellipse from semi-major and semi-minor axes which are largest and smallest of dist to center
    habitatspecificity <- pi*min(dist2center)*max(dist2center)
    hsout <- data.frame(SpeciesNum = x, kfold = rep, habspec = habitatspecificity)
    hsout
    }))
  ellipseout
  }))

summaryhabspec <- summarySE(habspecificity, measurevar = "habspec", groupvars = c("SpeciesNum"))

```


Distance from all specimens to all EORs regardless of year      
See distXsp_noEORgrid <- in "Herb to EORs_v4.Rmd"
```{r}
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid.Rda")

allspecies <- mapply(cbind, distXsp_noEORgrid, "SpeciesNum" = 1:60, SIMPLIFY = FALSE)
allspecies <- do.call(rbind, allspecies[notnull])
gc()

```

```{r}
# Overlay area and spatial error for each species
ggplot(habspecificity, aes(factor(SpeciesNum), habspec))+
  geom_boxplot()+
  geom_point(position=position_jitter()) +
  theme_bw()+
  ylab("Habitat specificity (95% CI)")+
  xlab("Species ID")
  # geom_boxplot(data=allspecies[allspecies$SpeciesNum %in% atleast12,], aes(factor(SpeciesNum), Dist), colour = "red", position=position_dodge(0.5))+
  # geom_point(data=allspecies[allspecies$SpeciesNum %in% atleast12,], 
  #            aes(factor(SpeciesNum), Area/(1000)),
  #            colour="blue")


  
```
Habitat specificity (average) by distance
```{r}


```


