---
title: "Second chapter 1 for double rstudio"
author: "Michelle DePrenger-Levin"
date: "February 28, 2019"
output: html_document
---


```{r}
rm(list=ls())
library(ggplot2)
library(rgeos)
library(raster)
library(foreach)
library(parallel)
library(doParallel)
library(maptools)
library(dismo)
library(Rmisc)
library(rgdal)
library(ENMeval)
library(Taxonstand)
library(splancs)
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/habspEORandNoandWith.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/coloradosps.g1g2_168.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2namesall68.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid68.Rda")
load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid1_68.Rda")

load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/nichevaluesbySDM.Rda")
l1eor <- readShapePoly("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_ArcMap_Projects/Link_EO_Herbarium_Records/L1shp")

##Each polygon might be made of multiple disconnected polygons. Need to separate and label
l1G1G2 <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2"),])
l1G1G2$PolyID <- do.call(rbind, lapply(split(l1G1G2,l1G1G2$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))
l1G1G2and <- disaggregate(l1eor[l1eor$GRANK %in% c("G1","G2","G1G2"),])
l1G1G2and$PolyID <- do.call(rbind, lapply(split(l1G1G2and,l1G1G2and$OBJECTID),
                                       function(x){
              x$POlyID <- paste(x$EO_ID, LETTERS[seq(from=1, to= nrow(x))],sep="")
              x
              }))
namesg1g2 <- table(as.character(l1G1G2$GNAME))
length(namesg1g2) #60 species
namesg1g2and <- table(as.character(l1G1G2and$GNAME))
length(namesg1g2and) # 68
#What? are some in twice? 
namesg1g2and <- c(namesg1g2and[match(names(namesg1g2),names(namesg1g2and))],
                  namesg1g2and[setdiff(names(namesg1g2and),names(namesg1g2))])



load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/g1g2names.Rda")


# February 26, 2019 added _bioclim where I've resampled to the bioclim raster cell size (less than 1km)
# coplus50int.tif
coElev_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/ElevationResampled_bioclim.tif")
# aspect50int.tif
coAspect_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/AspectResampled_bioclim.tif")
# COplus_ruggedInt50.tif
coRugged_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/RuggedResampled_bioclim.tif")

bio1_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio1Resampled_bioclim.tif")
bio12_res <- raster("Q:/Research/All_Projects_by_Species/aa_Shapefiles_Maps/aa_GENERAL_non-species_files/All_General_Background_Layers/NationalMapUSDA_DEM_aroundcolorado/Bio12Resampled_bioclim.tif")
gc()
rasterstack <- stack(coElev_res,coAspect_res,coRugged_res,bio1_res,bio12_res)
rm(bio1_res,bio12_res,coAspect_res,coElev_res,coRugged_res)
gc()
stitchtogether <- function(whichones, pathstart, patternmatch, rasternames){
  lapply(whichones, function(i){
  gc()
  lapply(1:10, function(k){
    resultpath <- list.files(path = pathstart, 
                             pattern = paste(patternmatch,i,"kfold",k,"_",sep=""), 
                             full.names=TRUE)
    rastout <- lapply(resultpath, function(x){
      raster(x)
      })
    rastout$filename <- paste(pathstart,"ProbTiffSp",i,rasternames,k,".tif", sep="")
    rastout$overwrite <- TRUE
    m <- do.call(merge, rastout)
  })
})
}

thin.max <- function(x, cols, npoints){
  #Create empty vector for output
  inds <- vector(mode="numeric")
  
  #Create distance matrix
  this.dist <- as.matrix(dist(x[,cols], upper=TRUE))
  
  #Draw first index at random
  inds <- c(inds, as.integer(runif(1, 1, length(this.dist[,1]))))
  
  #Get second index from maximally distant point from first one
  #Necessary because apply needs at least two columns or it'll barf
  #in the next bit
  inds <- c(inds, which.max(this.dist[,inds]))
  
  while(length(inds) < npoints){
    #For each point, find its distance to the closest point that's already been selected
    min.dists <- apply(this.dist[,inds], 1, min)
    
    #Select the point that is furthest from everything we've already selected
    this.ind <- which.max(min.dists)
    
    #Get rid of ties, if they exist
    if(length(this.ind) > 1){
      print("Breaking tie...")
      this.ind <- this.ind[1]
    }
    inds <- c(inds, this.ind)
  }
  
  return(x[inds,])
}

#Need to averge and SD each of the 10

library(cluster)
library(snow)

forhistofaverage <- function(whichones = atleast12, pathstart, patternmatch){
  stacktoaverage <- lapply(whichones, function(i){
    rasterstoavg <- list.files(path = pathstart, 
                               pattern = paste("ProbTiffSp",
                                               i,
                                               patternmatch,sep=""), 
                               full.names=TRUE)
    ras <- stack(lapply(rasterstoavg, function(y){
      raster(y)
    }))
    beginCluster(10)
    ras.mean <- clusterR(ras, calc, args=list(mean, na.rm=T))
    writeRaster(ras.mean, paste(pathstart,
                                "AvgTiffSp",i,patternmatch,g1g2namesall68$AcceptedName[i],
                                ".tif", sep=""),overwrite=TRUE)
    gc()
    endCluster()
    ras.mean
  })
  stacktoaverage
}

forhistofsd <- function(whichones = atleast12, pathstart, patternmatch){
  stacktoaverage <- lapply(whichones, function(i){
    rasterstoavg <- list.files(path = pathstart, 
                               pattern = paste("ProbTiffSp",
                                               i,
                                               patternmatch,sep=""), 
                               full.names=TRUE)
    ras <- stack(lapply(rasterstoavg, function(y){
      raster(y)
    }))
    beginCluster(10)
    ras.mean <- clusterR(ras, calc, args=list(sd, na.rm=T))
    writeRaster(ras.mean, paste(pathstart, "SDTiffSp",i,patternmatch,
                              g1g2namesall68$AcceptedName[i],
                              ".tif", sep=""),overwrite=TRUE)
    gc()
    endCluster()
    ras.mean
  })
  stacktoaverage
}


load("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/Data/distXsp_noEORgrid.Rda")
distXspall <- do.call(rbind, distXsp_noEORgrid)
#The over 400 km is clearly wrong; so are any above 300km is out of the state (if point is in the middle) so need to cutoff below 300,000
```

```{r}


pathstart <- "Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/"
stitchtogether(atleast12[22:28], pathstart,"PredictHerbWITHerrorSp", "HerbWITHerrorkfold")

stitchtogether(atleast12[1], pathstart,"PredictHerbnoerrorSp", "Herbnoerrorkfold")
```


Habitat specificity including EORs   
Might have errors if there are more Herb points than EORs. 
```{r}
notnull1_68 <- which(!unlist(lapply(distXsp_noEORgrid1_68, is.null)))
length(notnull1_68) # 52 have data

atleast12168 <- c()
for(l in notnull1_68){  # notnull1_68
  atleast12168[match(l,notnull1_68)] <- if(nrow(distXsp_noEORgrid1_68[[l]])>11){   # match(l,notnull1_68)
    l } else {
      NA
    }
}
atleast12168 <- atleast12168[!is.na(atleast12168)] 
reallistofTiffs <- atleast12168[!atleast12168 %in% c(29,40)]

whichones <- reallistofTiffs[2:5]
whichones <- reallistofTiffs[2]

habitatSpecificity <- function(whichones, pathstart, replicates){
  habspno <- do.call(rbind,lapply(whichones, function(x){
  outno <- do.call(rbind,lapply(1:replicates, function(rep){
    load(paste(pathstart,"maxentHerbnoerror","Sp", x,"kfold",rep, ".Rda",sep=""))
    outinner <- data.frame(SpeciesNum = x, kfold = rep, HerbType = "NoError", xm@presence)
    outinner
    }))
  outno
  }))
  
  habspwith <- do.call(rbind,lapply(whichones, function(x){
  outWITH <- do.call(rbind,lapply(1:replicates, function(rep){
    load(paste(pathstart,"maxentHerbWITHerror","Sp", x,"kfold",rep, ".Rda",sep=""))
    outinner <- data.frame(SpeciesNum = x, kfold = rep, HerbType = "WithError",xm@presence)
    outinner
    }))
  outWITH
  }))
  
  habspEOR <- do.call(rbind,lapply(whichones, function(x){
    polys <- l1G1G2and[l1G1G2and$GNAME %in% c(g1g2namesall68$AcceptedName[x],
                                          g1g2namesall68$Taxon[x]),]
    proj4string(polys) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84") 
    EORpnts <- do.call(rbind, lapply(1:length(polys), function(f){
         outline <- polys@polygons[[f]]@Polygons[[1]]@coords
         outlineout <- data.frame(x=outline[,1],y=outline[,2])
         areas <- sapply(slot(polys, "polygons"), slot, "area")
         if(min(extent(polys[f,])@xmax-extent(polys[f,])@xmin,
                extent(polys[f,])@ymax-extent(polys[f,])@ymin)>100)
         if(areas[f]<)
         grid <- makegrid(polys, cellsize = 100) # cellsize in map units!
         names(grid) <- c("x","y")
         gridout <- grid[inout(grid,outline), ]
         pntsout <- rbind(gridout,outlineout)
         pntsout
         }))
    
# cell size doesn't work soemtimes, maybe divide sample size by area then thin?    
for(f in 1:length(polys)){
  # print(extents[f,])
  #   print(round(areas[f]/(sum(areas)),0)+1)
  outline <- polys@polygons[[f]]@Polygons[[1]]@coords
  grid <- (makegrid(polys, cellsize = 100 ))
  names(grid) <- c("x","y")
  print(grid[inout(grid,outline), ])
}
    
    extents <- do.call(rbind,lapply(1:length(polys), function(x){
      ex <- extent(polys[x,])
      data.frame(xrange = ex@xmax-ex@xmin, yrange= ex@ymax-ex@ymin)
    }) )
    # Get the sample size of one replicate of each species (x)
    habspeor <- habspno[habspno$SpeciesNum==x & habspno$kfold == 1,]
    if(nrow(EORpnts)>nrow(habspeor)) EORpnts <- thin.max(EORpnts, c("x","y"), nrow(habspeor))
    convertgridthin <- SpatialPoints(EORpnts[,c("x","y")], proj4string = CRS("+proj=utm +zone=13 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"))
    gridthin <- spTransform(convertgridthin, CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
    gridextract <- extract(rasterstack,gridthin)
    out <- data.frame(SpeciesNum = x, kfold = 1, HerbType = "EOR",gridextract)
    out
  }))

  habsp <- rbind(habspno,habspwith, habspEOR)
  
  prPCA <- princomp(habsp[,-c(1:3)])
  allsphabsp <- data.frame(habsp[,1:3],prPCA$scores)
  allsphabsp$HerbType <- as.character(allsphabsp$HerbType)
  
  # for all species and both error and no and EOR, dropping parameters (kfolds in EOR; only 1)
  habspecificity <- do.call(rbind,
                            lapply(split(allsphabsp, 
                                         list(allsphabsp$SpeciesNum,
                                              allsphabsp$kfold,
                                              allsphabsp$HerbType), drop=TRUE), function(x){

      p <- ggplot(x, aes(Comp.1,Comp.2))+
      geom_point()+
      stat_ellipse(segments=201) #default is to draw 51 line segments to make the ellipse
    # get ellipse coordinates
    pb <- ggplot_build(p)
    table(pb$data[[2]]$group)
    el <- pb$data[[2]][c("x","y")]
    
    # Center of ellipse
    ctr <- MASS::cov.trob(el)$center
    
    # Distance to center from each point on ellipse
    dist2center <- sqrt(rowSums((t(t(el)-ctr))^2))
    
    # Area of ellipse from semi-major and semi-minor axes which are largest and smallest of dist to center
    habitatspecificity <- pi*min(dist2center)*max(dist2center)
    ellipseoutfold <- data.frame(SpeciesNum = unique(x$SpeciesNum), 
                                 kfold = unique(x$kfold), 
                                 HerbType = unique(x$HerbType), habspec = habitatspecificity)
    ellipseoutfold
        }))
  habspecificity
}
testhabsp <- habitatSpecificity(reallistofTiffs[4:5], pathstart, replicates = 10)

```



<https://rpubs.com/frousseu/328065> 

```{r}

for(x in atleast12[20:28]){
  rm(e)
    errorpoints <- distXsp_v3[[x]][[1]]
     # for each point I will draw a circle of size (drawn from the distribution of error seen distXspall$Dist) and then pick a random point along the circle.
    errorpointsout <- do.call(rbind,lapply(1:nrow(errorpoints), function(r){
      errordist <- sample(distdistribution, 1)
      if(errordist>0){
        erroraround <- gBuffer(errorpoints[r,], width=errordist)
        newpoint <- erroraround@polygons[[1]]@Polygons[[1]]@coords
        out <- newpoint[sample(1:nrow(newpoint),1),]
      } else {
          out <- errorpoints@coords[r,]
      }
      out
    }))
    
    df <- data.frame(errorpointsout)
    coordinates(df) <- ~x+y
    proj4string(df) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
    circlesout <- circles(df, d = 5000) #Should be 5km around
    polygns <- polygons(circlesout)
    bgpnts <- spsample(polygns, 300, "stratified") # one single random location in each 'cell' 
    
    convertxy <- spTransform(df, CRS("+proj=longlat +datum=WGS84"))
    proj4string(bgpnts) <- CRS("+proj=utm +zone=13 ellps=NAD83 +ellps=WGS84")
    bgpnts <- spTransform(bgpnts, CRS("+init=epsg:4326") )
        
  for(rep in 1:10){
        convertxy$kfold <- kfold(convertxy, k=4) # to have 75:25%
        xm <- maxent(x = rasterstack,p = convertxy[convertxy$kfold!=1,], a = bgpnts@coords) # ,
                    # args=c("noautofeature","noproduct","nothreshold"))
        write.csv(data.frame(convertxy@coords,convertxy@data),
                  paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/presenceHerbWITHerrorSp",x,"kfold",rep,".csv", sep=""))
        save(xm, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/maxentHerbWITHerrorSp",x,"kfold",rep,".Rda", sep=""))
        gc()
        #register parallel computing backend
        cl = parallel::makeCluster(ncores)
        doParallel::registerDoParallel(cl,ncores)
        #compute indices for data splitting
        rows = 1:nrow(rasterstack)
        split = sort(rows%%ncores)+1
        outname = paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/PredictHerbWITHerrorSp", x,"kfold",rep, sep="")
        #perform the prediction on subsets of the predictor dataset
        foreach(i=unique(split), .combine=c)%dopar%{
          rows_sub = rows[split==i]
          sub = raster::crop(rasterstack,raster::extent(rasterstack, min(rows_sub),
                                                        max(rows_sub), 1, ncol(rasterstack)))
          raster::predict(sub, xm, filename=paste(outname, i, sep="_"), overwrite=TRUE)
        }

        gc()
        stopCluster(cl)

        e <- evaluate(convertxy[convertxy$kfold==1,], bgpnts, xm, rasterstack)
        save(e, file= paste("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/evaluateHerbWITHerrorSp",x,"kfold",rep,".Rda", sep=""))

        rm(xm, errorpointout, errorpoints,polygns)
  }
        e
}

```



```{r}

pathstart <- ("Q:/Research/Projects/alpine-phenology/Uncertainty in niche modeling/RMaxEnt_herb_herbpluserror/")
atleast12168 <- c()
for(l in notnull1_68){  # notnull1_68
  atleast12168[match(l,notnull1_68)] <- if(nrow(distXsp_noEORgrid1_68[[l]])>11){   # match(l,notnull1_68)
    l } else {
      NA
    }
}
atleast12168 <- atleast12168[!is.na(atleast12168)] 

reallistofTiffs <- atleast12168[!atleast12168 %in% c(29,40)]

nichevaluesbySDM <- lapply(c(reallistofTiffs), function(i){
  gc()
  resultpathno <- list.files(path = pathstart, 
                           pattern = paste("AvgTiffSp",i,"Herbnoerror",sep=""), 
                           full.names=TRUE)
  rastoutno <- raster(resultpathno)
  resultpathWITH <- list.files(path = pathstart, 
                     pattern = paste("AvgTiffSp",i,"HerbWITHerror",sep=""), 
                     full.names=TRUE)
  rastoutWITH <- raster(resultpathWITH)

  quantilesno <- summary(values(rastoutno))
  tenthsno <- (quantilesno[5]-quantilesno[1])/10
  quantilesWITH <- summary(values(rastoutWITH))
  tenthsWITH <- (quantilesWITH[5]-quantilesWITH[1])/10
  notenths <- lapply(2:10, function(t){
    D <- overlay(rasterstack, rastoutno, fun=function(x,y){ 
      x[y<((t-1)*tenthsno) | y>(t*tenthsno)] <- NA; x})
    plot(D)
    
    
    out <- na.omit(values(D))
    out <- data.frame(out)
    out
  })
  withtenths <- lapply(2:10, function(t){
    D <- overlay(rasterstack, rastoutWITH, fun=function(x,y){ 
      x[y<((t-1)*tenthsno) | y>(t*tenthsWITH)] <- NA; x})
    out <- na.omit(values(D))
    out <- data.frame(out)
    out
  })
  list(notenths,withtenths)
})

plot(D)
```
